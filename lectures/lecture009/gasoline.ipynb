{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting octane numbers from NIR spectra\n",
    "\n",
    "In this example, we will predict [octane numbers](https://en.wikipedia.org/wiki/Octane_rating) from measured NIR spectra. Specifically, we will compare a least squares model to a partial least squares model and we will\n",
    "use cross-validation to check the performance of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the raw data\n",
    "\n",
    "The raw data can be found in the file [gasoline.csv](./gasoline.csv). We will here load it with pandas and\n",
    "extract the octane number, the spectra, and the wavelengths for the spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "sns.set_theme(style=\"ticks\", context=\"notebook\", palette=\"muted\")\n",
    "%matplotlib notebook\n",
    "\n",
    "np.random.seed(2022)  # Set random state to get the same results for each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data set:\n",
    "data = pd.read_csv(\"gasoline.csv\")\n",
    "# Each row contain a measured spectrum and a corresponding octane number:\n",
    "# - extract the octane numbers:\n",
    "yvars = [\"octane\"]\n",
    "octane = data[yvars].to_numpy()\n",
    "# - extract the spectra:\n",
    "xvars = [i for i in data.columns if i not in yvars]\n",
    "spectra = data[xvars].to_numpy()\n",
    "# - get the wavelengths:\n",
    "wavelengths = np.array([int(i.split()[0].split(\".\")[1]) for i in xvars])\n",
    "print(f\"Number of wavelengths measured: {len(xvars)}\")\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let us visualize the spectra, just to see what we have to work with:\n",
    "# We add some color, so we can color the spectra according to\n",
    "# the octane numbers:\n",
    "norm = mpl.colors.Normalize(vmin=octane.min(), vmax=octane.max())\n",
    "cmap = mpl.cm.ScalarMappable(norm=norm, cmap=\"coolwarm\")\n",
    "\n",
    "fig, axi = plt.subplots(constrained_layout=True)\n",
    "axi.set_title(\"NIR spectra\")\n",
    "for i, speci in enumerate(spectra):\n",
    "    axi.plot(wavelengths, speci, color=cmap.to_rgba(octane[i]))\n",
    "axi.set(xlabel=\"Wavelength (nm)\", ylabel=\"Absorbance\")\n",
    "# axi.set_facecolor(\"0.975\")\n",
    "fig.colorbar(cmap, ax=axi, label=\"Octane numbers\")\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the figure above, we see that there is some difference in the spectra, depending on the octane number. So, let us see if we can use this to create some models for predicting the octane numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares and PLS with test-train and cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create training and test sets:\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(spectra, octane, test_size=0.3)\n",
    "\n",
    "scaler_x = StandardScaler().fit(X_train)\n",
    "X_train = scaler_x.transform(X_train)\n",
    "X_test = scaler_x.transform(X_test)\n",
    "\n",
    "scaler_y = StandardScaler().fit(Y_train)\n",
    "Y_train = scaler_y.transform(Y_train)\n",
    "Y_test = scaler_y.transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PLS model, but use cross-validation to find\n",
    "# the best number of pls components to use:\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "parameters = {\n",
    "    \"n_components\": range(1, 11),\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    PLSRegression(),\n",
    "    parameters,\n",
    "    # scoring='r2',\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    refit=True,\n",
    ")\n",
    "\n",
    "grid.fit(X_train, Y_train)\n",
    "print(grid.best_params_)\n",
    "pls_model_optimized = grid.best_estimator_\n",
    "B_PLS = pls_model_optimized.coef_[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axi = plt.subplots(constrained_layout=True)\n",
    "score = grid.cv_results_[\"mean_test_score\"]\n",
    "score_std = grid.cv_results_[\"std_test_score\"]\n",
    "axi.errorbar(\n",
    "    parameters[\"n_components\"],\n",
    "    score,\n",
    "    yerr=score_std,\n",
    "    marker=\"o\",\n",
    ")\n",
    "axi.set_xticks(parameters[\"n_components\"])\n",
    "axi.set(\n",
    "    xlabel=\"PLS components\", ylabel=\"score\", title=\"Results from grid search\"\n",
    ")\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a least squares model and train it:\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "leastsquares = LinearRegression(fit_intercept=False)\n",
    "leastsquares.fit(X_train, Y_train)\n",
    "B_MLR = leastsquares.coef_[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LASSO model and train it:\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "parameters_lasso = {\"alpha\": np.logspace(-3, 2, 10)}\n",
    "\n",
    "grid_lasso = GridSearchCV(\n",
    "    Lasso(fit_intercept=False, max_iter=10000),\n",
    "    parameters_lasso,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    refit=True,\n",
    ")\n",
    "grid_lasso.fit(X_train, Y_train)\n",
    "print(grid_lasso.best_params_)\n",
    "lasso_model_optimized = grid_lasso.best_estimator_\n",
    "B_lasso = lasso_model_optimized.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check performance with cross-validation:\n",
    "fig, axes = plt.subplots(\n",
    "    constrained_layout=True, ncols=3, sharex=True, sharey=True, figsize=(9, 3)\n",
    ")\n",
    "\n",
    "axes[0].set_title(\"Partial least squares\", loc=\"left\")\n",
    "axes[1].set_title(\"Least squares\", loc=\"left\")\n",
    "axes[2].set_title(\"Lasso\", loc=\"left\")\n",
    "\n",
    "models = [pls_model_optimized, leastsquares, lasso_model_optimized]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    cv_results = cross_validate(\n",
    "        model,\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        scoring=(\"r2\", \"neg_mean_squared_error\"),\n",
    "        return_train_score=True,\n",
    "    )\n",
    "    axes[i].plot(cv_results[\"train_r2\"], label=\"Training\", marker=\"o\")\n",
    "    axes[i].plot(cv_results[\"test_r2\"], label=\"Test\", marker=\"o\")\n",
    "    axes[i].set_xlabel(\"CV no.\")\n",
    "axes[0].set_ylabel(\"R²\")\n",
    "axes[0].legend()\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "def get_scores(y, y_hat):\n",
    "    r2 = r2_score(y, y_hat)\n",
    "    rmse = mean_squared_error(y, y_hat, squared=False)\n",
    "    return r2, rmse\n",
    "\n",
    "\n",
    "def add_scores(model, X_train, y_train, X_test, y_test, ax):\n",
    "    \"\"\"Plot y vs y_hat for test and training.\"\"\"\n",
    "    y_hat_train = model.predict(X_train)\n",
    "    y_hat_test = model.predict(X_test)\n",
    "\n",
    "    r2_train, rmsec = get_scores(y_train, y_hat_train)\n",
    "    r2_test, rmsep = get_scores(y_test, y_hat_test)\n",
    "\n",
    "    txt_train = f\"R²(train) = {r2_train:.2f}\\nRMSEC = {rmsec:.2f}\"\n",
    "    txt_test = f\"R²(test) = {r2_test:.2f}\\nRMSEP = {rmsep:.2f}\"\n",
    "\n",
    "    ax.scatter(Y_train, y_hat_train, label=txt_train)\n",
    "    ax.scatter(Y_test, y_hat_test, label=txt_test)\n",
    "    ax.legend(fontsize=\"small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    constrained_layout=True,\n",
    "    ncols=3,\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    "    figsize=(9, 3),\n",
    ")\n",
    "\n",
    "axes[0].set_title(\"Partial least squares\", loc=\"left\")\n",
    "axes[1].set_title(\"Least squares\", loc=\"left\")\n",
    "axes[2].set_title(\"Lasso\", loc=\"left\")\n",
    "\n",
    "models = [pls_model_optimized, leastsquares, lasso_model_optimized]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    axes[i].set_aspect(\"equal\")\n",
    "    add_scores(model, X_train, Y_train, X_test, Y_test, axes[i])\n",
    "    axes[i].set_xlabel(\"y\")\n",
    "axes[0].set_ylabel(\"ŷ\")\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    constrained_layout=True,\n",
    "    ncols=1,\n",
    "    nrows=3,\n",
    "    sharex=True,\n",
    ")\n",
    "\n",
    "axes[0].set_title(\"Partial least squares\", loc=\"left\")\n",
    "axes[1].set_title(\"Least squares\", loc=\"left\")\n",
    "axes[2].set_title(\"Lasso\", loc=\"left\")\n",
    "\n",
    "coeffs = [B_PLS, B_MLR, B_lasso]\n",
    "\n",
    "for i, coef in enumerate(coeffs):\n",
    "    axes[i].plot(wavelengths, coef)\n",
    "    axes[i].axhline(y=0.0, ls=\":\", color=\"k\")\n",
    "    axes[i].set_ylabel(\"Coeff.\")\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = mpl.colors.Normalize(vmin=octane.min(), vmax=octane.max())\n",
    "cmap = mpl.cm.ScalarMappable(norm=norm, cmap=\"coolwarm\")\n",
    "fig, axi = plt.subplots(constrained_layout=True)\n",
    "axi.set_title(\"NIR spectra\")\n",
    "for i, speci in enumerate(spectra):\n",
    "    axi.plot(wavelengths, speci, color=cmap.to_rgba(octane[i]))\n",
    "\n",
    "# axi.plot(wavelengths, B_lasso)\n",
    "axi.set(xlabel=\"Wavelength (nm)\", ylabel=\"Absorbance\")\n",
    "# axi.set_facecolor(\"0.975\")\n",
    "fig.colorbar(cmap, ax=axi, label=\"Octane numbers\")\n",
    "sns.despine(fig=fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

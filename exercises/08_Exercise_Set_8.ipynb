{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise set 8\n",
    "\n",
    ">The goal of this exercise is to perform **principal component analysis**\n",
    ">and **clustering** on a data set with many variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8.1\n",
    "\n",
    "This exercise will explore the [wine data set](https://archive.ics.uci.edu/ml/datasets/Wine), a data set commonly used as an example for classification.\n",
    "The data set contains the results of\n",
    "a chemical analysis of wines from a region in Italy. These\n",
    "wines are made using grapes grown by three different cultivators.\n",
    "In this first exercise, we will explore the\n",
    "data set using principal component analysis and investigate\n",
    "if the results from the chemical analysis can be used to separate\n",
    "the wines into groups that correspond to the cultivator of the grapes.\n",
    "\n",
    "The data set contains the following columns:\n",
    "\n",
    "\n",
    "| Column name                    | Description                                              |\n",
    "|--------------------------------|----------------------------------------------------------|\n",
    "| alcohol                        | The alcohol content of the wine.                         | \n",
    "| malic_acid                     | The amount of malic acid in the wine (malic acid has an apple aroma).  |\n",
    "| ash                            | The amount of ash in the wine (ash is the matter that remains after evaporation and incineration).   | \n",
    "| alcalinity_of_ash              | The alkalinity of the ash content of the wine.           |\n",
    "| magnesium                      | The amount of magnesium in the wine.                      |\n",
    "| total_phenols                  | The total amount of [phenols](https://en.wikipedia.org/wiki/Phenolic_content_in_wine) (that are not flavanoids) in the wine. |\n",
    "| flavanoids                     | The amount of [flavanoids](https://en.wikipedia.org/wiki/Flavonoid) in the wine |\n",
    "| nonflavanoid_phenols           | The total amount of phenols in the wine.   |\n",
    "| proanthocyanins                | The amount of [proanthocyanins](https://en.wikipedia.org/wiki/Proanthocyanidin) in the wine (important for red/blue/purple colors).   |\n",
    "| color_intensity                | Color intensity of the wine (measured spectroscopically).  |\n",
    "| hue                            | Color hue of the wine (measured spectroscopically).         |\n",
    "| od280/od315_of_diluted_wines   | The protein content of the wine. OD280/OD315 is a method for determining protein concentration.                                     |\n",
    "| proline                        | The amount of [proline](https://en.wikipedia.org/wiki/Proline) in the wine (proline is the main amino acid found in red wine).   |  \n",
    "| target                         | The cultivator of the wine, given as 0, 1, or 2.   |\n",
    "\n",
    "The data can be loaded as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load the wine data set\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "sns.set_theme(style=\"ticks\", context=\"notebook\", palette=\"muted\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the data set as a pandas frame:\n",
    "data_set = load_wine(as_frame=True)[\"frame\"]\n",
    "data_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1(a)\n",
    "Begin by exploring the raw data. Here, you should choose\n",
    "the method yourself. You can, for instance, look at histograms of the\n",
    "different measured quantities, correlations between the quantities,\n",
    "or other plots of the raw data (for instance, the \n",
    "[scatter plot matrix](https://seaborn.pydata.org/examples/scatterplot_matrix.html) we used in a previous exercise). After looking at the raw data, are there some of the\n",
    "variables that seem to be able to distinguish\n",
    "between the wines produced by the different cultivators?\n",
    "\n",
    "To make things a bit more interesting (and to show you how to make things slightly more interactive in a\n",
    "Jupyter notebook); here are two examples that create a dropdown selector for picking variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ipywidgets import Dropdown, interact\n",
    "\n",
    "# This code shows the distributions for the three targets for one variable:\n",
    "\n",
    "\n",
    "def show_data(variable):\n",
    "    fig1, (ax1, ax2) = plt.subplots(\n",
    "        constrained_layout=True, ncols=2, figsize=(8, 4)\n",
    "    )\n",
    "    sns.boxplot(data=data_set, y=variable, x=\"target\", ax=ax1)\n",
    "    sns.kdeplot(\n",
    "        data=data_set,\n",
    "        x=variable,\n",
    "        hue=\"target\",\n",
    "        fill=True,\n",
    "        palette=\"muted\",\n",
    "        ax=ax2,\n",
    "    )\n",
    "\n",
    "\n",
    "variables = [i for i in data_set if i != \"target\"]\n",
    "\n",
    "dropdown = Dropdown(options=variables, description=\"Variable:\")\n",
    "interact(show_data, variable=dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a 2D plot to show the distribution with two variables:\n",
    "\n",
    "\n",
    "def show_data2(variable_x, variable_y):\n",
    "    grid = sns.jointplot(\n",
    "        data=data_set,\n",
    "        x=variable_x,\n",
    "        y=variable_y,\n",
    "        hue=\"target\",\n",
    "        palette=\"muted\",\n",
    "    )\n",
    "\n",
    "\n",
    "dropdown1 = Dropdown(options=variables, description=\"Variable X:\")\n",
    "dropdown2 = Dropdown(options=variables, description=\"Variable Y:\")\n",
    "interact(show_data2, variable_x=dropdown1, variable_y=dropdown2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 8.1(a): Did you find some variables that seem to distinguish between cultivators?\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1(b)\n",
    "Perform a PCA on the data set (see the example code \n",
    "for this below)\n",
    "and consider the following:\n",
    "\n",
    "* (i)  Do you need to scale your data before\n",
    "  performing PCA in this case (why/why not)?\n",
    "\n",
    "\n",
    "* (ii)  Should you include the `target` column in the data you use for the PCA?\n",
    "\n",
    "\n",
    "* (iii)  How many principal components are needed to explain 95 % of the\n",
    "  variance in the data? Answer this by plotting the explained variance\n",
    "  as a function of the number of principal components.\n",
    "\n",
    "\n",
    "Example code for PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load the wine data set and run PCA.\"\"\"\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "data_set = load_wine(as_frame=True)[\"frame\"]\n",
    "variables = [i for i in data_set.columns if i != \"target\"]\n",
    "X = data_set[variables].to_numpy()\n",
    "\n",
    "# Uncomment the following line to scale your data:\n",
    "# X = scale(X)\n",
    "pca = PCA()\n",
    "scores = pca.fit_transform(X)\n",
    "\n",
    "# Print out the percentage of variance explained by each component:\n",
    "variance_ratio = pca.explained_variance_ratio_\n",
    "print(variance_ratio)\n",
    "# To get the cumulative variance explained, you can do the following:\n",
    "print(np.cumsum(variance_ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 8.1(b):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1(c)\n",
    "\n",
    "* (i)  Rerun the PCA with\n",
    "  the number of components you found in the previous question. Select the number of components with the argument\n",
    "  `n_components` in `PCA()`, e.g. `pca = PCA(n_components=13)`,\n",
    "  or, (for 95 % of the variance) `pca = PCA(n_components=0.95)`\n",
    "\n",
    "\n",
    "* (ii)  Obtain the scores, and make a plot of the scores for\n",
    "  principal component 1 (on the $x$-axis) and principal component 2 (on the $y$-axis).\n",
    "\n",
    "\n",
    "* (iii)  Do you see any grouping(s) (\"clusters\") in your scores plot?\n",
    "  Here, you can choose to color the scores according\n",
    "  to the cultivator (i.e., by using the values in the `target`\n",
    "  column in the data set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example plot for the scores:\n",
    "#fig, ax = plt.subplots()\n",
    "#ax.scatter(scores[:, 0], scores[:, 1])  # Plot scores on first and second PC\n",
    "# Example for coloring:\n",
    "#fig, ax = plt.subplots()\n",
    "#sns.scatterplot(x=scores[:, 0], y=scores[:, 1], hue=data_set[\"target\"], palette=\"muted\", ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 8.1(c):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1(d)\n",
    "Explore the loadings for your PCA model by plotting the\n",
    "loadings for the variables (on principal component 1 and\n",
    "principal component 2). Are any of the variables correlated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The loadings are stored as the transpose in pca.components_\n",
    "# The loadings for PC1 is:\n",
    "load1 = pca.components_[0, :]\n",
    "# The loadings for PC2 is:\n",
    "load2 = pca.components_[1, :]\n",
    "\n",
    "# Aternatively:\n",
    "# loadings = pca.components_.T\n",
    "# load1 = loadings[:, 0]\n",
    "# load2 = loadings[:, 1]\n",
    "\n",
    "# Example plot:\n",
    "fig, ax = plt.subplots()\n",
    "ax.axhline(y=0, ls=\":\", color=\"black\", lw=1)\n",
    "ax.axvline(x=0, ls=\":\", color=\"black\", lw=1)\n",
    "ax.set_xlim(-0.6, 0.6)\n",
    "ax.set_ylim(-0.6, 0.6)\n",
    "ax.set_aspect(\"equal\")\n",
    "\n",
    "# Just plotting the points:\n",
    "ax.scatter(load1, load2)\n",
    "\n",
    "# Adding text (name of variables):\n",
    "for i, variablei in enumerate(variables):\n",
    "    ax.text(load1[i], load2[i], variablei, fontsize=\"small\")\n",
    "\n",
    "# Here, you can probably make the plot easier to read. Maybe it should be bigger,\n",
    "# more colorful, with arrows, or maybe interactive like in the appedix in exercise 7?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 8.1(d):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1(e)\n",
    "Save the scores for the first two principal components.\n",
    "We will use this information in the next part\n",
    "of the exercise, where we will try to find clusters in our data.\n",
    "Saving the scores can be\n",
    "done with `pandas` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that the scores are in the matrix scores, you can\n",
    "# do the following to save the data (remember to limit to the first\n",
    "# two PCs):\n",
    "\n",
    "# 1. Create variable names for the principal components:\n",
    "pc_name = [f\"PC{i+1}\" for i in range(scores.shape[1])]\n",
    "# 2. Create a DataFrame from the scores:\n",
    "scores_data = pd.DataFrame(scores, columns=pc_name)\n",
    "scores_data[\"target\"] = data_set[\"target\"]\n",
    "# 3. Save the scores to a comma separated values-file:\n",
    "scores_data.to_csv(\"scores.csv\", index=False)\n",
    "\n",
    "# Note, here you could also save it into many other formats,\n",
    "# for instance, Excel:\n",
    "# scores_data.to_excel(\"scores.xlsx\", index=False)\n",
    "# or maybe as LaTeX for a report:\n",
    "# print(scores_data.style.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the code below, the file should be available here: [scores.csv](./scores.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us check that the file is present:\n",
    "my_data = pd.read_csv(\"scores.csv\")\n",
    "my_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8.2\n",
    "\n",
    "We will continue exploring the wine data set. We will pretend that we do not\n",
    "know that there are three cultivators in the data set, and we will investigate\n",
    "what the `KMeans` clustering method can tell us about it. For this\n",
    "exercise, it is a good idea to read through all points below before\n",
    "starting, since you will do the same analysis twice (first for the complete data set,\n",
    "and then for the PCA scores you saved in part [8.1(e)](#8.1(e)))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2(a)\n",
    "Outline the steps in the `KMeans` clustering algorithm.\n",
    "How can we use this algorithm without knowing the number of clusters in the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 8.2(a):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2(b)\n",
    "Run `KMeans` clustering on the wine data set (see the example code below).\n",
    "Here, you will have to\n",
    "select a set of numbers of clusters to look for (limit yourself to\n",
    "a maximum of 10 clusters).\n",
    "\n",
    "After running the clustering for your \n",
    "data, obtain and plot the following metrics:\n",
    "\n",
    "* (i) The sum of squared distances of the samples to\n",
    "  their closest cluster center as a function of the number of clusters considered.\n",
    "  \n",
    "  \n",
    "* (ii) The average silhouette value as a function of the number of clusters considered. (Note:\n",
    "  if you want to plot the distribution of silhouette values (not required here!), take\n",
    "  a look at this\n",
    "  [silhouette example](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_samples.html).)\n",
    "\n",
    "\n",
    "* (iii) The Gap statistic as a function of the number of clusters considered. (Skip this point if you are unable to install [gapstap](https://github.com/jmmaloney3/gapstat) - see the instructions below).\n",
    "\n",
    "Explain briefly (with a few lines of text) how you use these plots to identify the \"best\" number of clusters and use them to decide how many clusters there are in the wine data set.\n",
    "\n",
    "The cells below show Python code that runs the clustering and calculates the metrics to get you started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load the wine data set and run KMeans.\"\"\"\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "data_set = load_wine(as_frame=True)[\"frame\"]\n",
    "variables = [i for i in data_set.columns if i != \"target\"]\n",
    "X = scale(data_set[variables].to_numpy())\n",
    "# We scale the variance here (you have probably already\n",
    "# figured out this is a good idea during the PCA part in 8.1.)\n",
    "\n",
    "# Define a set of numbers of clusters to run KMeans for:\n",
    "number_of_clusters = [2, 3, 4, 5]\n",
    "# Set up variables for storing the results\n",
    "results = []  # Results for the clustering\n",
    "\n",
    "for i in number_of_clusters:\n",
    "    # Set up the KMeans method with i cluster centers:\n",
    "    cluster_k = KMeans(n_clusters=i, n_init=\"auto\")\n",
    "    # Run the clustering method:\n",
    "    cluster_k.fit(X)\n",
    "    # Store the results:\n",
    "    results.append(cluster_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `cluster_k` object contains the following results as attributes:\n",
    " * `cluster_centers_`: Coordinates of cluster centers.\n",
    " * `labels_`: Labels of each sample. Each sample is assigned to a cluster, and the label shows which cluster a sample belongs to. Note that these are just\n",
    "    labels - the actual numbers (0, 1, ...) do not have any meaning except being a label.\n",
    " * `inertia_`: Sum of squared distances of samples to their closest cluster center.\n",
    " * `n_iter_`: Number of iterations run.\n",
    " \n",
    "The silhouette values can be calculated with [sklearn.metrics.silhouette_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html), and\n",
    "the Gap statistic can be obtained via the [gapstat](https://github.com/jmmaloney3/gapstat) package. If you do not have this one installed, you can install it via:\n",
    "\n",
    "```bash\n",
    "pip install git+https://github.com/jmmaloney3/gapstat\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below to install gapstat:\n",
    "# !pip install git+https://github.com/jmmaloney3/gapstat\n",
    "from gapstat import gapstat_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is how you can calculate the metrics needed for the plots:\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"Clustering with {result.n_clusters} clusters:\")\n",
    "    sse = result.inertia_  # This is the sum of squared distances\n",
    "    print(f\"\\t- SSE = {sse}\")\n",
    "    silhouette = silhouette_score(\n",
    "        X, result.labels_\n",
    "    )  # Calculate average silhouette\n",
    "    print(f\"\\t- Silhouette = {silhouette}\")\n",
    "    gap = gapstat_score(X, result.labels_, k=result.n_clusters)\n",
    "    print(f\"\\t- GAP = {gap}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 8.2(b): What seems to be the best number of clusters to use?\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2(c)\n",
    "The clustering you just have done used all the variables. Visualizing the clusters (and potential regions for the different types) in\n",
    "this 13-dimensional space is difficult! We will therefore use the scores from the principal\n",
    "component analysis where we just stored two components. This means\n",
    "that we now have a 2-dimensional problem!\n",
    "\n",
    "Rerun the cluster analysis for the scores (again, vary the number of clusters)\n",
    "and make the same plots as you made in [8.2(b)](#8.2(b)). What is the\n",
    "best number of clusters to use now? Are your results different from the\n",
    "cluster analysis on the full data set, and how does it compare to\n",
    "what we know - that the samples come from three different cultivators of wine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 8.2(c):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2(d) Bonus: Showing the decision regions.\n",
    "Since we reduced the problem to two dimensions in [8.2(c)](#8.2(c)), we\n",
    "can plot the clusters. Here, we can also plot the so-called decision\n",
    "regions, which show the areas that belong to each cluster. Use the code below\n",
    "to show the decision regions for the best clustering you found in [8.2(c)](#8.2(c))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "X = data_set[\n",
    "    [\"alcohol\", \"flavanoids\"]\n",
    "].to_numpy()  # Replace with the 2D-scores you used in 8.2(c)\n",
    "cluster = KMeans(n_clusters=3, n_init=\"auto\").fit(\n",
    "    X\n",
    ")  # Replace with the best clustering from 8.2(c)\n",
    "\n",
    "y = cluster.labels_  # Use the assigned labeles\n",
    "\n",
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "\n",
    "# Show the samples:\n",
    "colors = []\n",
    "for i in sorted(set(y)):\n",
    "    scat = ax.scatter(X[y == i, 0], X[y == i, 1], label=i)\n",
    "    colors.append(scat.get_facecolors())  # Store colors, so we can reuse them\n",
    "# Draw the boundaries:\n",
    "cmap = matplotlib.colors.ListedColormap(colors)  # Use same colors\n",
    "DecisionBoundaryDisplay.from_estimator(\n",
    "    cluster,\n",
    "    X,\n",
    "    grid_resolution=200,\n",
    "    ax=ax,\n",
    "    cmap=cmap,\n",
    "    alpha=0.1,\n",
    ")\n",
    "ax.legend(title=\"Cluster no.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

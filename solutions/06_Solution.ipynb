{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise set 6\n",
    "\n",
    "> The first goal of this exercise is to analyze a fractional factorial design and use **confounding**, **deﬁning contrast(s)**, **generators** and the **resolution**.\n",
    ">\n",
    "> In connection with experimental design, we have seen two approaches for checking whether\n",
    "determined effects are important. These two approaches are based on creating a probability\n",
    "plot and performing ANOVA. The second goal of this exercise is to use these two approaches.\n",
    ">\n",
    "> Finally, we are also going to analyze the results of a more complex experimental design."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6.1\n",
    "\n",
    "You have recently started a new job in a chocolate bars company. A new and supposedly tasty\n",
    "chocolate is under development, and the main ingredients that you can vary are:\n",
    "\n",
    "\n",
    "*  The amount of cocoa ($A$).\n",
    "\n",
    "*  The number of pecan nuts ($B$).\n",
    "\n",
    "*  The amount of caramel ($C$).\n",
    "\n",
    "*  The amount of milk powder ($D$).\n",
    "\n",
    "*  The amount of sugar ($E$).\n",
    "\n",
    "*  The amount of vanilla ($F$).\n",
    "\n",
    "You are tasked with carrying out a maximum of $16$\n",
    "experiments (limited due to cost\n",
    "and time constraints) in which the best mixture of\n",
    "the main ingredients ($A$--$F$)\n",
    "is found. (\"Best\" is here determined by a tasting panel of $30$ people.)\n",
    "For this task, you decide on making a two-level\n",
    "fractional factorial design.\n",
    "\n",
    "\n",
    "### 6.1(a)\n",
    "How many experiments would you have to carry out in a full factorial design?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full factorial with 6 components:\n",
    "print(f\"Full factorial, 2 levels & 6 components = 2**6 = {2**6}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 6.1(a):\n",
    "With 6 factors in a two-level design, the number of experiments would be $2^6 = 64$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1(b)\n",
    "As stated, you can only carry out $16$ experiments. \n",
    "Explain what confounding is and why the set up with\n",
    "$16$ experiments will lead to confounding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 6.1(b):\n",
    "\n",
    "When we carry out a full factorial design, we do enough\n",
    "experiments so that we can determine the effect of all\n",
    "factors. When we\n",
    "do a fractional factorial design, we do too few experiments\n",
    "to uniquely determine all the effects. When we estimate effects,\n",
    "we then find that the expressions for some of the effects are\n",
    "identical and there is no way that we can distinguish between them.\n",
    "\n",
    "In the present case, we need $64$ experiments (see the [answer to 6.1(a)](#Your-answer-to-question-6.1(a):))\n",
    "but we can only do $16$. We therefore know that some of our factors\n",
    "will be confounded with each other.\n",
    "\n",
    "Luckily, we have some choice and we can, for instance, make it so\n",
    "that the main effects are confounded with higher-order interactions.\n",
    "This is useful as we often can neglect higher-order interactions\n",
    "compared to the main effects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1(c)\n",
    "After talking with the chocolate design team, you\n",
    "decide on the following generators:\n",
    "\n",
    "*  $E = ABC$.\n",
    "\n",
    "*  $F = BCD$.\n",
    "\n",
    "What is a defining contrast, and what are the\n",
    "defining contrasts in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 6.1(c):\n",
    "\n",
    "A defining contrast is a\n",
    "relation that can be used to deduce\n",
    "what variables are confounded.\n",
    "In this case, we decided on two generators which can be used\n",
    "to generate the defining contrasts,\n",
    "\n",
    "\n",
    "* $E = ABC \\implies E^2 = 1 = ABCE$.\n",
    "* $F = BCD \\implies F^2 = 1 = BCDF$.\n",
    "\n",
    "\n",
    "In addition, we have that,\n",
    "\n",
    "\\begin{equation*}\n",
    "1 \\times 1 = 1 = ABCE \\times BCDF = ADEF.\n",
    "\\end{equation*}\n",
    "  \n",
    "Thus, we have $3$ defining contrasts here:\n",
    "\n",
    "* $1 = ABCE$.\n",
    "* $1 = BCDF$.\n",
    "* $1 = ADEF$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1(d)\n",
    "Find the resolution for this design and write out the\n",
    "short-hand representation of the design on the\n",
    "form $2^{N-p}_R$. Are any of the main effects\n",
    "confounded with $2$-factor\n",
    "interactions? Hint: Consult the summary tables\n",
    "at [https://www.itl.nist.gov/div898/handbook/pri/section3/pri3347.htm](https://www.itl.nist.gov/div898/handbook/pri/section3/pri3347.htm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 6.1(d):\n",
    "\n",
    "We can find the present setup in the summary table as the setup with 6 factors that uses 16 experiments. This is a\n",
    "$2_\\text{IV}^{6-2}$ design. Since the resolution is 4, we know that the main effects are confounded with effects\n",
    "of order $4-1=3$ and higher, so no, they are not confounded with 2-factor interactions.\n",
    "We can also check this by hand (see the PDF-version of the solution)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1(e)\n",
    "Construct the design matrix for the current design but show only the columns for the main effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def design_matrix_16():\n",
    "    # Generate for A, B, C, D first:\n",
    "    ABCD = np.array(list(product([-1, 1], repeat=4)))\n",
    "    A = ABCD[:, 0]\n",
    "    B = ABCD[:, 1]\n",
    "    C = ABCD[:, 2]\n",
    "    D = ABCD[:, 3]\n",
    "    # Use the generators for getting E and F\n",
    "    # E = ABC:\n",
    "    E = A * B * C\n",
    "    # F = BCD:\n",
    "    F = B * C * D\n",
    "\n",
    "    names = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"]\n",
    "\n",
    "    design = {}\n",
    "\n",
    "    for key, val in zip(names, [A, B, C, D, E, F]):\n",
    "        design[key] = [\"+\" if i > 0 else \"-\" for i in val]\n",
    "    design = pd.DataFrame(design)\n",
    "    return design\n",
    "\n",
    "design_matrix_16()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 6.1(e):\n",
    "\n",
    "(See the table above.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1(f)\n",
    "Another member of your team suggests doing just $8$ experiments\n",
    "as this will cut time and cost.\n",
    "Do you think this is a good idea? Why/why not? What would\n",
    "the design matrix look like in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def design_matrix_8():\n",
    "    # Generate for A, B, C, D first:\n",
    "    ABC = np.array(list(product([-1, 1], repeat=3)))\n",
    "    A = ABC[:, 0]\n",
    "    B = ABC[:, 1]\n",
    "    C = ABC[:, 2]\n",
    "    # Use generators for getting E, E and F\n",
    "    # D = AB:\n",
    "    D = A * B\n",
    "    # E = AC:\n",
    "    E = A * C\n",
    "    # F = BC:\n",
    "    F = B * C\n",
    "\n",
    "    names = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"]\n",
    "\n",
    "    design = {}\n",
    "\n",
    "    for key, val in zip(names, [A, B, C, D, E, F]):\n",
    "        design[key] = [\"+\" if i > 0 else \"-\" for i in val]\n",
    "    design = pd.DataFrame(design)\n",
    "    return design\n",
    "\n",
    "design_matrix_8()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 6.1(f):\n",
    "\n",
    "Consulting the [summary tables](https://www.itl.nist.gov/div898/handbook/pri/section3/eqns/2to6m3.txt) we\n",
    "find that the design with 8 experiments is a $2_\\text{III}^{6-3}$ setup. In this case, the main effects\n",
    "are confounded with second order effects. In general, we want our main effects to not be confounded with\n",
    "interactions lower than $3$-factor interactions. We would then\n",
    "advise against doing only $8$ experiments, and keep to the\n",
    "original plan with $16$ experiments to be able to better\n",
    "assess the main effects.\n",
    "\n",
    "The design matrix is shown above, note that you might get a different table, depending on the\n",
    "generators you have used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6.2\n",
    "\n",
    "After running a set of experiments, you determine the effects\n",
    "given in Table 1 for $4$ factors: A, B, C, and D.\n",
    "Use a normal probability plot to identify the important effects among\n",
    "the ones listed in this table.\n",
    "\n",
    "\n",
    "**Table 1:** *Effects determined in a set of experiments. Data for [Exercise 6.2](#Exercise-6.2)*\n",
    "\n",
    "\n",
    "| A    | B    | C     | D     | AB  | AC   | AD   | BC    | BD   | CD    | ABC   | ACD   | BCD   | ABCD  | ABD   |\n",
    "|:-----|:-----|:------|:------|:----|:-----|:-----|:------|:-----|:------|:------|:------|:------|:------|:------|\n",
    "| -8.0 | 24.0 | -2.25 | -5.50 | 1.0 | 0.75 | 0.00 | -1.25 | 4.50 | -0.25 | -0.75 | -0.25 | -0.75 | -0.25 | 0.50  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns  # Styling of plots\n",
    "\n",
    "%matplotlib notebook\n",
    "sns.set_theme(style=\"ticks\", context=\"notebook\", palette=\"muted\")\n",
    "\n",
    "effects = [\n",
    "    (\"A\", -8.00),\n",
    "    (\"B\", 24.00),\n",
    "    (\"C\", -2.25),\n",
    "    (\"D\", -5.50),\n",
    "    (\"AB\", 1.00),\n",
    "    (\"AC\", 0.75),\n",
    "    (\"AD\", 0.00),\n",
    "    (\"BC\", -1.25),\n",
    "    (\"BD\", 4.50),\n",
    "    (\"CD\", -0.25),\n",
    "    (\"ABC\", -0.75),\n",
    "    (\"ACD\", -0.25),\n",
    "    (\"BCD\", -0.75),\n",
    "    (\"ABCD\", -0.25),\n",
    "    (\"ABD\", 0.50),\n",
    "]\n",
    "\n",
    "table1 = pd.DataFrame(effects, columns=[\"factor\", \"effect\"])\n",
    "\n",
    "# Create a normal probability plot with statsmodels:\n",
    "plot = sm.ProbPlot(table1[\"effect\"].to_numpy(), fit=False)\n",
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "plot.qqplot(line=\"q\", ax=ax)\n",
    "\n",
    "x = plot.theoretical_quantiles  # The expected locations\n",
    "y = plot.sample_quantiles  # The sorted effects\n",
    "\n",
    "# Also get the name of factors from sorting the table:\n",
    "sorted_factors = table1.sort_values(\"effect\")\n",
    "for xi, yi, factor in zip(x, y, sorted_factors[\"factor\"]):\n",
    "    ax.text(\n",
    "        xi,\n",
    "        yi,\n",
    "        factor,\n",
    "        va=\"center\",\n",
    "        ha=\"center\",\n",
    "        bbox={\n",
    "            \"facecolor\": \"w\",\n",
    "            \"edgecolor\": \"#4C72B0\",\n",
    "            \"boxstyle\": \"round\",\n",
    "            \"lw\": 1.5,\n",
    "        },\n",
    "        fontsize=\"xx-small\"\n",
    "    )\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 6.2:\n",
    "\n",
    "In the normal probability plot generated above, four factors deviate significantly from the other effects,\n",
    "(and the straight line): A, D, BD, and B. We thus conclude\n",
    "that these four factors are the important factors in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6.3\n",
    "\n",
    "**Only do this exercise if you have time, or did not do [Exercise 6.2](#Exercise-6.2).**\n",
    "\n",
    "From a $2^2$ factorial experiment replicated three times you have obtained\n",
    "the data given in Table 2. We use here a short-hand notation\n",
    "for the $4$ possible combinations of the variables: $(1)$, $a$, $b$, and $ab$.\n",
    "In this notation, $(1)$ is the experiment where all factors were at their low levels. For the other cases, the absence of a letter means that the corresponding factor was at a low level, and\n",
    "the presence of a letter indicates that the corresponding factor was at a high level (e.g., \"$a$\" is the\n",
    "same as saying that factor A was at the high level and B at the low level).\n",
    "\n",
    "**Table 2:** *Results from a $2^2$ factorial experiment, repeated $3$ times. Data for [Exercise 6.3](#Exercise-6.3)*\n",
    "\n",
    "|**Experiment** | **Replicate 1** | **Replicate 2** | **Replicate 2** |\n",
    "|:---:|:---:|:---:|:---:|\n",
    "|$(1)$ | $9$  | $10$ | $11$ |\n",
    "|$a$   | $30$ | $31$ | $29$ |\n",
    "|$b$   | $19$ | $20$ | $21$ |\n",
    "|$ab$  | $5$  | $6$  | $4$  |\n",
    "\n",
    "\n",
    "### 6.3(a)\n",
    "Calculate the effects (A, B, and AB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"(1)\": np.array([9, 10, 11]),\n",
    "    \"a\": np.array([30, 31, 29]),\n",
    "    \"b\": np.array([19, 20, 21]),\n",
    "    \"ab\": np.array([5, 6, 4]),\n",
    "}\n",
    "\n",
    "data_values = np.array(\n",
    "    [\n",
    "        [9, 10, 11],\n",
    "        [30, 31, 29],\n",
    "        [19, 20, 21],\n",
    "        [5, 6, 4],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this notation:\n",
    "# (1): A=-, B=-, AB=+\n",
    "# a: A=+, B=-, AB=-\n",
    "# b: A=-, B=+, AB=-\n",
    "# ab: A=+, B=+, AB=+\n",
    "\n",
    "# The mean response is:\n",
    "mean_data = {key: np.mean(val) for key, val in data.items()}\n",
    "# And the effects are:\n",
    "effect = {}\n",
    "effect[\"A\"] = 0.5 * (\n",
    "    (mean_data[\"a\"] + mean_data[\"ab\"]) - (mean_data[\"(1)\"] + mean_data[\"b\"])\n",
    ")\n",
    "effect[\"B\"] = 0.5 * (\n",
    "    (mean_data[\"b\"] + mean_data[\"ab\"]) - (mean_data[\"(1)\"] + mean_data[\"a\"])\n",
    ")\n",
    "effect[\"AB\"] = 0.5 * (\n",
    "    (mean_data[\"(1)\"] + mean_data[\"ab\"]) - (mean_data[\"b\"] + mean_data[\"a\"])\n",
    ")\n",
    "print(effect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 6.3(a):\n",
    "The average effects are (see the calculation above):\n",
    "\n",
    "* A: 2.5\n",
    "* B: -7.5\n",
    "* AB: -17.5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3(b)\n",
    "Use ANOVA to investigate which effects are important in this case.\n",
    "Use a significance level of $\\alpha = 0.01$. For\n",
    "a significance level of $\\alpha = 0.01$, the relevant critical\n",
    "$f$-value is $f_{\\alpha=0.01}(1, 8) = 11.259$ with $1$ and $8$ degrees\n",
    "of freedom. (Note: The numbers in Table 2\n",
    "are the same as for the example on\n",
    "page 96 in the textbook.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the contrasts first, since we already have the effects, we can get it as:\n",
    "k = 3  # 3 repeated experiments\n",
    "N = 2  # 2 factors.\n",
    "denom = k * 2**(N-1)\n",
    "contrasts = {key: val*denom for key, val in effect.items()}\n",
    "contrasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, find the sum of squares:\n",
    "sum_of_squares = {key: val * val / (k*2**N) for key, val in contrasts.items()}\n",
    "sum_of_squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And total sum of squares:\n",
    "SST = np.sum((data_values - data_values.mean()) ** 2)\n",
    "print(f\"SST = {SST}\")\n",
    "# And the SSE:\n",
    "SSE = SST - sum([val for _, val in sum_of_squares.items()])\n",
    "print(f\"SSE = {SSE}\")\n",
    "df_sse = 2**2 * (k - 1)\n",
    "print(\"Degrees of freedom SSE:\", df_sse)\n",
    "sigma = SSE / df_sse  # Estimate for variance from SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "# Calculate f-values and p-values:\n",
    "for factor, ssi in sum_of_squares.items():\n",
    "    fval = ssi / sigma\n",
    "    pval = 1 - scipy.stats.f.cdf(fval, 1, df_sse)\n",
    "    print(f\"ANOVA for: {factor}\")\n",
    "    print(f\"\\tf = {fval}\")\n",
    "    print(f\"\\tp = {pval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out some critical f-values at different significance levels:\n",
    "print(\"\\nCritical f-values:\")\n",
    "for alpha in (0.001, 0.01, 0.05, 0.1):\n",
    "    f_critical = scipy.stats.f.ppf(1 - alpha, 1, df_sse)\n",
    "    print(f\"\\tAt alpha {alpha:5.3f}: f-critical = {f_critical:6.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 6.3(b):\n",
    "\n",
    "At the given significance level (0.01), all effects are significant. This is also reflected\n",
    "in the calculated $p$-values. All of these are small, which means that if the effects\n",
    "are *not significant*, then the probability of observing what we have observed is small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6.4\n",
    "\n",
    "A chemical company is producing the\n",
    "compound B from compound A in the reaction $\\text{A} \\to \\text{B}$\n",
    "and the company is running a project to \n",
    "maximize the yield of compound B.\n",
    "\n",
    "The yield for the conversion from A to B is low\n",
    "at low temperatures. The yield increases at\n",
    "higher temperatures, but\n",
    "a competing secondary reaction transforms B into C, an unwanted product.\n",
    "The secondary reaction, $\\text{A} \\to \\text{B} \\to \\text{C}$,\n",
    "is more prominent at higher temperatures, especially when the reaction is allowed to run for a long time.\n",
    "To determine what combinations of temperature and\n",
    "reaction time result in the best yield, the company has\n",
    "carried out a set of experiments. The experimental space and the experimental points\n",
    "are shown in the figure below (in the Python cell).\n",
    "\n",
    "Here, the company first\n",
    "defined a feasibility region (based on chemical knowledge)\n",
    "and then created a *D*-optimal\n",
    "design for a cubic model. The experimental results are given\n",
    "in the Excel file [Data/yield.xls](Data/yield.xls). Use the experimental data to create a cubic model and locate the settings (temperature & time)\n",
    "that gives the highest yield."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code to get you started:\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns  # Styling of plots\n",
    "\n",
    "%matplotlib notebook\n",
    "sns.set_theme(style=\"ticks\", context=\"notebook\", palette=\"muted\")\n",
    "\n",
    "data = pd.read_excel(\"Data/yield.xls\")  # you might have to first do: pip install openpyxl\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot experimental region\n",
    "from matplotlib.patches import Polygon\n",
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "ax.set(xlabel=\"Time (s)\", ylabel=\"Temperature (K)\")\n",
    "points = [\n",
    "    (660, 520),\n",
    "    (360, 529),\n",
    "    (360, 550), \n",
    "    (420, 550),\n",
    "    (720, 523),\n",
    "    (720, 520),\n",
    "]\n",
    "region = Polygon(points, edgecolor=\"k\", facecolor=\"0.95\", linestyle=\"--\", label=\"Feasible settings\")\n",
    "ax.add_artist(region)\n",
    "ax.scatter(data[\"Time (s)\"], data[\"Temperature (K)\"], label=\"Experimental points\")\n",
    "ax.legend()\n",
    "ax.set_title(\"Experimental space\", loc=\"left\")\n",
    "sns.despine(fig=fig)\n",
    "fig.savefig(\"space1.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate all the possible terms for a cubic polynomial can be a hassle (and it is easy to\n",
    "forget some terms!). Here we would need to have: time, temperature, time², temperature², time × temperature, time³, temperature³, time × temperature² and time² × temperature.\n",
    "\n",
    "Below is some Python code that will do this for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are some hints for creating the model:\n",
    "# 1) We can transform the variables to -1, 1 with a MinMaxScaler from sklearn.\n",
    "# 2) We can generate all cubic terms for a polynomial with PolynomialFeatures from sklearn\n",
    "# 3) We can join these two operations with a so-called pipeline.\n",
    "# Here is an example:\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# We do not need to use the scaler here, and we do not need the pipeline.\n",
    "# The pipeline is convenient if we want to redo this preprocessing on new data\n",
    "# (for instance, if we want to use the model in the future for predictions).\n",
    "# The MinMaxScaler is not really needed, but it can make it easier to compare\n",
    "# regression coefficients.\n",
    "\n",
    "X_raw = data[[\"Time (s)\", \"Temperature (K)\"]]\n",
    "y = data[\"Yield\"]\n",
    "\n",
    "# Make a pipeline for preprocessing (first scale Time & Temperature, the add polynomial)\n",
    "preprocess = Pipeline(\n",
    "    steps=[\n",
    "        (\"minmax-scale\", MinMaxScaler(feature_range=(-1, 1))),  # Scale to -1 to 1\n",
    "        (\"cubic\", PolynomialFeatures(degree=3, include_bias=True)),  # Add x1, x1^2, x2, x1*x2, ...\n",
    "        #include_bias = True = add also a constant term\n",
    "    ]\n",
    ")\n",
    "preprocess.fit(X_raw)\n",
    "# The line above is fitting the pipeline to the data (this sets up the scaler and polynomial transformation).\n",
    "# This does not apply it yet!\n",
    "\n",
    "X = pd.DataFrame(\n",
    "    preprocess.transform(X_raw),  # Transform the data = scale and make the polynomial\n",
    "    columns=preprocess.get_feature_names_out(),  # Store the variables\n",
    ")\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here: fit the polynomial and locate the maximum (you can do this graphically)\n",
    "import statsmodels.api as sm\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit above seems pretty good, but we note that two of the terms seems to not be needed (they have a high $p$-value). Let us remake the model without these two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = X.drop(columns=[\"Time (s)^3\", \"Time (s)^2 Temperature (K)\"], inplace=False)\n",
    "model2 = sm.OLS(y, X2).fit()\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model found above seems to fit the data very well. Let us use to to draw a contour diagram to show\n",
    "the yield. To do this, we have to evaluate the yield on a grid of time and temperature points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.linspace(350, 725, 100)  # 50 points \n",
    "temperature = np.linspace(518, 552, 100)  # 50 points\n",
    "\n",
    "# Create the grid (this is for plotting) as all combinations of time and temperature\n",
    "time_grid, temperature_grid = np.meshgrid(time, temperature)  # 100 x 100 points\n",
    "# To evaluate on the grid, we first make a new table with all the points, here\n",
    "# we convert the 2D grid to a 1D list of points with flatten()\n",
    "X_evaluate = pd.DataFrame(\n",
    "    np.column_stack((time_grid.flatten(), temperature_grid.flatten())),\n",
    "    columns=[\"Time (s)\", \"Temperature (K)\"],\n",
    ")\n",
    "# Transform to the cubic model:\n",
    "X_evaluate = pd.DataFrame(\n",
    "    preprocess.transform(X_evaluate),  # Transform the data = scale and make the polynomial\n",
    "    columns=preprocess.get_feature_names_out(),  # Store the variables\n",
    ")\n",
    "X_evaluate.drop(columns=[\"Time (s)^3\", \"Time (s)^2 Temperature (K)\"], inplace=True)\n",
    "# Evaluate the model on the grid:\n",
    "y_hat = model2.predict(X_evaluate)\n",
    "y_hat_grid = y_hat.to_numpy().reshape(time_grid.shape)\n",
    "\n",
    "y_hat_grid[y_hat_grid < 0] = float(\"nan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can plot it:\n",
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "cont = ax.contourf(time_grid, temperature_grid, y_hat_grid, levels=30)\n",
    "ax.set(xlabel=\"Time (s)\", ylabel=\"Temperature (K)\")\n",
    "points = [\n",
    "    (660, 520),\n",
    "    (360, 529),\n",
    "    (360, 550),\n",
    "    (420, 550),\n",
    "    (720, 523),\n",
    "    (720, 520),\n",
    "]\n",
    "region = Polygon(points, edgecolor=\"k\", facecolor=\"None\", linestyle=\"-\", label=\"Feasible settings\")\n",
    "ax.add_artist(region)\n",
    "ax.legend()\n",
    "cbar = fig.colorbar(cont, ax=ax)\n",
    "cbar.ax.set_title(\"Yield\")\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find the optimum, it is here maybe easiest to just pick out the largest value from the grid above.\n",
    "# We can also try to do it numerically. It is then easiest to define a new function:\n",
    "\n",
    "def evaluate_model(x):\n",
    "    time, temperature = x\n",
    "    X = pd.DataFrame({\"Time (s)\": [time], \"Temperature (K)\": [temperature]})\n",
    "    X = pd.DataFrame(\n",
    "        preprocess.transform(X),\n",
    "        columns=preprocess.get_feature_names_out(),\n",
    "    )\n",
    "    X.drop(columns=[\"Time (s)^3\", \"Time (s)^2 Temperature (K)\"], inplace=True)\n",
    "    return -model2.predict(X).to_numpy()  # Scipy will minimize something for us...\n",
    "\n",
    "evaluate_model((360, 542.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import Bounds, minimize\n",
    "bounds = Bounds([360, 520], [720, 550])\n",
    "# These bounds are not correct, we could efine the region with equations, but that is a lot\n",
    "# of work, and judging from the drawing above, we are not going to end up outside the feasible\n",
    "# region.\n",
    "x0 = (360, 542.5)  # Guess from the figure\n",
    "res = minimize(evaluate_model, x0, method='trust-constr', options={'verbose': 1}, bounds=bounds)\n",
    "yield_max = -evaluate_model(res.x)\n",
    "print(f\"Optimum at {res.x}, yield = {yield_max}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "cont = ax.contourf(time_grid, temperature_grid, y_hat_grid, levels=30)\n",
    "ax.set(xlabel=\"Time (s)\", ylabel=\"Temperature (K)\")\n",
    "points = [\n",
    "    (660, 520),\n",
    "    (360, 529),\n",
    "    (360, 550),\n",
    "    (420, 550),\n",
    "    (720, 523),\n",
    "    (720, 520),\n",
    "]\n",
    "region = Polygon(points, edgecolor=\"k\", facecolor=\"None\", linestyle=\"-\", label=\"Feasible settings\")\n",
    "ax.add_artist(region)\n",
    "cbar = fig.colorbar(cont, ax=ax)\n",
    "cbar.ax.set_title(\"Yield\")\n",
    "ax.scatter(res.x[0], res.x[1], marker=\"*\", label=\"Optimum\", color=\"k\", s=100)\n",
    "ax.legend()\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 6.4: What settings gives you the highest yield?\n",
    "Within the constraints: A time of 360 s and a temperature of 543 K will yield the highest.\n",
    "\n",
    "If we think outside the box, the model indicates that an even shorter reaction time (maybe 300 s) and a slightly higher temperature (545 K) can yield even better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

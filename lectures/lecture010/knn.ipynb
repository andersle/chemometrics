{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN classifier\n",
    "\n",
    "This is just a short example on how we can create a [k-Nearest neighbors](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) classifier and display the\n",
    "confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import numpy as np\n",
    "plt.style.use('seaborn-notebook')\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = load_breast_cancer()\n",
    "data = pd.DataFrame(data_set['data'], columns=data_set['feature_names'])\n",
    "data['target'] = data_set['target']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = {0: 'Malignant', 1: 'Benign'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We select just two of the variables so we can plot things in 2D:\n",
    "variables = ['worst radius', 'mean texture']\n",
    "X = data[variables].to_numpy()\n",
    "y = data['target'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a kNN classifier:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=1)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots(constrained_layout=True)\n",
    "# Predict for many points to display the decision boundaries:\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.05),\n",
    "                     np.arange(y_min, y_max, 0.05))\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "colors = [\n",
    "    [1., 0.49803922, 0.05490196],\n",
    "    [0.12156863, 0.46666667, 0.70588235],\n",
    "]\n",
    "cmap = ListedColormap(colors)\n",
    "ax1.contourf(xx, yy, Z, alpha=0.5, vmin=0, vmax=1, cmap=cmap)\n",
    "\n",
    "ax1.scatter(X[y==1, 0], X[y==1, 1], label=class_names[1], color=colors[1])\n",
    "ax1.scatter(X[y==0, 0], X[y==0, 1], label=class_names[0], color=colors[0])\n",
    "\n",
    "ax1.set_title(f'kNN with n_neighbors = {clf.n_neighbors}')\n",
    "ax1.legend()\n",
    "ax1.set_xlabel(variables[0]);\n",
    "ax1.set_ylabel(variables[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix:\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, stratify=y\n",
    ")\n",
    "clf = KNeighborsClassifier(n_neighbors=1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_hat = clf.predict(X_test)\n",
    "fig = ConfusionMatrixDisplay.from_estimator(clf, X_test, y_test, display_labels=['Malignant', 'Benign'])\n",
    "fig.ax_.set_title(f'kNN with n_neighbors = {clf.n_neighbors}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us use cross-validation to find the best parameters:\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    ")\n",
    "\n",
    "X = data[variables].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, stratify=y\n",
    ")\n",
    "\n",
    "clf = KNeighborsClassifier()\n",
    "parameters = [{'n_neighbors': range(1, 11)}]\n",
    "grid = GridSearchCV(\n",
    "    clf,\n",
    "    parameters,\n",
    "    cv=5,\n",
    "    scoring='precision',\n",
    "    return_train_score=True,\n",
    ")\n",
    "grid.fit(X_train, y_train)\n",
    "print('Best parameters for knn:', grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots(constrained_layout=True)\n",
    "ax1.errorbar(\n",
    "    parameters[0]['n_neighbors'],\n",
    "    grid.cv_results_['mean_test_score'],\n",
    "    yerr=grid.cv_results_['std_test_score'],\n",
    "    marker='o', markersize=14\n",
    ")\n",
    "ax1.set(xlabel='n_neighbors', ylabel=grid.scoring)\n",
    "ax1.set_title('Optimizing n_neighbors for a k-nearest neighbors classifier');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ConfusionMatrixDisplay.from_estimator(\n",
    "    grid.best_estimator_, X_test, y_test, display_labels=['Malignant', 'Benign']\n",
    ")\n",
    "fig.ax_.set_title(f'kNN with n_neighbors = {grid.best_estimator_.n_neighbors}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

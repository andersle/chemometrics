{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b288ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import black\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load(\n",
    "    lab=False,\n",
    "    line_length=79,\n",
    "    verbosity=\"DEBUG\",\n",
    "    target_version=black.TargetVersion.PY313,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8aaf14",
   "metadata": {},
   "source": [
    "# Solution to exercise set 3: \n",
    "\n",
    "\n",
    "**Learning Objectives:**\n",
    "\n",
    "After completing this exercise set, you will be able to:\n",
    "\n",
    "- Calculate effects from full and fractional factorial experimental designs.\n",
    "- Create and interpret normal probability plots to assess the importance of effects.\n",
    "- Create least squares models from experimental design results and use them to estimate effects.\n",
    "\n",
    "\n",
    "**To get the exercise approved, complete the following problems:**\n",
    "\n",
    "- [3.2(a)](#3.2(a)), [3.2(b)](#3.2(b)), and [3.2(c)](#3.2(c)): To show that you can analyse a full factorial design, including creating the normal probability plot.\n",
    "\n",
    "- [3.3(b)](#3.3(b)) and [3.3(c)](#3.3(c)): To show that you can calculate effects from a fractional factorial design and create a least squares model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1aea00",
   "metadata": {},
   "source": [
    "## Exercise 3.1\n",
    "\n",
    "> **Note:** This problem is more of an example. The code given here will show you how to create a normal probability plot. Run the code, create the plot and interpret it.\n",
    "\n",
    "\n",
    "After running a set of experiments, you determine the effects\n",
    "given in the table below for 4 factors: A, B, C, and D:\n",
    "\n",
    "\n",
    "\n",
    "| A    | B    | C     | D     | AB  | AC   | AD   | BC    | BD   | CD    | ABC   | ACD   | BCD   | ABCD  | ABD   |\n",
    "|:-----|:-----|:------|:------|:----|:-----|:-----|:------|:-----|:------|:------|:------|:------|:------|:------|\n",
    "| -8.0 | 24.0 | -2.25 | -5.50 | 1.0 | 0.75 | 0.00 | -1.25 | 4.50 | -0.25 | -0.75 | -0.25 | -0.75 | -0.25 | 0.50  |\n",
    "\n",
    "\n",
    "\n",
    "**Task:** Use the example code below to create a normal probability plot. Interpret this plot and decide what the important effects are in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53d6598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code to create a probability plot.\n",
    "\n",
    "# We collect the effects from the table above:\n",
    "import pandas as pd\n",
    "\n",
    "effects = [\n",
    "    (\"A\", -8.00),\n",
    "    (\"B\", 24.00),\n",
    "    (\"C\", -2.25),\n",
    "    (\"D\", -5.50),\n",
    "    (\"AB\", 1.00),\n",
    "    (\"AC\", 0.75),\n",
    "    (\"AD\", 0.00),\n",
    "    (\"BC\", -1.25),\n",
    "    (\"BD\", 4.50),\n",
    "    (\"CD\", -0.25),\n",
    "    (\"ABC\", -0.75),\n",
    "    (\"ACD\", -0.25),\n",
    "    (\"BCD\", -0.75),\n",
    "    (\"ABCD\", -0.25),\n",
    "    (\"ABD\", 0.50),\n",
    "]\n",
    "table1 = pd.DataFrame(effects, columns=[\"factor\", \"effect\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77584876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the probability plot using statsmodels:\n",
    "from matplotlib import pyplot as plt  # Needed for plotting\n",
    "import seaborn as sns  # Used to style plots for a Jupyter Notebook\n",
    "import statsmodels.api as sm  # Needed to create the probability plot\n",
    "\n",
    "sns.set_context(\"notebook\")\n",
    "\n",
    "# Create the probability plot object using the \"effect\" column from table1.\n",
    "# By default, ProbPlot compares the data to a standard normal distribution.\n",
    "# This can also be selected by setting fit=False.\n",
    "plot = sm.ProbPlot(table1[\"effect\"], fit=False)\n",
    "\n",
    "# Create a figure and an axes object. This allows for more control over the plot,\n",
    "# such as setting axis labels, titles, and so on. fig represents the entire figure,\n",
    "# while ax represents the specific axes where the plot will be drawn.\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Generate the plot and draw it on the specified axes (ax).\n",
    "_ = plot.qqplot(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1244ff4b",
   "metadata": {},
   "source": [
    "The plot above is somewhat hard to read since we do not see the names of the effects.\n",
    "Let us try to make it easier to read by adding text showing the factor names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a057f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure:\n",
    "fig, ax = plt.subplots()\n",
    "plot = sm.ProbPlot(table1[\"effect\"], fit=False)\n",
    "plot.qqplot(ax=ax)\n",
    "# Extract the theoretical and sample quantiles from the ProbPlot object.\n",
    "# These will be used as the x and y coordinates for our scatter plot.\n",
    "x = (\n",
    "    plot.theoretical_quantiles\n",
    ")  # Quantiles of the standard normal distribution.\n",
    "y = plot.sample_quantiles  # Ordered (sorted) values of the 'effect' column.\n",
    "\n",
    "# Get the factor names, sorted according to the 'effect' values.  This ensures\n",
    "# the labels are placed correctly corresponding to the sorted effects on the plot.\n",
    "sorted_factors = table1.sort_values(\"effect\")\n",
    "\n",
    "# Add text labels to the plot, one for each data point.\n",
    "# We iterate through the x (theoretical quantiles), y (sample quantiles), and\n",
    "# factor names simultaneously using zip().\n",
    "for i, (xi, yi, factor) in enumerate(zip(x, y, sorted_factors[\"factor\"])):\n",
    "    # Put the text slightly away from the points. Offset determines\n",
    "    # how far away the points will be. You can experiment with values\n",
    "    # different from 3.\n",
    "    offset = 3 if i % 2 == 0 else -3\n",
    "    # Use annotate to show the text with a line connecting to the effect:\n",
    "    ax.annotate(\n",
    "        factor,  # Use the factor text\n",
    "        (xi, yi),  # Point we are adding text to\n",
    "        xytext=(\n",
    "            xi,\n",
    "            yi + offset,\n",
    "        ),  # Shift the text along the y-axis to make it more visible\n",
    "        ha=\"center\",  # Center the text horizontally on the point\n",
    "        va=\"center\",  # Center the text vertically on the point\n",
    "        arrowprops={\n",
    "            \"arrowstyle\": \"-\"\n",
    "        },  # Add a line connecting the text to the point\n",
    "        fontsize=\"small\",  # Make the font slightly smaller\n",
    "    )\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6fb54e",
   "metadata": {},
   "source": [
    "In plots like the one above, data from a normal distribution with a mean of zero and a variance $\\sigma^2$ will tend to fall along a straight line passing through the origin, with a slope equal to $\\sigma$. It is therefore helpful to add a reference line to the plot to aid in visual assessment.\n",
    "\n",
    "When checking if numbers are from a standard normal distribution (with $\\sigma = 1$), adding the line $x=y$ to the plot is common. This line represents the expected location of points from a standard normal distribution. In the code above this can be achieved by using the `line=\"45\"` option:\n",
    "\n",
    "```python\n",
    "plot.qqplot(ax=ax, line=\"45\")\n",
    "```\n",
    "In this case, fitting a line through the observed data points can be helpful. A challenge is that potential outliers (which might represent important effects) can influence the fitted line. `statsmodels` offers a robust option based on fitting through quartiles. This can be achieved using the `line=\"q\"` option\n",
    "\n",
    "```python\n",
    "plot.qqplot(ax=ax, line=\"q\")\n",
    "```\n",
    "\n",
    "In some cases, even `line=\"q\"` might be affected by outliers. A second option is to **use your own judgment to identify the linear region** and potentially fit a line manually, excluding any obvious outliers. This visual inspection might be easier to perform on a plot without added annotations (effect names), as those can sometimes distract from the overall pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c219cbb3",
   "metadata": {},
   "source": [
    "#### Your answer to question 3.1: What are the important effects?\n",
    "\n",
    "The important effects are:\n",
    "* A\n",
    "* D\n",
    "* BD\n",
    "* B\n",
    "\n",
    "This is based on manually identifying the linear region in the figure below. C might be a borderline case, but it is close to the linear region identified in the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac398d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure:\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plot = sm.ProbPlot(table1[\"effect\"], fit=False)\n",
    "plot.qqplot(ax=ax)\n",
    "x = plot.theoretical_quantiles\n",
    "y = plot.sample_quantiles\n",
    "\n",
    "sorted_factors = table1.sort_values(\"effect\")\n",
    "\n",
    "# Use the 11 smallest points as the linear region:\n",
    "idx = np.argsort(abs(y))\n",
    "xin = x[idx[:11]]\n",
    "yin = y[idx[:11]]\n",
    "p = np.polyfit(xin, yin, deg=1)\n",
    "line = np.polyval(p, x)\n",
    "\n",
    "ax.plot(x, line, label=\"Linear trend\", color=\"red\")\n",
    "\n",
    "for i, (xi, yi, factor) in enumerate(zip(x, y, sorted_factors[\"factor\"])):\n",
    "    diff_to_line = yi - np.polyval(p, xi)\n",
    "    if abs(diff_to_line) < 2:\n",
    "        continue\n",
    "    offset = 2\n",
    "    ax.annotate(\n",
    "        factor,\n",
    "        (xi, yi),\n",
    "        xytext=(xi, yi + offset),\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        arrowprops={\"arrowstyle\": \"-\"},\n",
    "        fontsize=\"small\",\n",
    "    )\n",
    "ax.legend(loc=\"upper left\")\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc6d39d",
   "metadata": {},
   "source": [
    "## Exercise 3.2\n",
    "\n",
    "To optimize the filtration rate of a chemical product manufactured in a pressure\n",
    "vessel, a 2⁴ factorial experiment was conducted in a pilot plant.\n",
    "The experiment investigated the effects of temperature (A), pressure (B),\n",
    "formaldehyde concentration (C), and stirring rate (D), each at two levels.\n",
    "\n",
    "The goal was to determine how these factors influence filtration rate (volume filtered per unit time), aiming to maximize it for increased throughput and potentially lower costs.\n",
    "\n",
    "Results from this experimental design can be found below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8e6e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data32 = {\n",
    "    \"A\": [-1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1],\n",
    "    \"B\": [-1, -1, 1, 1, -1, -1, 1, 1, -1, -1, 1, 1, -1, -1, 1, 1],\n",
    "    \"C\": [-1, -1, -1, -1, 1, 1, 1, 1, -1, -1, -1, -1, 1, 1, 1, 1],\n",
    "    \"D\": [-1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    \"Filtration Rate (L/hour)\": [\n",
    "        45,\n",
    "        71,\n",
    "        48,\n",
    "        65,\n",
    "        68,\n",
    "        60,\n",
    "        80,\n",
    "        65,\n",
    "        43,\n",
    "        100,\n",
    "        45,\n",
    "        104,\n",
    "        75,\n",
    "        86,\n",
    "        70,\n",
    "        96,\n",
    "    ],\n",
    "}\n",
    "table32 = pd.DataFrame(data32)\n",
    "table32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6b75ae",
   "metadata": {},
   "source": [
    "### 3.2(a)\n",
    "\n",
    "Calculate all main effects and interaction effects (second-, third-, and fourth-order). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b085f369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first add all the interaction effects to the table:\n",
    "factors = [\"A\", \"B\", \"C\", \"D\"]\n",
    "import itertools\n",
    "\n",
    "for i in [2, 3, 4]:\n",
    "    for combination in itertools.combinations(factors, i):\n",
    "        key = \"\".join(combination)\n",
    "        table32[key] = 1\n",
    "        for factor in combination:\n",
    "            table32[key] *= table32[factor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab961bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y = table32[\"Filtration Rate (L/hour)\"].to_numpy()\n",
    "N = 4  # no. of main factors\n",
    "table32_effects = {\"factor\": [], \"effect\": []}\n",
    "for key in table32.columns:\n",
    "    if key != \"Filtration Rate (L/hour)\":\n",
    "        values = table32[key].to_numpy()\n",
    "        contrast = np.dot(values, y)\n",
    "        effect = contrast / (2 ** (N - 1))\n",
    "        table32_effects[\"factor\"].append(key)\n",
    "        table32_effects[\"effect\"].append(effect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166f07ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "table32_effects = pd.DataFrame(table32_effects)\n",
    "table32_effects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38be80a",
   "metadata": {},
   "source": [
    "#### Your answer to question 3.2(a): What are the calculated effects?\n",
    "\n",
    "Please see the table printed above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e59006",
   "metadata": {},
   "source": [
    "### 3.2(b)\n",
    "Construct a normal probability plot and use it to identify the important effects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aed1b81",
   "metadata": {},
   "source": [
    "We try first by adding the `line=\"q\"` option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab770ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plot = sm.ProbPlot(table32_effects[\"effect\"], fit=False)\n",
    "plot.qqplot(ax=ax, line=\"q\")\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61894887",
   "metadata": {},
   "source": [
    "In this case, it seems that we can find another linear region by using the 10 smallest points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc71c170",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plot = sm.ProbPlot(table32_effects[\"effect\"], fit=False)\n",
    "plot.qqplot(ax=ax)\n",
    "x = plot.theoretical_quantiles\n",
    "y = plot.sample_quantiles\n",
    "# Use the 10 smallest points as the linear region:\n",
    "idx = np.argsort(abs(y))\n",
    "xin = x[idx[:10]]\n",
    "yin = y[idx[:10]]\n",
    "p = np.polyfit(xin, yin, deg=1)\n",
    "line = np.polyval(p, x)\n",
    "ax.plot(x, line, label=\"Linear trend\", color=\"red\")\n",
    "\n",
    "\n",
    "sorted_factors = table32_effects.sort_values(\"effect\")\n",
    "for i, (xi, yi, factor) in enumerate(zip(x, y, sorted_factors[\"factor\"])):\n",
    "    diff_to_line = yi - np.polyval(p, xi)\n",
    "    if abs(diff_to_line) < 2:\n",
    "        continue\n",
    "    offset = 2\n",
    "    ax.annotate(\n",
    "        factor,\n",
    "        (xi, yi),\n",
    "        xytext=(xi, yi + offset),\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        arrowprops={\"arrowstyle\": \"-\"},\n",
    "        fontsize=\"small\",\n",
    "    )\n",
    "ax.legend(loc=\"upper left\")\n",
    "sns.despine(fig=fig)\n",
    "\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e70e417",
   "metadata": {},
   "source": [
    "#### Your answer to question 3.2(b): What are important effects?\n",
    "\n",
    "The important effects are (see the plot above):\n",
    "* A (temperature)\n",
    "* C (concentration)\n",
    "* D (stirring)\n",
    "* AC (interaction of temperature and concentration)\n",
    "* AD (interaction of temperature and stirring)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1b394d",
   "metadata": {},
   "source": [
    "### 3.2(c)\n",
    "Based on your results, at what level (high or low) should you put each of three factors A, C, and D to maximize the filtration rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1e2541",
   "metadata": {},
   "source": [
    "To answer that, let us first extract the effects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019bc01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_rows = table32_effects[\n",
    "    table32_effects[\"factor\"].isin([\"A\", \"AD\", \"D\", \"C\", \"AC\"])\n",
    "]\n",
    "selected_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc5b0eb",
   "metadata": {},
   "source": [
    "#### Your answer to question 3.2(c): How should you set the factors A, C, and D?\n",
    "\n",
    "All main effects are positive, suggesting that we should run A (temperature), C (concentration), and D (stirring rate) all at the high setting. However, the interaction between A and C is negative, implying that the positive effect of A is reduced when C is at a high level. Conversely, the positive AD interaction indicates a synergistic effect when both A and D are increased.\n",
    "\n",
    "While increasing all factors individually seems beneficial, the AC interaction suggests otherwise. A potential strategy could be to maintain C at a low level while increasing both A and D to capitalize on their synergistic effect (motivated by the fact that the effect of C is lower than the other positive effects).\n",
    "\n",
    "We can check the original experiments, where we find that these settings are indeed giving the highest filtration rates:\n",
    "\n",
    "|    |   A |   B |   C |   D |   Filtration Rate (L/hour) |\n",
    "|----|-----|-----|-----|-----|----------------------------|\n",
    "|  9 |   1 |  -1 |  -1 |   1 |                        100 |\n",
    "| 11 |   1 |   1 |  -1 |   1 |                        104 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bc42d9",
   "metadata": {},
   "source": [
    "## Exercise 3.3\n",
    "\n",
    "Reconsider the experiment described in [Exercise 3.2](#Exercise-3.2). Due to limited resources, we can only do 8 runs. We will therefore use a $2^{4-1}$ fractional factorial design. We select the following generator: $D=ABC$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f13d2e",
   "metadata": {},
   "source": [
    "### 3.3(a)\n",
    "\n",
    "Find the defining contrast and resolution of this design.  Are any main effects aliased with two-factor interactions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302ea3cf",
   "metadata": {},
   "source": [
    "#### Your answer to question 3.3(a):\n",
    "\n",
    "The defining contrast is,\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "D \\times D = D^2 &= ABC \\times D \\\\\n",
    "1 &= ABCD \\\\\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "This defining contrast is a combination of 4 factors, which means that the resolution is also 4. In this case, a main effect will be aliased with an interaction of order $4 - 1 = 3$. Thus: No main effects are not aliased with two-factor interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084493df",
   "metadata": {},
   "source": [
    "### 3.3(b)\n",
    "The results of a fractional factorial experiment are shown below.\n",
    "Verify that $D = ABC$ and add columns for the interaction effects $AB$, $AC$, and $BC$ to the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b9eac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data33 = {\n",
    "    \"Run\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "    \"A\": [-1, 1, -1, 1, -1, 1, -1, 1],\n",
    "    \"B\": [-1, -1, 1, 1, -1, -1, 1, 1],\n",
    "    \"C\": [-1, -1, -1, -1, 1, 1, 1, 1],\n",
    "    \"D\": [-1, 1, 1, -1, 1, -1, -1, 1],\n",
    "    \"Filtration Rate (L/hour)\": [45, 100, 45, 65, 75, 60, 80, 96],\n",
    "}\n",
    "\n",
    "table33 = pd.DataFrame(data33)\n",
    "table33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8e54f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "table33[\"AB\"] = table33[\"A\"] * table33[\"B\"]\n",
    "table33[\"AC\"] = table33[\"A\"] * table33[\"C\"]\n",
    "table33[\"BC\"] = table33[\"B\"] * table33[\"C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8f4059",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = table33[\"A\"] * table33[\"B\"] * table33[\"C\"]\n",
    "compare = D == table33[\"D\"]\n",
    "compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723544c4",
   "metadata": {},
   "source": [
    "#### Your answer to question 3.3(b): Is $D=ABC$?\n",
    "\n",
    "Yes, they are equal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4941a3d",
   "metadata": {},
   "source": [
    "### 3.3(c)\n",
    "Calculate all effects ($A$, $B$, $C$, $AB$, $AC$, $BC$, and $D=ABC$). Do this by creating a least squares model, for instance, using [statsmodels](https://www.statsmodels.org/stable/examples/notebooks/generated/ols.html) or [scikit-learn](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e15e423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X = table33[[\"A\", \"B\", \"C\", \"AB\", \"AC\", \"BC\", \"D\"]]\n",
    "X = sm.add_constant(X)\n",
    "y = table33[\"Filtration Rate (L/hour)\"]\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa8b7c0",
   "metadata": {},
   "source": [
    "To calculate the effects, we use that the regression coefficients are 1/2 of the effect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4ed77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "table33_effects = {\"factor\": [], \"effect\": []}\n",
    "for factor in results.params.index:\n",
    "    if factor != \"const\":\n",
    "        table33_effects[\"factor\"].append(factor)\n",
    "        table33_effects[\"effect\"].append(results.params[factor] * 2.0)\n",
    "table33_effects = pd.DataFrame(table33_effects)\n",
    "table33_effects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c01fa5",
   "metadata": {},
   "source": [
    "#### Your answer to question 3.3(c): What are the effects you calculated?\n",
    "\n",
    "See the table above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f747ee91",
   "metadata": {},
   "source": [
    "### 3.3(d)\n",
    "\n",
    "Identify the unimportant effect(s) based on their calculated values.  Confirm their insignificance by fitting a new least squares model without the unimportant effects. (Removing the unimportant effects should not change $R^2$  significantly.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9f4cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = table33[[\"A\", \"C\", \"AC\", \"BC\", \"D\"]]\n",
    "X1 = sm.add_constant(X1)\n",
    "y = table33[\"Filtration Rate (L/hour)\"]\n",
    "model1 = sm.OLS(y, X1)\n",
    "results1 = model1.fit()\n",
    "\n",
    "X2 = table33[[\"B\", \"C\", \"AB\", \"AC\", \"BC\", \"D\"]]\n",
    "X2 = sm.add_constant(X2)\n",
    "y = table33[\"Filtration Rate (L/hour)\"]\n",
    "model2 = sm.OLS(y, X2)\n",
    "results2 = model2.fit()\n",
    "\n",
    "\n",
    "print(results1.summary())\n",
    "print(results2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e681f7",
   "metadata": {},
   "source": [
    "#### Your answer to question 3.3(d): What are the unimportant effects?\n",
    "\n",
    "Effects B and AB are considerably smaller than the other effects, suggesting they might be negligible. This aligns with the findings from the full design analysis.\n",
    "\n",
    "Removing these unimportant effects and refitting the model results in a negligible change in $R^2$ (from 1.0 to 0.998). In contrast, removing the important factor A causes a substantial drop in $R^2$ (from 1.0 to 0.765)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e9aaa9",
   "metadata": {},
   "source": [
    "## Exercise 3.4\n",
    "\n",
    "[Teixeira et al. (2018)](https://doi.org/10.1016/j.scitotenv.2018.07.204) investigated the removal of two antibiotics from water using walnut shell-based activated carbon and a Box-Behnken experimental design. Their study examined the effects of pH, temperature (T), and initial antibiotic concentration (C) on antibiotic removal (measured as mg of antibiotic adsorbed per gram of activated carbon).\n",
    "\n",
    "We will investigate if we can reproduce their results for one of the antibiotics, [Sulfamethoxazole](https://en.wikipedia.org/wiki/Sulfamethoxazole), namely that the optimal conditions for removal of Sulfamethoxazole are obtained at a temperature of 30 °C, initial concentration of 40 mg/L and a pH value of 5.5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce09356",
   "metadata": {},
   "source": [
    "**Task:** Create a linear regression model using the provided experimental data (see [antibiotic.csv](./antibiotic.csv)) to predict the conditions (pH, T, and C) that maximize the removal of Sulfamethoxazole from water. The data includes measurements of Sulfamethoxazole adsorption (mg/g) at various pH (ranging from 2 to 8), temperature (ranging from 10 to 30 °C), and initial concentration (ranging from 20 to 40 mg/L) levels.\n",
    "\n",
    "The linear model should include all main effects, all second-order main effects, and all interaction effects. That is, your model for the adsorption of the antibiotic ($y$) should be of the form: \n",
    "\n",
    "$y = b_0 + \\sum_i b_i x_i + \\sum_i b_{ii} x_i^2 + \\sum_{i <j} b_{ij} x_i x_j$\n",
    "\n",
    "where $x_i$ represents one of the factors (pH, T, or C).\n",
    "\n",
    "\n",
    "**Suggested steps:**\n",
    "1. Load the data using [pandas](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html).\n",
    "2. Generate terms needed for the linear model using scikit-learn's [PolynomialFeatures](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html).\n",
    "3. Fit the linear regression model using [statsmodels](https://www.statsmodels.org/dev/examples/notebooks/generated/ols.html) or [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html). Evaluate the model's performance by calculating $R²$.\n",
    "4. Identify the conditions (pH, T, and C) that maximize Sulfamethoxazole removal within the experimental region.  This can be done by using methods from [scipy.optimize](https://docs.scipy.org/doc/scipy/tutorial/optimize.html), for instance [minimize](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html) (you can maximize $y$ by minimizing $-y$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8213e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load the raw data:\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"antibiotic.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd982c2",
   "metadata": {},
   "source": [
    "The raw data is provided in the following format:\n",
    "\n",
    "|    |   pH |   T (°C) |   C (mg/L) |   x1 |   x2 |   x3 |   Sulfamethoxazole (mg/g) |\n",
    "|---:|-----:|---------:|-----------:|-----:|-----:|-----:|--------------------------:|\n",
    "|  0 |    2 |       10 |         30 |   -1 |   -1 |    0 |                      57.2 |\n",
    "|  1 |    2 |       10 |         30 |   -1 |   -1 |    0 |                      54.9 |\n",
    "|  2 |    2 |       10 |         30 |   -1 |   -1 |    0 |                      54.3 |\n",
    "\n",
    "Where the columns are:\n",
    "\n",
    "*   **pH:**  The pH of the solution.\n",
    "*   **T (°C):** The temperature of the solution in degrees Celsius.\n",
    "*   **C (mg/L):** The initial concentration of Sulfamethoxazole in mg/L.\n",
    "*   **x1:** The pH value scaled to the range [-1, 1] using the formula:  `x1 = (pH - 5) / 3`\n",
    "*   **x2:** The temperature scaled to the range [-1, 1] using the formula: `x2 = (T - 20) / 10`\n",
    "*   **x3:** The initial concentration scaled to the range [-1, 1] using the formula: `x3 = (C - 30) / 10`\n",
    "*   **Sulfamethoxazole (mg/g):** The amount of Sulfamethoxazole adsorbed per gram of activated carbon, measured in mg/g."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1c48ae",
   "metadata": {},
   "source": [
    "We begin by developing a method for generating polynomial terms. We use scaled variables to allow direct comparison of the relative importance of the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87702d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "def make_polynomial(x1, x2, x3, poly, drop=None):\n",
    "    \"\"\"Generate polynomial features.\"\"\"\n",
    "    _X = pd.DataFrame(\n",
    "        {\n",
    "            \"x1\": x1,\n",
    "            \"x2\": x2,\n",
    "            \"x3\": x3,\n",
    "        }\n",
    "    )\n",
    "    X_new = pd.DataFrame(\n",
    "        poly.transform(_X), columns=poly.get_feature_names_out()\n",
    "    )\n",
    "    if drop is not None:\n",
    "        X_new.drop(columns=drop, inplace=True)\n",
    "    return X_new\n",
    "\n",
    "\n",
    "# Create the generator for polynomial features:\n",
    "poly = PolynomialFeatures(\n",
    "    degree=2,\n",
    "    include_bias=True,\n",
    ")\n",
    "poly.fit(data[[\"x1\", \"x2\", \"x3\"]])\n",
    "\n",
    "y = data[\"Sulfamethoxazole (mg/g)\"]\n",
    "X = make_polynomial(data[\"x1\"], data[\"x2\"], data[\"x3\"], poly)\n",
    "X.head()  # This should now contain all the terms we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c46a9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982abd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the polynomial:\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6953a55",
   "metadata": {},
   "source": [
    "The initial fit suggests a reasonable model. However, the interaction terms `x1 x2` (pH and temperature) and `x1 x3` (pH and concentration) exhibit high p-values, indicating a lack of statistical significance. We proceed by refitting the model without these two terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06e13c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = [\"x1 x2\", \"x1 x3\"]\n",
    "\n",
    "X = make_polynomial(data[\"x1\"], data[\"x2\"], data[\"x3\"], poly, drop=drop)\n",
    "# Fit the polynomial:\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e317601",
   "metadata": {},
   "source": [
    "We now visualize the model to understand its predictions at three different concentrations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26776beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c734096",
   "metadata": {},
   "outputs": [],
   "source": [
    "pH = np.linspace(2, 8, 25)\n",
    "T = np.linspace(10, 30, len(pH))\n",
    "conc = np.array([20, 30, 40])\n",
    "\n",
    "\n",
    "def transform_pH(x):\n",
    "    \"\"\"Transform a pH value to the range [-1, 1]\"\"\"\n",
    "    return (x - 5.0) / 3.0\n",
    "\n",
    "\n",
    "def transform_T(x):\n",
    "    \"\"\"Transform a T value to the range [-1, 1]\"\"\"\n",
    "    return (x - 20.0) / 10.0\n",
    "\n",
    "\n",
    "def transform_C(x):\n",
    "    \"\"\"Transform a C value to the range [-1, 1]\"\"\"\n",
    "    return (x - 30.0) / 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1b0957",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    constrained_layout=True,\n",
    "    figsize=(12, 4),\n",
    "    ncols=3,\n",
    "    subplot_kw={\"projection\": \"3d\"},\n",
    ")\n",
    "\n",
    "fig2, axes2 = plt.subplots(\n",
    "    constrained_layout=True, figsize=(12, 4), ncols=3, sharex=True, sharey=True\n",
    ")\n",
    "\n",
    "for ci, axi, axj in zip(conc, axes, axes2):\n",
    "    pH_grid, T_grid = np.meshgrid(pH, T)\n",
    "    conc_grid = np.full_like(pH_grid, ci)\n",
    "\n",
    "    X_new = make_polynomial(\n",
    "        transform_pH(pH_grid.ravel()),\n",
    "        transform_T(T_grid.ravel()),\n",
    "        transform_C(conc_grid.ravel()),\n",
    "        poly,\n",
    "        drop=drop,\n",
    "    )\n",
    "    Y = model.predict(X_new.to_numpy()).reshape(pH_grid.shape)\n",
    "    axi.plot_surface(pH_grid, T_grid, Y, cmap=\"rocket\", linewidth=0)\n",
    "    axi.set_xlabel(\"pH\")\n",
    "    axi.set_ylabel(\"T (°C)\")\n",
    "    axi.set_zlabel(\"Adsorption (mg/g)\")\n",
    "    axi.set_box_aspect(None, zoom=0.85)\n",
    "    cont = axj.contourf(pH_grid, T_grid, Y, levels=30, cmap=\"rocket\")\n",
    "    axj.set(xlabel=\"pH\", ylabel=\"T (°C)\")\n",
    "    axj.set_title(f\"C = {ci} mg/L\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78cab8e",
   "metadata": {},
   "source": [
    "Visual analysis suggests that high temperature and concentration, along with a pH between 5 and 6, lead to maximum absorbance. We now perform a numerical optimization to pinpoint the optimal conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6523a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find the optimum, it is here maybe easiest to just pick out the largest value from the grid above.\n",
    "# We can also try to do it numerically. It is then easiest to define a new function:\n",
    "def evaluate_model(x):\n",
    "    xx = x.reshape(1, -1)\n",
    "    X_new = make_polynomial(xx[:, 0], xx[:, 1], xx[:, 2], poly, drop=drop)\n",
    "    Y = model.predict(X_new)\n",
    "    return -Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94882768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import Bounds, minimize\n",
    "\n",
    "low = [-1, -1, -1]\n",
    "high = [1, 1, 1]\n",
    "\n",
    "bounds = Bounds(low, high)\n",
    "x0 = np.array([0.0, 1.0, 1.0])  # Initial guess\n",
    "res = minimize(\n",
    "    evaluate_model,\n",
    "    x0,\n",
    "    method=\"trust-constr\",\n",
    "    options={\"verbose\": 1},\n",
    "    bounds=bounds,\n",
    ")\n",
    "y_max = -evaluate_model(res.x)\n",
    "\n",
    "\n",
    "pH_opt = 5.0 + res.x[0] * 3.0\n",
    "T_opt = 20.0 + res.x[1] * 10.0\n",
    "C_opt = 30.0 + res.x[2] * 10.0\n",
    "\n",
    "print(\n",
    "    f\"Optimum at pH = {pH_opt:3.2f}, T = {T_opt:4.2f} °C, C = {C_opt:4.2f} mg/L, y = {y_max:4.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46156774",
   "metadata": {},
   "source": [
    "This is consistent with the original paper, which states:\n",
    "\n",
    "> The best conditions, predicted by the model, for the removal of the antibiotic Sulfamethoxazole (106.9 mg/g) are obtained at a temperature of 30 °C, initial concentration of 40 mg/L and a pH value of 5.5. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fead688",
   "metadata": {},
   "source": [
    "#### Your answer to question 3.4: What settings gives you optimum absorbance?\n",
    "\n",
    "The optimum is at:\n",
    "* pH = 5.50,\n",
    "* T = 30 °C,\n",
    "* Concentraion = 40 mg/L."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

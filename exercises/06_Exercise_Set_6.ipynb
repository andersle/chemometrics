{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise set 6\n",
    "\n",
    "The goal of this exercise is to go through some of the steps required\n",
    "to make a predictive regression model. We will here try different types\n",
    "of models, and we will also assess the models in greater detail, compared to the\n",
    "previous exercises. In particular, this exercise will introduce the use of a\n",
    "*training set*, a *test set*, *cross-validation* and different\n",
    "measures of the errors in our models.\n",
    "\n",
    "\n",
    "**Exercise 6.1:** \n",
    "\n",
    "Concrete is one of the most important materials in civil engineering, and it\n",
    "has a rich chemical composition. The strength of concrete is a\n",
    "function of its ingredients and age.\n",
    "We will in this exercise investigate to what extent we can predict the\n",
    "strength of concrete from the ingredients and its age, with linear models.\n",
    "\n",
    "The [data set](https://doi.org/10.1016/S0008-8846(98)00165-3) we\n",
    "will consider here contains $1030$ samples, and the\n",
    "following variables have been measured:\n",
    "\n",
    "|Variable|Unit|\n",
    "|:-------|---:|\n",
    "|Cement (component 1)                 | kg/m$^3$ |\n",
    "|Blast Furnace Slag (component 2)     | kg/m$^3$ |\n",
    "|Fly Ash (component 3)                | kg/m$^3$ |\n",
    "|Water (component 4)                  | kg/m$^3$ |\n",
    "|Superplasticizer (component 5)       | kg/m$^3$ |\n",
    "|Coarse Aggregate (component 6)       | kg/m$^3$ |\n",
    "|Fine Aggregate (component 7)         | kg/m$^3$ | \n",
    "|Age                                  | days     |\n",
    "|Concrete compressive strength        | MPa      |\n",
    "|**Table 1:** *Data columns present in the [Data file](Data/concrete_data.csv)*||\n",
    "\n",
    "**(a)**\n",
    "Begin by exploring the raw data. Here, it is a good idea to make scatter plots,\n",
    "in particular of the strength as a function of the other variables. In addition,\n",
    "you may find it useful to investigate correlations between the variables. Below,\n",
    "you will find some Python code to get you started.\n",
    "\n",
    "After looking at the raw data, are there some of the variables that seem to be\n",
    "correlated with the strength of the concrete?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from pandas.plotting import scatter_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Load the raw data:\n",
    "data = pd.read_csv('Data/concrete_data.csv')\n",
    "# Print out variables:\n",
    "print(data.columns)\n",
    "# Rename the variables to have shorter names:\n",
    "rename = {\n",
    "    'Cement (component 1)(kg in a m^3 mixture)': 'cement',\n",
    "    'Blast Furnace Slag (component 2)(kg in a m^3 mixture)': 'slag',\n",
    "    'Fly Ash (component 3)(kg in a m^3 mixture)': 'ash',\n",
    "    'Water  (component 4)(kg in a m^3 mixture)': 'water',\n",
    "    'Superplasticizer (component 5)(kg in a m^3 mixture)': 'super',\n",
    "    'Coarse Aggregate  (component 6)(kg in a m^3 mixture)': 'coarse',\n",
    "    'Fine Aggregate (component 7)(kg in a m^3 mixture)': 'fine',\n",
    "    'Age (day)': 'age',\n",
    "    'Concrete compressive strength(MPa, megapascals)': 'strength',\n",
    "}\n",
    "data = data.rename(columns=rename)\n",
    "# Remove the ID of samples:\n",
    "data = data.drop(columns=['Sample ID'])\n",
    "# Print out information about the data:\n",
    "print(data.describe())\n",
    "# Investigate correlations:\n",
    "corr = data.corr()\n",
    "# Sort correlations for the strength:\n",
    "print(corr['strength'].sort_values(ascending=False))\n",
    "# Make scatter plots of the raw data (this will be a large figure...):\n",
    "scatter_matrix(data, figsize=(14, 12), diagonal='kde')\n",
    "plt.tight_layout()\n",
    "# If some of the variables seem more interesting, they can be\n",
    "# inspected in greater detail as follows:\n",
    "data.plot(kind='scatter', x='age', y='strength', alpha=0.5, s=100)\n",
    "data.plot(kind='scatter', x='cement', y='strength', alpha=0.5, s=100)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer to 6.1(a):** *(double click here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** Before we start the modeling, we will create a *training set* and a *test* set. With `sklearn`, there is a\n",
    "method to do this, shown below.\n",
    "\n",
    "Here, we create a test set using $20$% of the samples from `X` and `y`. Modify this code for\n",
    "your Python script, and use it to create a training set and a test set.\n",
    "\n",
    "What is the purpose of doing this split? That is, what is the *training set* and the *test set*\n",
    "used for respectively?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training set:\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "xvars = ['cement', 'slag', 'ash', 'water', 'super', 'coarse', 'fine', 'age']\n",
    "X = data[xvars]\n",
    "y = data['strength']\n",
    "X = scale(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer to 6.1(b):** *(double click here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** Our first model will be a linear least-squares model. \n",
    "In the rest of the exercise, we will refer to this\n",
    "model as \"model 1\". For creating model 1, we will use the\n",
    "`LinearRegression` class from `sklearn.linear_model`. \n",
    "\n",
    "Below, you will find some Python code that can be used as a starting point for\n",
    "creating a linear model.\n",
    "\n",
    "Modify your Python code to do the linear least-squares regression and plot \n",
    "the measured strengths ($y_i$) vs. the predicted strengths ($\\hat{y}_i$) for\n",
    "your training data.\n",
    "Also, plot the residuals, $y_i - \\hat{y}_i$, as a function of $y_i$. Do the\n",
    "residuals seem to be homoscedastic or heteroscedastic? What does this plot\n",
    "indicate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "xvars = ['cement', 'slag', 'ash', 'water', 'super', 'coarse',\n",
    "         'fine', 'age']\n",
    "X = data[xvars]\n",
    "y = data['strength']\n",
    "X = scale(X)\n",
    "\n",
    "# Create a test set:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "    \n",
    "# Do a linear regression:\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "y_hat = linear_model.predict(X_train)\n",
    "fig, ax1 = plt.subplots(constrained_layout=True)\n",
    "ax1.scatter(y_train, y_hat)\n",
    "ax1.set(xlabel='y (measured, training)', ylabel='y (predicted, training)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer to 6.1(c):** *(double click here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d)** \n",
    "We have now created a linear model (model 1) and you may have seen that\n",
    "it does not seem to perform very well.\n",
    "In this part of the exercise, we will define some ways we can\n",
    "assess the performance and\n",
    "we will use the same assessments in the rest of the exercise for the other models we\n",
    "are going to create.\n",
    "\n",
    "* In part **(b)** of this exercise, you created a test set. This test set can be used to check\n",
    "  how well the model performs for data which was not included when making it.\n",
    "  Predict the strength using model 1 and the test set data. Plot the predicted\n",
    "  strengths vs. the measured strengths for the test set, and compare this with the\n",
    "  plot you made when creating/training model 1.\n",
    "\n",
    "* We have, in previous exercises, used the \n",
    "  [coefficient of determination](https://en.wikipedia.org/wiki/Coefficient_of_determination) $R^2$,\n",
    "  as a measure of well a model performs. This will also be the first metric we will use here.\n",
    "  With `sklearn`, this is [available](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html) as the function `r2_score` from the module `sklearn.metrics`. \n",
    "  Here, we can calculate two different $R^2$ values:\n",
    "  1. Using the training set (let us call this $R^2$ in the continuation)\n",
    "  2. Using the test set (let us call this $R_\\text{p}^2$ in the continuation).\n",
    "  \n",
    "  Calculate the $R^2$ and $R_\\text{p}^2$ values for model 1 and compare them.\n",
    "  \n",
    "* Another set of metrics for the performance is based on the mean squared error (MSE).\n",
    "  This error is calculated from the difference of measured y-values ($y_i$) and predicted y-vales ($\\hat{y}_i$):\n",
    "  \\begin{equation*}\n",
    "    \\text{MSE} = \\frac{1}{N} \\sum_{i=1}^N (y_i - \\hat{y}_i)^2 ,\n",
    "  \\end{equation*}\n",
    "  where $N$ is the number of samples. It is common to report the root mean squared error (RMSE) which\n",
    "  is obtained by just taking the square root: $\\text{RMSE} = \\sqrt{\\text{MSE}}$.\n",
    "  Here, we can again calculate two of these values, one for the training set and one for the test set.\n",
    "  We will give these two different values unique names:\n",
    "  1. **RMSEC**: Root mean squared error of *calibration*, which is obtained by calculating the RMSE\n",
    "     for the *training set*.\n",
    "  2. **RMSEP**: Root mean squared error of *prediction*, which is obtained by calculating the RMSE\n",
    "     for the *test set*.\n",
    "     \n",
    "  Calculate these two values for model 1.\n",
    "  \n",
    "  Hint: Here you can use the method [mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error) from\n",
    "  the [sklearn.metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)\n",
    "  module of `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer to 6.1(d):** *(double click here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e)**\n",
    "When we are doing the actual training (or fitting) of the model,\n",
    "we can also do *cross-validation*. This is in particular\n",
    "useful if we have additional parameters\n",
    "we need to optimize. Such additional parameters could,\n",
    "for instance, be the number\n",
    "of variables to include in a least-squares model,\n",
    "the number of components to use in a PCR model,\n",
    "or the extra parameters in regularized\n",
    "regression techniques. We could then optimize these\n",
    "parameters in a cross-validation step, and test the\n",
    "full model using the test set.\n",
    "\n",
    "In cross-validation, we split the training set into $k$ smaller sets.\n",
    "For each of these sets, we do the following:\n",
    "\n",
    "1. We fit/train the model using the $k-1$ other sets.\n",
    "2. We evaluate the performance using the set we kept out of the fitting.\n",
    "\n",
    "Essentially, we have trained the model $k$ times,\n",
    "and we have $k$ evaluations of\n",
    "the fitting. The overall performance of the fitting\n",
    "can then be obtained as the\n",
    "average over all the $k$ performance measures.\n",
    "See Fig. 1 for a graphical overview of this approach.\n",
    "<img src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\" width=\"500\">\n",
    "  \n",
    "**Fig. 1:** Illustration of cross-validation where we split the training set\n",
    "into $5$ smaller sets for cross-validation.\n",
    "This illustration has been taken from the `sklearn`\n",
    "[homepage](https://scikit-learn.org/stable/modules/cross_validation.html).\n",
    "Here, we first split our original data into a training set and a test set.\n",
    "We then split the training set into $5$ smaller sets in the cross-validation\n",
    "step, and use this to obtain the parameters. Finally, we check the full\n",
    "model using the test set.\n",
    "  \n",
    "We will now add a cross-validation step to our fitting.\n",
    "In `sklearn`, there is a method that will do this for us,\n",
    "[cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html)\n",
    "This method can be used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a least-squares model:\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "# Run cross-validation:\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(linear_model, X_train, y_train,\n",
    "                         scoring='neg_mean_squared_error',\n",
    "                         cv=10)\n",
    "# Take the square root of -scores:\n",
    "scores = np.sqrt(-scores)\n",
    "print('Average score:', scores.mean())\n",
    "print('Standard deviation for score:', scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we set the following two parameters:\n",
    "\n",
    "* `scoring`: Which defines how we evaluate the model.       \n",
    "  Here we select the \\emph{negative} mean squared error.\n",
    "  The `cross_val_score` method expects\n",
    "  that a higher score corresponds to a better\n",
    "  model, which is the opposite of the meaning of the\n",
    "  mean squared error. This is the reason\n",
    "  or using the *negative* mean squared error.\n",
    "                \n",
    "* `cv`: Which defines how many\n",
    "  splits we will do for the data.\n",
    "  In this case, we will split the data $10$ times.\n",
    "\n",
    "Update your script to include a cross-validation step.\n",
    "It is common to report the average score as\n",
    "a so-called \"root mean squared error of cross-validation\"\n",
    "(abbreviated RMSECV). Calculate RMSECV for model 1,\n",
    "and compare it with the RMSEC and RMSEP values you obtained previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer to 6.1(e):** *(double click here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(f)**\n",
    "We are not too happy with the performance of the model we have so far.\n",
    "In the lectures, we have briefly mentioned regularized\n",
    "regression methods as an alternative to least-squares regression.\n",
    "We will here see if using a regularized fitting method, the so-called\n",
    "[Ridge regression method](https://en.wikipedia.org/wiki/Tikhonov_regularization), will improve things.\n",
    "\n",
    "In `sklearn`, this method is available from\n",
    "[sklearn.linear_model.Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge).\n",
    "\n",
    "When using this method, we have to specify one additional\n",
    "parameter, $\\alpha$, which determines how strongly we penalize\n",
    "large coefficients. This is an unknown parameter, and we need to\n",
    "find the \"best\" one to use. One approach to finding the best $\\alpha$\n",
    "is to just try different values and look for the $\\alpha$ value\n",
    "that gives the lowest RMSECV. Luckily, this process can be automated\n",
    "in `sklearn` by using a method\n",
    "called [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). This method will automatically\n",
    "try different $\\alpha$ values from a range we specify, and locate\n",
    "the best parameter by scoring each parameter with cross-validation.\n",
    "This can be implemented as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge()\n",
    "# We will look for alpha parameters between 0 and 1.5 in steps of 0.01:\n",
    "parameters = [{'alpha': np.arange(0, 1.5, 0.01)}]\n",
    "grid = GridSearchCV(ridge, parameters,\n",
    "                    cv=10,\n",
    "                    scoring='neg_mean_squared_error',\n",
    "                    return_train_score=True)\n",
    "grid.fit(X_train, y_train)\n",
    "print(np.sqrt(-grid.best_score_))\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new model, \"model 2\", in which you use Ridge regression.\n",
    "Use the Python code given above as\n",
    "a starting point for determining $\\alpha$ and fit\n",
    "the model using this $\\alpha$ value. Further,\n",
    "calculate $R^2$, $R_\\text{p}^2$, RMSEC, RMSEP, and RMSECV for model 2.\n",
    "How does model 2 compare with model 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer to 6.1(f):** *(double click here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(g)**\n",
    "A powerful alternative for doing regression is the PLSR method.\n",
    "We will in this step investigate if PLSR can improve our ability\n",
    "to predict the strength. Below, you will find some code for\n",
    "running PLSR. Implement this in your script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PLSR model:\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "max_components = 8  # Maxmum number = number of original variables.\n",
    "# Run cross-validation:\n",
    "results = []\n",
    "for i in range(1, max_components + 1):\n",
    "    print('Trying with {} PLS components'.format(i))\n",
    "    plsr_model = PLSRegression(n_components=i)\n",
    "    scores = cross_val_score(plsr_model, X_train, y_train,\n",
    "                             scoring='neg_mean_squared_error',\n",
    "                             cv=10)\n",
    "    rmsecv = np.average(np.sqrt(-scores))\n",
    "    results.append((i, rmsecv))\n",
    "results = np.array(results)\n",
    "fig, axi = plt.subplots(constrained_layout=True)\n",
    "axi.plot(results[:, 0], results[:, 1], marker='o')\n",
    "axi.set(xlabel='Number of components', ylabel='RMSECV')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we here use cross-validation for determining\n",
    "the number of PLS components we use. What seems to be the best\n",
    "number of components in this case?\n",
    "Create a new model, \"model 3\", in which you use\n",
    "*only* $2$ PLS components. Calculate\n",
    "$R^2$ $R_\\text{p}^2$, RMSEC, RMSEP, and RMSECV for model 3.\n",
    "How does this model compare with model 1 and model 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer to 6.1(g):** *(double click here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(h)**\n",
    "So far, we have not found a good model for\n",
    "predicting the strength. One option now is to try to use\n",
    "even more advanced regression methods. However, it\n",
    "is often a good idea to try to understand the problem we are dealing\n",
    "with better, before using more complex methods.\n",
    "Luckily, we have a colleague who is\n",
    "an expert on concrete. From that colleague, we learn that the strength\n",
    "depends on the variables we have measured in a highly non-linear way! Our\n",
    "coworker also tells us that they often find that the strength depends on:\n",
    "\n",
    "* The water to cement ratio.\n",
    "* The logarithm of the age, $\\ln(\\text{age})$.\n",
    "\n",
    "Motivated by this, create a new least-squared model, \"model 4\",\n",
    "in which you include the water to cement ratio\n",
    "and $\\ln(\\text{age})$ as variables.\n",
    "Calculate $R^2$ $R_\\text{p}^2$, RMSEC, RMSEP, and RMSECV for model 4, and\n",
    "compare this with your previous models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer to 6.1(h):** *(double click here)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

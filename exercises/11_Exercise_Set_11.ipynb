{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "717bf838",
   "metadata": {},
   "source": [
    "# Exercise 11\n",
    "\n",
    "\n",
    "> In this exercise, we will have a look at penguins! We will attempt to figure out the species of penguins based\n",
    "> on their bill length, bill depth, flipper length, and body mass.\n",
    "> The data is from a paper by \n",
    "> [Gorman, Williams, and Fraser](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0090081)\n",
    "> and can also be found in the R package [palmerpenguins](https://github.com/allisonhorst/palmerpenguins).\n",
    "> Here, we will use a version of the data set [penguins.csv](./Data/penguins.csv) where missing\n",
    "> values have been removed.\n",
    ">\n",
    "> The exercise is structured as follows:\n",
    "> * [11.1 Initial exploration (of the data set)](#11.1-Initial-exploration)\n",
    "> * [11.2 Creating a decision tree for determining the species](#11.2-Creating-a-decision-tree-for-determining-the-species)\n",
    "> * [11.3 Exploring the penguins with partial least squares discriminant analysis (PLS-DA)](#11.3-Exploring-the-penguins-with-partial-least-squares-discriminant-analysis-(PLS-DA))\n",
    ">\n",
    "> In [11.3](#11.3-Exploring-the-penguins-with-partial-least-squares-discriminant-analysis-(PLS-DA))\n",
    "> you will mostly run some code (to perform the analysis) and then interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f23d5e",
   "metadata": {},
   "source": [
    "## 11.1 Initial exploration\n",
    "\n",
    "The penguins belong to three species: [Adelie](https://en.wikipedia.org/wiki/Ad%C3%A9lie_penguin),\n",
    "[Chinstrap](https://en.wikipedia.org/wiki/Chinstrap_penguin), and [Gentoo](https://en.wikipedia.org/wiki/Gentoo_penguin), and the figure below shows the three islands where these penguins can be found (click the image to make it larger): \n",
    "\n",
    "\n",
    "\n",
    "| <a href=\"./Figures/penguins.png\"><img src=\"./Figures/penguins2.png\" width=\"50%\"></a>           |\n",
    "|:-:|\n",
    "| **Fig. 1** *Location of islands and images of the penguin species.*    |\n",
    "\n",
    "You will find seven columns in the [penguins.csv](./Data/penguins.csv) data file. Each row is a measurement for\n",
    "a single penguin for the seven variables found in the columns:\n",
    "\n",
    "\n",
    "| Column            |  Description                                                        |\n",
    "|:------------------|--------------------------------------------------------------------:|\n",
    "| species           | The species (Adelie/Chinstrap/Gentoo)                               |\n",
    "| island            | The island where the observation was made (Dream/Torgersen/Biscoe)  |\n",
    "| bill_length_mm    | (See the illustration below) (measured in mm)                       |\n",
    "| bill_depth_mm     | (See the illustration below) (measured in mm)                       |\n",
    "| flipper_length_mm | (See the illustration below) (measured in mm)                       |\n",
    "| body_mass_g       | The weight of the penguin (in grams)                                |\n",
    "| sex               | Female/Male                                                         |\n",
    "\n",
    "\n",
    "| <img src=\"./Figures/bill.png\" width=\"50%\">                                   |\n",
    "|:-:|\n",
    "| **Fig. 2** *Illustration of bill length, bill depth, and flipper length. (The foot is not used in this data set.)*    |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1e8223",
   "metadata": {},
   "source": [
    "### 11.1(a) Loading the data\n",
    "\n",
    "First, load the data set on the penguins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d29e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"Data/penguins.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31980189",
   "metadata": {},
   "source": [
    "After loading the data set, verify the following:\n",
    "\n",
    "1. We have data from three distinct islands (Dream, Torgersen, and Biscoe).\n",
    "\n",
    "1. We have data from three penguin species (Adelie, Chinstrap, and Gentoo).\n",
    "\n",
    "1. On the island Dream, the only species are Adelie and Chinstrap.\n",
    "\n",
    "1. On the island Torgersen, the only specie is Adelie.\n",
    "\n",
    "1. On the island of Biscoe, the only species are Adelie and Gentoo.\n",
    "\n",
    "Here are some hints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57512248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the unique elements in a column, we can do:\n",
    "print(data[\"species\"].unique())\n",
    "# Or we can do:\n",
    "print(set(data[\"species\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1597a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get more information on different islands, we can use the groupby method for pandas:\n",
    "group = data.groupby(\"species\")\n",
    "print(group.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6214648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method also works with several columns:\n",
    "group = data.groupby([\"island\", \"species\"])\n",
    "print(group.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246b560a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e8f923",
   "metadata": {},
   "source": [
    "#### Your answer to question 11.1(a):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aa200d",
   "metadata": {},
   "source": [
    "### 11.1(b) Exploring by plotting\n",
    "\n",
    "Create figures to see if the variables `bill_length_mm`, `bill_depth_mm`,\n",
    "`flipper_length_mm`, and `body_mass_g` can be used to separate the different\n",
    "species. Here, you can, for instance, create the scatter plot matrix,\n",
    "or use [jointplot](https://seaborn.pydata.org/tutorial/introduction.html#multivariate-views-on-complex-datasets)\n",
    "from seaborn. Or maybe a [boxplot](https://seaborn.pydata.org/generated/seaborn.boxplot.html) is useful?\n",
    "\n",
    "If you were to label a penguin as Adelie, Chinstrap, or Gentoo, what \"rules\" would you\n",
    "use for this (keep it simple!) based on the four variables `bill_length_mm`, `bill_depth_mm`,\n",
    "`flipper_length_mm`, and `body_mass_g`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65016319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_theme(style=\"ticks\", context=\"notebook\", palette=\"muted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d521e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20845cb",
   "metadata": {},
   "source": [
    "#### Your answer to question 11.1(b):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3d2441",
   "metadata": {},
   "source": [
    "## 11.2 Creating a decision tree for determining the species"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7d8430",
   "metadata": {},
   "source": [
    "### 11.2(a) Coding the species\n",
    "\n",
    "We have three species, and the data we have is categorical. To use the specie in\n",
    "numerical methods, we must represent it with numbers. For decision trees,\n",
    "we can use the numbers 0, 1, and 2 to represent the three species (we are not\n",
    "doing any math with these numbers, and they only have a meaning as labels for the decision tree).\n",
    "\n",
    "Generating numbers for categorical data is a common task, and sklearn has a built-in method for\n",
    "that called [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html). This one can be used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b20920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create some categorical data:\n",
    "raw_data = [\n",
    "    \"bears\",\n",
    "    \"beets\",\n",
    "    \"battlestar galactica\",\n",
    "    \"bears\",\n",
    "    \"bears\",\n",
    "    \"beets\",\n",
    "]\n",
    "# Create the encoder and fit it to the data:\n",
    "encoder = LabelEncoder().fit(raw_data)\n",
    "# Show the classes the encoder found:\n",
    "print(\"Classes are:\", encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3302fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the encoder to transform the raw data to numbers:\n",
    "y = encoder.transform(raw_data)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02511414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also convert back:\n",
    "labels = encoder.inverse_transform(y)\n",
    "print(labels)\n",
    "# Check that we got the same as we started with:\n",
    "print([i == j for i, j in zip(raw_data, labels)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386fce47",
   "metadata": {},
   "source": [
    "Create a new encoder for the species and transform the species in the data to numerical y-values.\n",
    "You will use these y-values in the following to create the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83d2175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028c664d",
   "metadata": {},
   "source": [
    "#### Your answer to question 11.2(a):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ed7640",
   "metadata": {},
   "source": [
    "### 11.2(b) Creating the decision tree\n",
    "\n",
    "Create a decision tree for determining the species. Use the numerical y-values you just created\n",
    "for your y, and use `bill_length_mm`, `bill_depth_mm`,\n",
    "`flipper_length_mm`, and `body_mass_g` as your X-variables. Keep the tree as simple as possible so\n",
    "that it is easy to interpret it.\n",
    "\n",
    "After you have created the decision tree, show the **confusion matrix** and calculate\n",
    "the **precision** and **recall**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93869af1",
   "metadata": {},
   "source": [
    "**Note!** We have three species here, which means we have to define how we should calculate these metrics.\n",
    "Let us take recall as an example. For binary classification, where we only have two classes, it is:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{recall} = \\frac{TP}{TP + FN}\n",
    "\\end{equation}\n",
    "\n",
    "where $TP$ is the number of true positives, and $FN$ is the number of false negatives. If we have three classes\n",
    "we will get $TP$ (and $FN$) for classes 0, 1, and 2. We will here consider two possibilities (there are more!) for\n",
    "the averaging into one recall score:\n",
    "\n",
    "* macro-averaging: This will calculate the metric for each class\n",
    "  independently and it will then take the average (all classes treated equally):\n",
    "  \n",
    "  \\begin{equation}\n",
    "  \\text{recall}_0 = \\frac{TP_0}{TP_0 + FN_0}, \\quad \\text{recall}_1 = \\frac{TP_1}{TP_1 + FN_1},\n",
    "  \\quad \\text{recall}_2 = \\frac{TP_2}{TP_2 + FN_2}.\n",
    "  \\end{equation}\n",
    "  \n",
    "  Here $TP_i$ means correct classifications for class $i$, and $FN_i$ means mistakes for class $i$.\n",
    "  \n",
    "  \\begin{equation}\n",
    "  \\text{recall}_\\text{macro} = \\frac{\\text{recall}_0 + \\text{recall}_1 + \\text{recall}_2}{3}\n",
    "  \\end{equation}\n",
    "  \n",
    "\n",
    "\n",
    "* micro-averaging: This will aggregate contributions of all classes and use this to\n",
    "  calculate the average:\n",
    "  \n",
    "  \\begin{equation}\n",
    "  \\text{recall}_\\text{micro} = \\frac{TP_0 + TP_1 + TP_2}{TP_0 + TP_1 + TP_2 + FN_0 + FN_1 + FN_2}\n",
    "  \\end{equation}\n",
    "  \n",
    "\n",
    "Since macro-averaging treats all classes equally, it will not deal well with cases\n",
    "where we have a class imbalance (for instance, if we have few items of one class compared to the others). In\n",
    "such cases, micro-averaging is preferred.\n",
    "\n",
    "Here is a short example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d5f5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "y_true = [0, 0, 1, 1, 2, 2, 2, 2]\n",
    "y_pred = [0, 1, 1, 2, 1, 1, 0, 2]\n",
    "macro = recall_score(y_true, y_pred, average=\"macro\")\n",
    "micro = recall_score(y_true, y_pred, average=\"micro\")\n",
    "print(f\"recall(macro) = {macro}\")\n",
    "print(f\"recall(micro) = {micro}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a049995f",
   "metadata": {},
   "source": [
    "For completeness, let us do this by hand as well:\n",
    "\n",
    "| Class | True positives (correct) | False negatives (mistakes) |\n",
    "|:-:|:-:|:-:|\n",
    "| 0 | 1 | 1 |\n",
    "| 1 | 1 | 1 |\n",
    "| 2 | 1 | 3 |\n",
    "\n",
    "* macro-averaging:\n",
    "  \n",
    "  \\begin{equation}\n",
    "  \\text{recall}_0 = \\frac{TP_0}{TP_0 + FN_0} = \\frac{1}{1+1}=0.5, \\quad \\text{recall}_1 = \\frac{TP_1}{TP_1 + FN_1} =   \\frac{1}{1+1}=0.5,\n",
    "  \\quad \\text{recall}_2 = \\frac{TP_2}{TP_2 + FN_2} = \\frac{1}{1+3}=0.25.\n",
    "  \\end{equation}\n",
    "\n",
    "  \\begin{equation}\n",
    "  \\text{recall}_\\text{macro} = \\frac{0.5 + 0.5 + 0.25}{3} = \\frac{5}{12} = 0.41666\\ldots\n",
    "  \\end{equation}\n",
    " \n",
    "* micro-averaging: \n",
    " \n",
    "  \\begin{equation}\n",
    "  \\text{recall}_\\text{micro} = \\frac{TP_0 + TP_1 + TP_2}{TP_0 + TP_1 + TP_2 + FN_0 + FN_1 + FN_2}\n",
    "  = \\frac{1 + 1 + 1}{1 + 1 + 1 + 1+ 1+3} = \\frac{3}{8} = 0.375\n",
    "  \\end{equation}\n",
    "  \n",
    "\n",
    "Motivated by the fact that we do not have an equal number of samples for the different species, I\n",
    "suggest using micro-averaging in the following. If you use\n",
    "[GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "for finding the optimum depth of your tree, this can be done by setting `scoring=\"recall_micro\"` in\n",
    "`GridSearchCV`. Here is a short example you can adapt to make your decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad68d196",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Just generate some synthetic classification data for this example:\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_classes=3,\n",
    "    n_clusters_per_class=1,\n",
    "    n_features=2,\n",
    "    n_redundant=0,\n",
    ")\n",
    "X = scale(X)\n",
    "\n",
    "# Create test/training sets:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "# Set up a grid search:\n",
    "parameters = {\"max_depth\": range(1, 5)}\n",
    "grid = GridSearchCV(\n",
    "    DecisionTreeClassifier(),\n",
    "    parameters,\n",
    "    scoring=\"recall_micro\",\n",
    ")\n",
    "\n",
    "# Run the grid search:\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Get the best classifier from the grid search:\n",
    "best_tree = grid.best_estimator_\n",
    "print(\"Best tree:\", best_tree)\n",
    "\n",
    "# Use the best classifier for the test set:\n",
    "y_pred = best_tree.predict(X_test)\n",
    "\n",
    "# Calculate the precision etc. for the test set:\n",
    "precision = precision_score(y_test, y_pred, average=\"micro\")\n",
    "recall = recall_score(y_test, y_pred, average=\"micro\")\n",
    "print(f\"precision = {precision}\")\n",
    "print(f\"recall = {recall}\")\n",
    "\n",
    "\n",
    "# Make confusion matrix:\n",
    "fig, ax = plt.subplots(constrained_layout=True, figsize=(4, 4))\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    best_tree,\n",
    "    X,\n",
    "    y,\n",
    "    display_labels=[\"Class 0\", \"Class 1\", \"Class 2\"],\n",
    "    ax=ax,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076dfdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here (create a decision tree and score it)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62461845",
   "metadata": {},
   "source": [
    "#### Your answer to question 11.1(b):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb58396",
   "metadata": {},
   "source": [
    "### 11.2(c) Micro-averaged precision vs. recall\n",
    "You may have noted that the precision and recall give the same value when using micro-averaging.\n",
    "Can you explain this from the definitions of the micro-averaged precision and recall,\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{recall}_\\text{micro} = \\frac{\\sum_{i} TP_i}{\\sum_{i} TP_i + \\sum_{i} FN_i}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{precision}_\\text{micro} = \\frac{\\sum_{i} TP_i}{\\sum_{i} TP_i + \\sum_{i} FP_i}\n",
    "\\end{equation}\n",
    "\n",
    "where the sum runs over all classes?\n",
    "\n",
    "**Hint:** Give an argument for the two sums $\\sum_{i} FN_i$ and $\\sum_{i} FP_i$ being equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa110230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef7b3dc",
   "metadata": {},
   "source": [
    "#### Your answer to question 11.2(c):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b05c86",
   "metadata": {},
   "source": [
    "### 11.2(d) Visualize your decision tree\n",
    "\n",
    "Visualize your decision tree and compare it with your answer to [11.1(b)](#11.1(b)-Exploring-by-plotting). Are the rules found\n",
    "by the decision tree (this is easier to compare if you did not go all-out on the depth of your decision tree) similar to your rules?\n",
    "\n",
    "Here is an example of how you can visualize a decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64727ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "from IPython.display import SVG\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "dot_data = export_graphviz(\n",
    "    best_tree,\n",
    "    out_file=None,\n",
    "    feature_names=[\"Variable 1\", \"Variable 2\"],\n",
    "    class_names=[\"Class 0\", \"Class 1\", \"Class 2\"],\n",
    "    rounded=True,\n",
    "    filled=True,\n",
    ")\n",
    "graph = graphviz.Source(dot_data)\n",
    "SVG(graph.pipe(format=\"svg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765e5985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d8deb7",
   "metadata": {},
   "source": [
    "#### Your answer to question 11.2(d):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7af690",
   "metadata": {},
   "source": [
    "## 11.3 Exploring the penguins with partial least squares discriminant analysis (PLS-DA)\n",
    "\n",
    "Partial least squares discriminant analysis is essentially PLS for categorical y-variables. Since it works with categorical variables, we can use it for classification and we will do that here. For the most part,\n",
    "[11.3](#11.3-Exploring-the-penguins-with-partial-least-squares-discriminant-analysis-(PLS-DA)) only asks you to run some code and observe the results!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7526592",
   "metadata": {},
   "source": [
    "### 11.3(a) Converting categorical data to numerical values\n",
    "\n",
    "First, we will convert the categorical data in the original data set to numerical values. We have to be\n",
    "careful here and remember that PLS will use these numerical values in calculations. We will,\n",
    "therefore, encode them so that the numbers only have meaning in terms of a variable being \"on\" or \"off\".\n",
    "\n",
    "Since this is also a common strategy to deal with categorical data, there is a method in pandas to do just this\n",
    "and this method is called [get_dummies](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec88660",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dum = pd.get_dummies(data)\n",
    "data_dum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb762008",
   "metadata": {},
   "source": [
    "As you can see from the table above, we have now effectively created one variable per category for the categorical\n",
    "variables.\n",
    "\n",
    "For instance, for \"sex\", we now have \"sex_female\" and \"sex_male\" to distinguish between female and\n",
    "male penguins. You will also note that these two new variables are perfectly correlated:\n",
    "If one of them is 1, then the other has to be 0! This means that we have introduced a lot of correlations in our new data set. If we were doing least squares regression, we would have kept only one of the two variables. We could have fixed that automatically by using\n",
    "```python\n",
    "data_dum = pd.get_dummies(data, drop_first=True)\n",
    "```\n",
    "\n",
    "(This also means that as long as we have only two categories for a variable, `pd.get_dummies(data, drop_first=True)` will just be the same as directly coding the variable as zeros and ones.)\n",
    "\n",
    "Since PLS is supposed to deal with correlated variables, we will keep all variables in the following!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c620c7",
   "metadata": {},
   "source": [
    "### 11.3(b) Creating a PLS model and inspecting loadings\n",
    "\n",
    "We will now create the PLS model. Here, we do not attempt to find the best number of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63de1cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "data_dum = pd.get_dummies(data)\n",
    "\n",
    "xvars = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\n",
    "yvars = [i for i in data_dum.columns if i not in xvars]\n",
    "\n",
    "X = scale(data_dum[xvars].to_numpy())\n",
    "Y = data_dum[yvars].to_numpy()\n",
    "pls = PLSRegression(n_components=4, scale=False)\n",
    "pls.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7faa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loadings_plot(pls_model, xvars, yvars, idx1=0, idx2=1, factor=2.5):\n",
    "    \"\"\"Plot the X and Y loadings for a PLS model.\"\"\"\n",
    "    fig, ax = plt.subplots(constrained_layout=True, figsize=(6, 6))\n",
    "\n",
    "    loadingsx = pls_model.x_rotations_\n",
    "    loadingsy = pls_model.y_loadings_\n",
    "\n",
    "    scat = ax.scatter(loadingsx[:, idx1], loadingsx[:, idx2])\n",
    "    for i, xi in enumerate(xvars):\n",
    "        ax.text(loadingsx[i, idx1], loadingsx[i, idx2], xi)\n",
    "\n",
    "    for i, yvar in enumerate(yvars):\n",
    "        ax.plot(\n",
    "            [0, factor * loadingsy[i, idx1]],\n",
    "            [0, factor * loadingsy[i, idx2]],\n",
    "            color=\"red\",\n",
    "        )\n",
    "        text = yvar.split(\"_\")[1]\n",
    "        ax.text(\n",
    "            factor * loadingsy[i, idx1],\n",
    "            factor * loadingsy[i, idx2],\n",
    "            text,\n",
    "            color=\"red\",\n",
    "            va=\"bottom\" if loadingsy[i, idx2] > 0 else \"top\",\n",
    "            ha=\"center\",\n",
    "        )\n",
    "    ax.axhline(y=0, color=\"k\", ls=\":\")\n",
    "    ax.axvline(x=0, color=\"k\", ls=\":\")\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_xlim(-1, 1)\n",
    "    ax.set_ylim(-1, 1)\n",
    "    ax.set(xlabel=f\"PLS component {idx1+1}\", ylabel=f\"PLS component {idx2+1}\")\n",
    "    ax.set_title(\"Loadings\", loc=\"left\")\n",
    "    sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b296a8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_loadings_plot(pls, xvars, yvars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbb58cb",
   "metadata": {},
   "source": [
    "Run the code above and consider the following:\n",
    "\n",
    "1. On the island of Biscoe, what specie do you expect to find the most of? Is there\n",
    "   a specie you do not expect to find on Biscoe?\n",
    "   \n",
    "2. What features distinguish most between female and male penguins?\n",
    "\n",
    "\n",
    "3. Do you agree with the following statement (why/why not):\n",
    "   \"Gentoo penguins are heavier than the other penguin species\".\n",
    "   \n",
    "\n",
    "4. Do you agree with the following statement (why/why not):\n",
    "   \"Gentoo penguins have a larger flipper length and smaller bill depth\n",
    "   than the other penguins\".\n",
    "   \n",
    "\n",
    "5. Do you agree with the following statement (why/why not):\n",
    "   \"The bill length distinguishes Adelie penguins from the other species."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65c5e01",
   "metadata": {},
   "source": [
    "#### Your answer to question 11.3(b):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6af8cd",
   "metadata": {},
   "source": [
    "## 11.3(c) Predicting the sex of penguins\n",
    "\n",
    "In the [original article](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0090081),\n",
    "the authors created several models to predict the sex of different penguin species. Here is an image with their\n",
    "results:\n",
    "\n",
    "\n",
    "| <img src=\"./Figures/penguintable.png\" width=\"100%\">                                   |\n",
    "|:-:|\n",
    "| **Fig. 3** *Regression models for predicting the sex of penguins.*    |\n",
    "\n",
    "**Note:** In Fig. 3 above, the word *Culmen* is used instead of *bill* (i.e., \"culmen length\" is the same as \"bill length\").\n",
    "\n",
    "We will now repeat this with \n",
    "PLS, and we use only the `sex_female` and `sex_male` variables as our Y.\n",
    "First, we create one model for each penguin specie and we will then inspect their\n",
    "regression coefficients and loadings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd922223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models, one per penguin specie:\n",
    "models = {}\n",
    "yvars_ = [\"sex_female\", \"sex_male\"]\n",
    "xvars = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\n",
    "\n",
    "for specie in data[\"species\"].unique():\n",
    "    data_species = data[data[\"species\"] == specie]\n",
    "    data_dum = pd.get_dummies(data_species)\n",
    "\n",
    "    X = scale(data_dum[xvars].to_numpy())\n",
    "    Y = data_dum[yvars_].to_numpy()\n",
    "    pls_model = PLSRegression(n_components=4, scale=False)\n",
    "    pls_model.fit(X, Y)\n",
    "    models[specie] = pls_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464d835b",
   "metadata": {},
   "source": [
    "### 11.3(c)-1 Regression coefficients and loadings for Adelie penguins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93823fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# First, we create a method for showing regression coefficients:\n",
    "def show_regression_coeffs(pls_model, xvars, yvars):\n",
    "    fig, ax = plt.subplots(constrained_layout=True, figsize=(8, 5))\n",
    "    fig.suptitle(\"Regression coefficients\")\n",
    "    pos = np.arange(len(xvars))\n",
    "\n",
    "    ax.axhline(y=0, ls=\":\", color=\"k\")\n",
    "    width2 = 0.8\n",
    "    width = width2 / 2\n",
    "\n",
    "    B_PLS = pls_model.coef_\n",
    "\n",
    "    r1 = ax.bar(pos - 0.25, B_PLS[0, :], width=width, label=\"Female\")\n",
    "    r2 = ax.bar(pos + 0.25, B_PLS[1, :], width=width, label=\"Male\")\n",
    "\n",
    "    for i in pos:\n",
    "        ax.axvline(x=i + 0.5, ls=\":\", color=\"k\")\n",
    "\n",
    "    ax.set_xticks(pos)\n",
    "    ax.set_xticklabels(xvars, rotation=90)\n",
    "    ax.legend()\n",
    "    sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0a0398",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_regression_coeffs(models[\"Adelie\"], xvars, yvars_)\n",
    "create_loadings_plot(models[\"Adelie\"], xvars, yvars_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59cb4fc",
   "metadata": {},
   "source": [
    "If you have a look at the [image given above](#11.3(c)-Predicting-the-sex-of-penguins)\n",
    "from the original article, you see that the performance of the three models for the Adelie penguins are equal (the same percentage of correct classifications are made). Can you explain this using the plots above (i.e., why do the models not change when the authors introduce more variables)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daaa941",
   "metadata": {},
   "source": [
    "#### Your answer to question 11.3(c)-1:\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b255972",
   "metadata": {},
   "source": [
    "### 11.3(c)-2 Regression coefficients and loadings for Chinstrap penguins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7860448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_regression_coeffs(models[\"Chinstrap\"], xvars, yvars_)\n",
    "create_loadings_plot(models[\"Chinstrap\"], xvars, yvars_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9855bb",
   "metadata": {},
   "source": [
    "For the model for Chinstrap penguins, the authors used only the bill length and bill depth (see the [image given above](#11.3(c)-Predicting-the-sex-of-penguins)). Do you think the model would improve if you also include the body mass?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c5d3bd",
   "metadata": {},
   "source": [
    "#### Your answer to question 11.3(c)-2:\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd5bb81",
   "metadata": {},
   "source": [
    "### 11.3(c)-3 Regression coefficients and loadings for Gentoo penguins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42d6547",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_regression_coeffs(models[\"Gentoo\"], xvars, yvars_)\n",
    "create_loadings_plot(models[\"Gentoo\"], xvars, yvars_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5503d21d",
   "metadata": {},
   "source": [
    "For their model for Gentoo penguins, the authors (see the [image given above](#11.3(c)-Predicting-the-sex-of-penguins)) included the bill length (and excluded the flipper length). Do you think the bill length is\n",
    "needed in the model of Gentoo penguins?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5894d9bd",
   "metadata": {},
   "source": [
    "#### Your answer to question 11.3(c)-3:\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6842f379",
   "metadata": {},
   "source": [
    "## 11.4 Building a logistic regression model for Gentoo penguins\n",
    "\n",
    "As a follow-up of [11.3(c)-3](#11.3(c)-3-Regression-coefficients-and-loadings-for-Gentoo-penguins),\n",
    "let us build the\n",
    "same type of\n",
    "[models as the original authors](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0090081#s2),\n",
    "and compare the effect of including the bill length or not. In the original article,\n",
    "the authors used [Logistic regression]() which essentially is least squares + \"something\" \n",
    "that squashes the straight least squares line into binary results (0 or 1, so that we can use the results\n",
    "for classification). Usually, that \"something\" is a sigmoid function\n",
    "(an \"S\" shaped function).\n",
    "\n",
    "\n",
    "Since the authors report the \"% correctly classified\"\n",
    "(see the [image given above](#11.3(c)-Predicting-the-sex-of-penguins))\n",
    "we will here use the accuracy (for a test set) as our metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6517d128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "xvars1 = [\"bill_length_mm\", \"bill_depth_mm\", \"body_mass_g\"]\n",
    "xvars2 = [\"bill_depth_mm\", \"body_mass_g\"]\n",
    "\n",
    "data_gentoo = data[data[\"species\"] == \"Gentoo\"]\n",
    "\n",
    "X1 = scale(data_gentoo[xvars1])\n",
    "X2 = scale(data_gentoo[xvars2])\n",
    "\n",
    "y = LabelEncoder().fit_transform(data_gentoo[\"sex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a62180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def make_model(X_data, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y, stratify=y)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3763e9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just repeat making the model 10 times:\n",
    "scores1 = [make_model(X1, y) for _ in range(10)]\n",
    "print(f\"Model 1 (X = {xvars1})\")\n",
    "print(f\"\\tAccuracy: {np.mean(scores1):.3g} ± {np.std(scores1):.2g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da511374",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2 = [make_model(X2, y) for _ in range(10)]\n",
    "print(f\"Model 2 (X = {xvars2})\")\n",
    "print(f\"\\tAccuracy: {np.mean(scores2):.3g} ± {np.std(scores2):.2g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52421112",
   "metadata": {},
   "source": [
    "Based on the results above, would you say that there is a big effect of including the bill length in the\n",
    "model for Gentoo penguins?\n",
    "Is this in agreement with your answer to [11.3(c)-3](#Your-answer-to-question-11.3(c)-3:)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ee7993",
   "metadata": {},
   "source": [
    "#### Your answer to question 11.4:\n",
    "*Double click here*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

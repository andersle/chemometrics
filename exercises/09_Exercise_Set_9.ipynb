{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise set 9\n",
    "\n",
    "> *  The goal of the first part of the exercise is to get familiarity with partial least\n",
    "> squares regression. For this, we will make\n",
    "> a model that can predict the concentrations in a mixture from near-infrared spectra.\n",
    "> \n",
    "> *  In the second part of the exercise, you will do a PCA analysis of gene expressions.\n",
    "> The goal\n",
    "> of this part is to get more experience with PCA, and in particular\n",
    "> with interpreting results from PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9.1\n",
    "\n",
    "[Windig and Stephenson](https://doi.org/10.1021/ac00046a015) have measured near-infrared spectra\n",
    "for 140 mixtures of the solvents methylene chloride, 2-butanol, methanol,\n",
    "dichloropropane, and acetone. We will in this exercise see if we can\n",
    "predict the compositions of the mixtures from the spectra.\n",
    "Each of the $140$ spectra has been sampled at $700$ wavelengths\n",
    "between $1100$ and $2500$ nm. The raw data containing the spectra\n",
    "and the corresponding concentrations can be found in the file\n",
    "[`Data/windig.csv`](Data/windig.csv).\n",
    "\n",
    "The raw data for this exercise can\n",
    "be loaded as shown below.\n",
    "Each row in the $\\mathbf{X}$ matrix\n",
    "contains a spectrum (700 intensities -- each column is\n",
    "a specific wavelength) and each row in the\n",
    "$\\mathbf{Y}$ matrix contains the measured concentrations\n",
    "of the solvents in the order given above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"Data/windig.csv\")\n",
    "X = data.filter(like=\"data\", axis=1).values  # NIR spectra\n",
    "Y = data.filter(like=\"concentrations\", axis=1).values  # Concentrations\n",
    "print(f\"No. of spectra: {X.shape[0]}\")\n",
    "print(f\"No. of wavelengths: {X.shape[1]}\")\n",
    "print(f\"No of concentration samples: {Y.shape[0]}\")\n",
    "print(f\"No of species in each sample: {Y.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)**  Create a partial least squares regression (PLSR) model for predicting\n",
    "the concentrations. Use 1 PLS component for your first model and\n",
    "assess it using $R^2$, RMSEC, RMSECV and RMSEP. An example\n",
    "of how this can be done are given below.\n",
    "\n",
    "These values (RMSEC, RMSECV, and RMSEP) are all based on calculating the\n",
    "root mean squared error (RMSE) given by,\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^N (y_i - \\hat{y}_i)^2},\n",
    "\\tag{1}\\end{equation}\n",
    "\n",
    "where $y_i$ are our measured $y$-values and $\\hat{y}_i$ are the\n",
    "values predicted by our model. The difference between RMSEC,\n",
    "RMSEP, and RMSECV lies in the part of the data we use to\n",
    "calculate them. This is based on first splitting the data into\n",
    "a *training* and *test* set, and then\n",
    "performing what we call\n",
    "*cross-validation* using\n",
    "the training set:\n",
    "\n",
    "\n",
    "*  When we use the training set to create our model, we are doing\n",
    "   a *calibration*. If we calculate RMSE based on using\n",
    "   the training set, we refer to this as the RMSEC (root mean squared\n",
    "   error of calibration).\n",
    "   This number\n",
    "   quantifies the error we get in connection with making (calibrating)\n",
    "   the model.\n",
    "\n",
    "\n",
    "*  When we use the test set to test our model, we are\n",
    "   checking how well our model *predicts* \"new\" samples\n",
    "   (that is, samples that were not used when making the model). If\n",
    "   we calculate RMSE based on the training set, we refer to \n",
    "   this as the RMSEP (root mean squared error of prediction). This\n",
    "   number quantifies the error we can expect to make when using\n",
    "   our model for predicting samples that were not used when making\n",
    "   the model.\n",
    "\n",
    "\n",
    "*  Cross-validation is based on doing a further split\n",
    "   of the training set. Typically, we split the training set into\n",
    "   $k$ smaller subsamples and we repeat the fitting of the\n",
    "   model $k$ times.\n",
    "   For each time we repeat the fitting, we retain a single\n",
    "   subsample for validation, and we fit the model using the\n",
    "   $k-1$ other subsamples. For the subsample we retained\n",
    "   for validation, we can calculate the RMSE value of how\n",
    "   well this is predicted by our model. Since we repeat this $k$ times,\n",
    "   we can make it so that each of the $k$ subsamples is\n",
    "   used exactly once for validation. Finally, we can\n",
    "   obtain the average RMSE of the $k$ fittings and we\n",
    "   refer to this value as the RMSECV (root mean squared error\n",
    "   of cross-validation). This number indicates how well\n",
    "   our model predict samples that were obtained among\n",
    "   the calibration cases. In addition to obtaining\n",
    "   the average, we can also obtain a standard deviation.\n",
    "   We can use this to see how sensitive the model parameters\n",
    "   are to the training set.\n",
    "   \n",
    "\n",
    "Luckily, methods for splitting our data into training and test\n",
    "sets, calculating RMSE, and doing cross-validation are already\n",
    "available in sklearn. There is also\n",
    "a nice illustration of cross-validation in the\n",
    "[scikit-learn documentation](https://scikit-learn.org/stable/modules/cross_validation.html):\n",
    "\n",
    "![cross](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Example for RMSEC, RMSEP and RMSECV\"\"\"\n",
    "import numpy as np\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_val_score,\n",
    ")\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True)  # Load example data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,  # Use 20 % of the data for the test set.\n",
    "    shuffle=True,  # Randomly shuffle the data\n",
    ")\n",
    "\n",
    "# Make a model using the training set:\n",
    "# PLS regression with one PLS component/latent variable:\n",
    "model = PLSRegression(n_components=1)\n",
    "model.fit(X_train, y_train)\n",
    "# Predict using the training set:\n",
    "y_hat_train = model.predict(X_train)\n",
    "# Predict using the test set:\n",
    "y_hat_test = model.predict(X_test)\n",
    "\n",
    "# For training set: calculate R^2 and RMSEC:\n",
    "r2_train = r2_score(y_train, y_hat_train)\n",
    "rmsec = np.sqrt(mean_squared_error(y_train, y_hat_train))\n",
    "print(f\"R² (training): {r2_train}\")\n",
    "print(f\"RMSEC: {rmsec}\")\n",
    "\n",
    "# For test set: calculate R^2 and RMSEP:\n",
    "r2_test = r2_score(y_test, y_hat_test)\n",
    "rmsep = np.sqrt(mean_squared_error(y_test, y_hat_test))\n",
    "print(f\"\\nR² (test): {r2_test}\")\n",
    "print(f\"RMSEP: {rmsep}\")\n",
    "\n",
    "# Run cross-validation:\n",
    "cvscore = cross_val_score(\n",
    "    model,  # Select the model we are going to score\n",
    "    X_train,  # Give the X-training set\n",
    "    y_train,  # Give the y-training set\n",
    "    scoring=\"neg_mean_squared_error\",  # select scoring method\n",
    "    cv=5,  # Number of splits to make\n",
    ")\n",
    "\n",
    "# Note: the scoring is here \"neg_mean_squared_error\".\n",
    "# This is the negative of the MSE!\n",
    "# The cross_val_score method is often used in\n",
    "# connection with optimization where we would like to\n",
    "# maximize something, and the score can be used to pick\n",
    "# the best value. Since we usually do not want to\n",
    "# maximize the error, this method is made so that it\n",
    "# calculates the negative of the error.\n",
    "\n",
    "cvscore = np.sqrt(-cvscore)  # Account for the negative sign.\n",
    "rmsecv = cvscore.mean()\n",
    "rmsecv_std = np.std(cvscore)\n",
    "print(f\"\\nRMSECV: {rmsecv} ± {rmsecv_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer to question 9.1(a):** *Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** Improve your PLSR model by including more\n",
    "PLS components. Try components in the\n",
    "range from 2 up to 15 and compare the different models. How many\n",
    "PLS components are you satisfied with? In the following, we will refer\n",
    "to the model you are most satisfied with as \"model A\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer to question 9.1(b):** *Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)**  Plot the regression coefficients for model A (see point **(b)**).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer to question 9.1(c):** *Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d)**  If you are given a new spectrum of a mixture of methylene chloride,\n",
    "2-butanol, methanol, dichloropropane, and acetone, how well would\n",
    "your model A predict the concentrations of the different solvents\n",
    "in the mixture?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer to question 9.1(d):** *Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e)**  Create a least squares model for predicting the concentrations.\n",
    "Assess it using $R^2$, RMSEC, RMSECV and RMSEP. Does this model\n",
    "perform as you expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer to question 9.1(e):** *Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9.2\n",
    "\n",
    "[Schummer *et al.*](https://doi.org/10.1016/S0378-1119(99)00342-X) studied ovarian cancer by measuring gene expression\n",
    "values for $1536$ genes in both normal and tumor tissues. One of their goals was\n",
    "to find genes that were overexpressed in tumor samples compared with normal samples.\n",
    "This knowledge may be used for tumor diagnosis and we will here see if we\n",
    "can find such genes by performing a PCA. The raw data can be\n",
    "found in the file [`Data/ovo.csv`](Data/ovo.csv)  and can be loaded as\n",
    "follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load the data set.\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"Data/ovo.csv\")\n",
    "classes = data[\"objlabels\"]  # Classification of samples.\n",
    "X = data.filter(like=\"X.\", axis=1)  # Gene expressions for samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in the matrix\n",
    "$\\mathbf{X}$ contains the gene expression (for 1536 genes) for a\n",
    "tissue sample. Each column corresponds to a specific gene.\n",
    "The classification of tissue as normal (\"N\") or cancer (\"C\") can\n",
    "be found in the variable \"classes\" defined above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)**   Perform a principal component analysis (PCA) on the gene expression data,\n",
    "and obtain the explained variance when using 1, 2, 5, and 10\n",
    "components.\n",
    "\n",
    "Center the data before performing the PCA. This can be\n",
    "done as follows with the `scale` method\n",
    "from `sklearn.preprocessing`: `X = scale(X, with_std=False)`.\n",
    "Here, all the variables are in the same units, so we do not need\n",
    "to scale the variance (we set `with_std=False`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer to question 9.2(a):** *Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** Inspect the data by plotting the scores and loadings for\n",
    "principal component\n",
    "number 1 and principal component number 2:\n",
    "\n",
    "\n",
    "* (i)  Can you observe any clustering\n",
    "  of the samples? Here, it is helpful to color the samples\n",
    "  according to their classification as normal or cancer.\n",
    "\n",
    "\n",
    "* (ii) Are there any outliers among the samples?\n",
    "\n",
    "\n",
    "* (iii) Can you identify some\n",
    "  genes which are overexpressed in tumors? \n",
    "\n",
    "\n",
    "* (iv) Can you identify some\n",
    "  genes which are underexpressed in tumors? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer to question 9.2(b):** *Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)**  Based on your answer in **(b)**, can\n",
    "you identify some pairs of genes that seem to distinguish between\n",
    "normal and tumor tissues? Support your findings by plotting the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer to question 9.2(c):** *Double click here*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

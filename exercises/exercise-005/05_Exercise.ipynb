{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b166dea2",
   "metadata": {},
   "source": [
    "# Exercise set 5: PCA, clustering, and outliers in least squares\n",
    "\n",
    "The main goals of this exercise are to use PCA\n",
    "\n",
    "**Learning Objectives:**\n",
    "\n",
    "After completing this exercise set, you will be able to:\n",
    "\n",
    "- Use PCA to find interesting variables.\n",
    "- Find outliers in connection with least squares.\n",
    "- Run agglomerative clustering and interpret a dendrogram.\n",
    "\n",
    "**To get the exercise approved, complete the following problems:**\n",
    "\n",
    "* [5.2(b)](#5.2(b)) and [5.2(c)](#5.2(c)): To show that you find outliers in connection with least squares.\n",
    "* [5.3(a)](#5.3(a)) and [5.3(b)](#5.3(b)): To show that you can run agglomerative clustering, make a dendrogram and interpret it.\n",
    "\n",
    "**Files required for this exercise:**\n",
    "* [Exercise 5.1](#Exercise-5.1): [ovo.csv](ovo.csv)\n",
    "* [Exercise 5.2](#Exercise-5.2): [forbes.csv](forbes.csv)\n",
    "* [Exercise 5.3](#Exercise-5.3): [zoo.csv](zoo.csv)\n",
    "\n",
    "Please ensure that these files are saved in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3b3382",
   "metadata": {},
   "source": [
    "## Exercise 5.1\n",
    "[Schummer *et al.*](https://doi.org/10.1016/S0378-1119(99)00342-X) used microarray technology to analyse the expression of 1536 genes in ovarian cancer and non-cancer tissues. Their primary objective was to identify differentially expressed genes in ovarian cancer versus non-cancer tissues to discover genes with diagnostic potential.\n",
    "\n",
    "The data file [`ovo.csv`](ovo.csv) contains numerical gene expressions (for 1536 genes) for 54 tissue samples. Each column corresponds to a specific gene, named `X.1`, `X.2`, and so on. Each tissue sample has been classified as non-cancer (`N`) or cancer (`C`) tissue, and these labels can be found in the column `class`. The raw data has been preprocessed by centring each gene expression so that no further preprocessing is needed. The raw data can be loaded as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a776ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data set\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_theme(style=\"ticks\", context=\"notebook\", palette=\"colorblind\")\n",
    "\n",
    "data_ovo = pd.read_csv(\"ovo.csv\")\n",
    "classes = data_ovo[\"class\"]  # Classification of samples.\n",
    "X_ovo = data_ovo.filter(like=\"X.\", axis=1)  # Gene expressions for samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bca546",
   "metadata": {},
   "source": [
    "### 5.1(a)\n",
    "\n",
    "**Task: Explore the raw data. Do you find genes that appear to show significant differences in expression between non-cancer and cancer tissue?**\n",
    "\n",
    "**Hint:** You can, for instance, explore the data by running a principal component analysis. If you want to avoid making the PCA plots from scratch, try the [yellowbrick library](https://www.scikit-yb.org/en/latest/api/features/pca.html) to visualise the scores and loadings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973f29ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2076b442",
   "metadata": {},
   "source": [
    "#### Your answer to question 5.1(a): Did you find any promising genes?\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a750c157",
   "metadata": {},
   "source": [
    "## Exercise 5.2\n",
    "[Forbes](https://doi.org/10.1017/S0080456800032075) investigated the\n",
    "relationship between the boiling point of water and the atmospheric pressure, and collected data in the Alps and Scotland. Forbes' goal was to estimate altitudes from the boiling point alone.\n",
    "\n",
    "We will use Forbes' data to make a linear model for predicting the atmospheric pressure, and we will investigate if there are any outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358a7a05",
   "metadata": {},
   "source": [
    "### 5.2(a)\n",
    "\n",
    "**Task: Create a linear model that predicts the atmospheric pressure\n",
    "from the boiling point\n",
    "with `statsmodels`. Plot your model together with the raw data, and plot the residuals. Do you have\n",
    "any comments about the residuals?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4fdf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is some code to get you started:\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ec8048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the code above fails because you do not have statsmodels installed,\n",
    "# you can uncomment and run this:\n",
    "#!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cfddd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The raw data can be loaded with:\n",
    "data_forbes = pd.read_csv(\"forbes.csv\")\n",
    "data_forbes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d984295a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create the least squares model with statsmodels:\n",
    "x = data_forbes[\"Temperature (F)\"]\n",
    "y = data_forbes[\"Pressure (inches Hg)\"]\n",
    "\n",
    "X = sm.add_constant(x)  # Make a matrix with a column of ones and then x.\n",
    "\n",
    "model = sm.OLS(y, X)  # Set up for OLS = Ordinary Least Squares.\n",
    "results = model.fit()  # Find parameters.\n",
    "y_hat = results.predict(X)  # Use the model to predict y_hat.\n",
    "\n",
    "# Print a small summary to show RÂ² and the coefficients:\n",
    "print(results.summary(slim=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbde6ed",
   "metadata": {},
   "source": [
    "**Note:** A description of the summary from statsmodels can be found in the [Appendix](#Appendix:-The-summary-results-from-statsmodels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2317b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf872596",
   "metadata": {},
   "source": [
    "#### Your answer to question 5.2(a): Do you have any comments about the residuals?\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcac28d6",
   "metadata": {},
   "source": [
    "### 5.2(b)\n",
    "\n",
    "**Task: Obtain different outlier measures and plot them. Do you see any potential outliers?**\n",
    "\n",
    "**Hint**: Calculate [influence/outlier measures with statsmodels](https://www.statsmodels.org/dev/generated/statsmodels.stats.outliers_influence.OLSInfluence.html#statsmodels.stats.outliers_influence.OLSInfluence) and plot the following:\n",
    "\n",
    "* (i) the studentised residuals,\n",
    "* (ii) the leverage ($h_{ii}$ from the $\\mathbf{H}$-matrix),\n",
    "* (iii) the Cook's distance, and\n",
    "* (iv) the [influence plot](https://www.statsmodels.org/dev/generated/statsmodels.graphics.regressionplots.influence_plot.html).\n",
    "\n",
    "You can find example code for doing this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2985919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The influence measures can be computed with:\n",
    "influence = results.get_influence()\n",
    "\n",
    "# The measures can be converted to a pandas data frame with:\n",
    "influence_table = influence.summary_frame()\n",
    "\n",
    "# And they can be accessed as follows:\n",
    "# (i) studentised residuals:\n",
    "studentised_residuals = influence_table[\"student_resid\"]\n",
    "\n",
    "# (ii) the leverage:\n",
    "hii = influence_table[\"hat_diag\"]\n",
    "\n",
    "# (iii) Cook's distance\n",
    "cooks_distance = influence_table[\"cooks_d\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1a0b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your plots (i)-(iii) here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875e13de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The influence plot, part (iv) can be created with:\n",
    "fig = influence.plot_influence()\n",
    "ax = fig.get_axes()[0]\n",
    "ax.set_ylim(-1.3, 3.5)\n",
    "ax.set_title(\"\")\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f955be",
   "metadata": {},
   "source": [
    "#### Your answer to question 5.2(b): Do you see any potential outliers?\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5a7e7c",
   "metadata": {},
   "source": [
    "### 5.2(c)\n",
    "\n",
    "**Task: Run a hypothesis test for outliers. Are any points marked as outliers?**\n",
    "\n",
    "**Hint:** You use the [outlier test](https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLSResults.outlier_test.html)\n",
    "method from `statsmodels` to run the hypothesis test (see the code in the cell below).\n",
    "\n",
    "This test outputs:\n",
    "* `student_resid`: The studentised residuals.\n",
    "* `unadj_p`: The unadjusted p-value for the hypothesis test that the expected value of the studentized residual for point *i* is zero, under the null hypothesis that the point is not an outlier.\n",
    "* `bonf(p)`: A Bonferroni corrected p-value, which adjusts for the increased risk of Type I errors (mistaken rejection of a true null hypothesis) due to multiple comparisons.\n",
    "\n",
    "The `outlier_test` method tests the null hypothesis that each point is not an outlier by considering if its studentized residual is significantly different from zero. Since we perform this test *N* times for *N* points, the risk of incorrectly labelling at least one point as an outlier (Type I error) increases. To mitigate this, `outlier_test` will apply a [correction](https://en.wikipedia.org/wiki/Bonferroni_correction), and we should base our decisions on these corrected p-values.\n",
    "\n",
    "You can identify a point as an outlier if the corrected p-value is smaller than the significance level, set to `alpha = 0.05` by default in the `outlier_test()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c711584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how you run the hypothesis test:\n",
    "test = results.outlier_test()\n",
    "test[test[\"bonf(p)\"] < 0.05]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d87cec0",
   "metadata": {},
   "source": [
    "#### Your answer to question 5.2(c): Were any points identified as outliers?\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccb7f50",
   "metadata": {},
   "source": [
    "### 5.2(d)\n",
    "\n",
    "**Task: You should have found one outlier in the previous problem. Remake the model without this point and\n",
    "compare it with the model you made in part [5.2(a)](#5.2(a)). Did the model change substantially?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2b57e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122fa200",
   "metadata": {},
   "source": [
    "#### Your answer to question 5.2(d): Did removing the outlier change the model substantially?\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a006e5",
   "metadata": {},
   "source": [
    "## Exercise 5.3\n",
    "The data file [zoo.csv](zoo.csv) contains some data on different animals:\n",
    "\n",
    "| Column | Description |\n",
    "| :---  | :--- |\n",
    "| `animal name` | The name for the animal (e.g., lion, penguin). |\n",
    "| `hair` | Does the animal have hair or fur? (0=no/1=yes) |\n",
    "| `feathers` | Does the animal have feathers? (0=no/1=yes) |\n",
    "| `eggs` | Does the animal lay eggs? (0=no/1=yes) |\n",
    "| `milk` | Does the animal provide milk for its young? (0=no/1=yes) |\n",
    "| `airborne` | Does the animal fly? (0=no/1=yes) |\n",
    "| `aquatic` | Does the animal live in or depend on water? (0=no/1=yes) |\n",
    "| `predator` | Does the animal hunt other animals? (0=no/1=yes) |\n",
    "| `toothed` | Does the animal have teeth? (0=no/1=yes) |\n",
    "| `backbone` | Does the animal have a spine? (0=no/1=yes) |\n",
    "| `breathes` | Does it breathe air (using lungs)? (0=no/1=yes) |\n",
    "| `venomous` | Does the animal produce toxins or venom? (0=no/1=yes) |\n",
    "| `fins` | Does the animal have fins for swimming? (0=no/1=yes) |\n",
    "| `legs` | The number of legs (normalised to the range 0 to 1). |\n",
    "| `tail` | Does the animal have a tail? (0=no/1=yes) |\n",
    "| `domestic` | Is it commonly domesticated by humans? (0=no/1=yes)|\n",
    "| `catsize` | Is the animal larger than a housecat? (0=no/1=yes) |\n",
    "\n",
    "\n",
    "We will use clustering on this data set to see if we can group animals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d39bf0",
   "metadata": {},
   "source": [
    "### 5.3(a)\n",
    "\n",
    "**Task: Run the code below to perform [Agglomerative clustering](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html) for the data in [zoo.csv](zoo.csv).**\n",
    "\n",
    "\n",
    "**Note:** As you may have noticed, we have many binary variables and one numerical variable (`legs`). Mixing variable types can be problematic when we are calculating a distance. We will ignore the potential issues related to this in this exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad56f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib notebook\n",
    "sns.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9584b78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data:\n",
    "data_zoo = pd.read_csv(\"zoo.csv\")\n",
    "data_zoo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b3bd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store some variables\n",
    "animal_names = data_zoo[\"animal name\"].values\n",
    "variables = [i for i in data_zoo.columns if i not in (\"animal name\",)]\n",
    "X_zoo = data_zoo[variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2bb5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the clustering class:\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27bef15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the clustering:\n",
    "model0 = AgglomerativeClustering(\n",
    "    n_clusters=1,\n",
    "    linkage=\"average\",\n",
    "    metric=\"sokalmichener\",\n",
    "    compute_distances=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Here:\n",
    "# n_clusters: Stop the clustering when n_clusters are found. Here it is set to 1, meaning that we will stop\n",
    "# when there is one cluster.\n",
    "# linkage: Selects the method for computing distances between clusters. Here it is set to average, meaning that\n",
    "# it calculates the average distance between the points in the clusters.\n",
    "# metric: Selects how the distances are calculated. Here \"sokalmichener\" selects a Sokal-Michener distance that takes\n",
    "# both matches and dissimilarities into account. We are not using an Euclidean distance since we have\n",
    "# almost exclusively boolean variables (0/1).\n",
    "# compute_distances: Set to True, meaning that distances (for visualisation in a dendrogram) are computed.\n",
    "\n",
    "# Run the clustering:\n",
    "model0.fit(X_zoo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f75d6a",
   "metadata": {},
   "source": [
    "**Note:** You can select different options for the `linkage` and the `metric` to see how this influences the results (the dendrogram produced in the next problem). Please see the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html) for options."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4723328a",
   "metadata": {},
   "source": [
    "### 5.3(b)\n",
    "\n",
    "**Task: Run the code below to create the dendrogram of the clustering performed above. Then consider the following:**\n",
    "1. What animal is \"human\" most similar to?\n",
    "2. What animal is \"platypus\" most similar to?\n",
    "3. What animal is least similar to any of the others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05154e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create the dendrogram, use this code:\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "\n",
    "def plot_dendrogram(model, **kwargs):\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "    # Create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack(\n",
    "        [model.children_, model.distances_, counts]\n",
    "    ).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19255853",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(constrained_layout=True, figsize=(8, 4))\n",
    "plot_dendrogram(\n",
    "    model0,\n",
    "    truncate_mode=\"level\",\n",
    "    labels=animal_names,\n",
    "    ax=axes,\n",
    "    p=100,\n",
    "    leaf_rotation=90,\n",
    ")\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cec7bd",
   "metadata": {},
   "source": [
    "#### Your answer to question 5.3(b):\n",
    "\n",
    "*Double click here*\n",
    "\n",
    "1. What animal is \"human\" most similar to?\n",
    "2. What animal is \"platypus\" most similar to?\n",
    "3. What animal is least similar to any of the others?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise set 10**\n",
    "==============\n",
    "\n",
    "\n",
    ">The goal of this exercise is to gain familiarity with some\n",
    ">classification methods and the different ways we can assess and compare them.\n",
    "\n",
    "\n",
    "**Exercise 10.1**\n",
    "\n",
    "\n",
    "In this exercise, we will consider the\n",
    "[UCI ML Breast Cancer Wisconsin (Diagnostic) dataset](https://goo.gl/U2Uwz2).\n",
    "\n",
    "This data set contains $569$ tumors which have been classified\n",
    "as malignant or benign. In addition, $30$ variables have been\n",
    "measured and it is our goal to make a predictive model which\n",
    "can classify new tumors as being malignant or benign.\n",
    "An overview of the different variables can be found\n",
    "on the [`sklearn` website](https://scikit-learn.org/stable/datasets/index.html#breast-cancer-dataset).\n",
    "\n",
    "In the following, we are going to label the two classes as:\n",
    "\n",
    "* \"benign\" as a negative, and\n",
    "\n",
    "* \"malignant\" as a positive.\n",
    "\n",
    "\n",
    "**(a)**  Begin the exercise by loading the raw data, and creating a test set.\n",
    "Create the test set using 33 % of the available data points for the test set.\n",
    "The data set itself can be loaded directly from `sklearn`\n",
    "as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data['data']\n",
    "# \"Rename\" y so that 0 = benign and 1 = malignant:\n",
    "y = [0 if i == 1 else 1 for i in data['target']]\n",
    "class_names = ['benign', 'malignant']\n",
    "print('Classes:')\n",
    "print(class_names)\n",
    "\n",
    "print('Variables:')\n",
    "print(data['feature_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test set can be created by using the method\n",
    "`train_test_split` which can be found in the module\n",
    "`sklearn.model_selection`. One of the input parameters to `train_test_split` is\n",
    "`stratify`. Reading the documentation for [`stratification`](https://scikit-learn.org/stable/modules/cross_validation.html#stratification)\n",
    "can you explain what this parameter does? And is it important for the data set we\n",
    "are considering here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer to question 10.1(a):** *Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** In this case, we have to determine what\n",
    "quantity we are going to use\n",
    "to compare the different classification methods. Before selecting\n",
    "what quantity to use, we should consider what false positives and false negatives\n",
    "mean in our current context. How would you define these two terms in our present\n",
    "case, and would you say that false positives are a more serious mistake to make\n",
    "than false negatives?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer to question 10.1(b):** *Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** Following up on the previous question, here\n",
    "are some possible metrics we could use to assess the performance of a\n",
    "classifier model we <abbr title=\"Note: There are other possibilities\n",
    "as well! If you are curious you can for instance include the\n",
    "*Accuracy* which is  the ratio of correct predictions\n",
    "to the number of total predictions.\">make:</abbr>\n",
    "\n",
    "\n",
    "* (i)  Precision: The ratio of true positives to the sum of true positives and false positives.\n",
    "\n",
    "* (ii)  Recall: The ratio of true positives to the sum of true positives and false negatives.\n",
    "\n",
    "* (iii)  F1: The (harmonic) mean of the precision and recall.\n",
    "\n",
    "In addition, we can summarize the performance using the *confusion matrix*.\n",
    "\n",
    "The choice of the metric for assessing a classifier will lead to different results.\n",
    "For instance, if we choose to use use the precision as our metric, we will maximize it\n",
    "during the optimization of our model. This means that we will *minimize* the\n",
    "number of *false positives*. If we choose to use the recall, on the other hand,\n",
    "we will *minimize* the number of *false negatives*.\n",
    "\n",
    "\n",
    "In the following, we will calculate all these metrics for the\n",
    "different classification methods we consider. At the end of the\n",
    "exercise, you will be asked to compare the different classifiers\n",
    "using them. \n",
    "\n",
    "But before we do that: Which of the\n",
    "aforementioned metrics would you say is most important for\n",
    "the classification task we have here? Base this on your answer to\n",
    "the previous point.\n",
    "\n",
    "**Note:** There is no single correct answer here, and it\n",
    "really depends on how *you* judge the seriousness of false positives vs.\n",
    "false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer to question 10.1(c):** *Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d)**  Create a $k$-nearest neighbor classifier(\n",
    "This classifier is available from\n",
    "`sklearn.neighbors.KNeighborsClassifier`\n",
    ") with $3$ neighbors and\n",
    "fit it using your training set. Evaluate (with the test set) the classifier using the\n",
    "precision, recall, and F1 metrics, and plot the confusion matrix.\n",
    "\n",
    "The different metrics are available in the `sklearn.metrics` module.\n",
    "Here, there is also a method, `plot_confusion_matrix` which you\n",
    "can use for plotting the confusion matrix.\n",
    "\n",
    "How many false positives and false negatives do you get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer to question 10.1(d):** *Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e)**  We will now try to optimize the $k$ for a $k$-nearest neighbor classifier.\n",
    "This can be done using the method [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html).\n",
    "\n",
    "One of the inputs to this method is the `scoring` parameter, which\n",
    "selects the metric to use for finding the best $k$. Here, use the metric\n",
    "you deemed most important in question **10.1.(c)**.\n",
    "\n",
    "When using `GridSearchCV`, consider $k$-values in the range $1 \\leq k \\leq 10$\n",
    "for your search for the best $k$.\n",
    "\n",
    "Evaluate the classifier with the best $k$ using\n",
    "all of the aforementioned metrics (with the test set) and plot the confusion matrix.\n",
    "\n",
    "What value for $k$ did you find in this case? And did the number of false\n",
    "positives and false negatives change compared to the non-optimized $k$-nearest neighbor classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer to question 10.1(e):** *Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(f)**  Create a decision tree classifier (This classifier is available from\n",
    "`sklearn.tree.DecisionTreeClassifier`) and fit it using your training set. Limit the tree to $3$ levels by setting\n",
    "the parameter `max_depth=3`.\n",
    "\n",
    "Evaluate the classifier using the\n",
    "aforementioned metrics (with the test set) and plot the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer to question 10.1(f):** *Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(g)**  We will also\n",
    "try to tune the `DecisionTreeClassifier`\n",
    "by determining the maximum depth\n",
    "we should use for the tree. Again, you can use the method\n",
    "`GridSearchCV` to optimize the parameter\n",
    "`max_depth` for the `DecisionTreeClassifier`.\n",
    "Use the metric you deemed most important\n",
    "in question **10.1(c)** and consider depths\n",
    "in the range `max_depth = range(1, 21)`, and, in addition,\n",
    "a depth\n",
    "where you set `max_depth = None` (this lets the\n",
    "tree expand as far down as possible).\n",
    "\n",
    "Evaluate the classifier with the best `max_depth` using the\n",
    "aforementioned metrics (with the test set) and plot the confusion matrix.\n",
    "\n",
    "What is the best `max_depth` you find in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer to question 10.1(g):** *Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(h)**  Visualize the decision tree with 3 levels. This\n",
    "can be done using the method `export_graphviz`\n",
    "from `sklearn.tree`, or the method `plot_tree`\n",
    "from `sklearn.tree`. (Please\n",
    "see the sklearn [`tree`](https://scikit-learn.org/stable/modules/tree.html) documentation and documentation for using [`export_graphviz`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer to question 10.1(h):** *Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(i)**  Compare the precision, recall, and F1 scores for all\n",
    "the classifiers you have considered.\n",
    "\n",
    "If you were to select one\n",
    "classifier to put into real-life use, which one would you choose and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer to question 10.1(i):** *Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(j)**  Extra task for the curious student: Create an alternative classifier, for instance,\n",
    "using a so-called support vector machine. We will not go into the details about how\n",
    "this classifier works in our lectures, but with `sklearn` it is rather easy\n",
    "to just try\n",
    "it and see what it can do for us. In sklearn this is available as the\n",
    "object `SVC` from `sklearn.svm`.\n",
    "\n",
    "There is [an example](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html) that will compare several classifiers, and maybe you\n",
    "can find one that performs better than the ones\n",
    "we have considered so far in this exercise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer to question 10.1(j):** *Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 10.2**\n",
    "\n",
    "Consider again the data set for ovarian cancer and the measured gene expressions (see exercise 9).\n",
    "Create a decision tree classifier for this data set. Limit the depth of the decision\n",
    "tree to 2, and visualize the decision tree. How do the \"rules\" the decision tree\n",
    "is using for its classification compare to what you found from the PCA analysis?\n",
    "Does it consider the same genes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer to question 10.2:** *Double click here*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

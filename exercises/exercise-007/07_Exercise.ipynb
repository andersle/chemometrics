{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "801b2291",
   "metadata": {},
   "source": [
    "# Exercise set 7: Signal processing\n",
    "\n",
    "The main goal of this exercise is to gain practical experience with signal processing techniques used for preprocessing, for instance, of Near-Infrared (NIR) spectra. Preprocessing methods are important for improving the signal-to-noise ratio, correcting for scattering effects (variations in light path due to particle size, etc.), and enhancing spectral features, which can lead to more reliable analysis and development of robust predictive models. In addition, you will see how we can smooth noisy signals and calculate the derivative of a noisy signal.\n",
    "\n",
    "**Learning Objectives:**\n",
    "\n",
    "After completing this exercise set, you will be able to:\n",
    "\n",
    "- Preprocess spectra by normalisation, multiplicative scatter correction, or taking a second derivative.\n",
    "- Create a spline to smooth a signal and compute its derivative.\n",
    "\n",
    "**To get the exercise approved, complete the following problems:**\n",
    "\n",
    "- [7.1(a)](#7.1(a)) and at least one of [7.1(b)](#7.1(b)), [7.1(c)](#7.1(c)), or [7.1(d)](#7.1(d)): To show that you can apply preprocessing to NIR spectra.\n",
    "- [7.2(a)](#7.2(a)) and [7.2(c)](#7.2(c)): To show that you can create a B-spline to smooth a signal and compute its derivative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0b4748",
   "metadata": {},
   "source": [
    "## Exercise 7.1 Preprocessing NIR spectra\n",
    "\n",
    "We will analyze NIR spectra from two distinct Ethiopian [sorghum](https://en.wikipedia.org/wiki/Sorghum) cultivars to determine if they can be differentiated. Specifically, we will examine how different preprocessing techniques impact the outcome of a principal component analysis (PCA) applied to the spectra. \n",
    "\n",
    "**Note:**\n",
    "\n",
    "1. The dataset used in this exercise is derived from [Kosmowski and Worku\n",
    "](https://doi.org/10.1371/journal.pone.0193620) who used a miniaturised NIR spectrometer to identify Ethiopian crop cultivars. To simplify the analysis, we focus on measurements from only two of the ten sorghum cultivars studied in the original work\n",
    "\n",
    "2. This exercise will mainly ask you to run and observe results from already implemented code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556ace50",
   "metadata": {},
   "source": [
    "### 7.1(a)\n",
    "\n",
    "The following code performs these steps:\n",
    "\n",
    "1. Load the NIR spectra from the data file [nir.csv](./nir.csv).\n",
    "2. Extracts wavelengths, spectra, and cultivar names.\n",
    "3. Defines colors for plotting cultivars.\n",
    "4. Creates a function to plot spectra by cultivar.\n",
    "5. Creates a function to run a PCA on provided spectra and plot the scores of the first two principal components.\n",
    "6. Initializes a figure for results.\n",
    "7. Plots the original spectra and the PCA results.\n",
    "\n",
    "**Task: Execute the code and observe the generated plot. In the PCA scores plot, are there any noticeable groupings that suggest cultivar separation?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f161cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the needed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_theme(style=\"ticks\", context=\"notebook\", palette=\"colorblind\")\n",
    "\n",
    "# Load the raw data:\n",
    "data = pd.read_csv(\"nir.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb1b93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract information from the data\n",
    "\n",
    "variables = [i for i in data.columns if i != \"Cultivator\"]\n",
    "# Wavelengths as numbers:\n",
    "wavelengths = np.array([float(i) for i in variables])\n",
    "print(f\"Number of wavelengths {len(wavelengths)}\")\n",
    "# All spectra as a data matrix:\n",
    "all_spectra = data[variables].to_numpy()\n",
    "print(f\"Size of data matrix: {all_spectra.shape}\")\n",
    "# Name of the two cultivators:\n",
    "cultivators = data[\"Cultivator\"].unique()\n",
    "print(\"Cultivators:\", cultivators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d51d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a color mapping for the two cultivators:\n",
    "colors = sns.color_palette(\"colorblind\", n_colors=len(cultivators))\n",
    "color_mapping = {key: colori for key, colori in zip(cultivators, colors)}\n",
    "# Show the two colors\n",
    "colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7974b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectra(\n",
    "    data, X, wavelengths, cultivators, color_mapping, axi, legend=False\n",
    "):\n",
    "    \"\"\"\n",
    "\n",
    "    Plots NIR spectra from the given data matrix X, color-coded by cultivar.\n",
    "\n",
    "    Args:\n",
    "        data (pandas.DataFrame): DataFrame containing cultivar information.\n",
    "        X (numpy.ndarray): Matrix of NIR spectra, where each row is a spectrum.\n",
    "        wavelengths (numpy.ndarray): Array of corresponding wavelengths for the spectra.\n",
    "        cultivators (list): List of unique cultivar names.\n",
    "        color_mapping (dict): Dictionary mapping cultivar names to colors.\n",
    "        axi (matplotlib.axes.Axes): Matplotlib Axes object for plotting.\n",
    "        legend (bool, optional): Whether to include a legend. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        None (plots directly to the provided Axes object).\n",
    "    \"\"\"\n",
    "    handles, labels = (\n",
    "        [],\n",
    "        [],\n",
    "    )  # Initialize empty lists to store legend handles and labels\n",
    "    for cultivator in cultivators:\n",
    "        # Filter spectra belonging to the current cultivar\n",
    "        spectra_cult = X[data[\"Cultivator\"] == cultivator]\n",
    "        for spectrum in spectra_cult:\n",
    "            # Plot each spectrum with the assigned color\n",
    "            (linei,) = axi.plot(\n",
    "                wavelengths, spectrum, color=color_mapping[cultivator]\n",
    "            )\n",
    "        # Append the line handle and cultivar label for the legend\n",
    "        handles.append(linei)\n",
    "        labels.append(cultivator)\n",
    "    if legend:\n",
    "        # Add a legend to the plot if 'legend' is True\n",
    "        legend = axi.legend(handles, labels, title=\"Cultivator:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c32b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pca_plot_scores(data, X, axi, cultivators, color_mapping):\n",
    "    \"\"\"\n",
    "    Performs Principal Component Analysis (PCA) on the input spectra and plots the scores (color-coded).\n",
    "\n",
    "    Args:\n",
    "        data (pandas.DataFrame): DataFrame containing cultivar information.\n",
    "        X (numpy.ndarray): Matrix of NIR spectra, where each row is a spectrum.\n",
    "        axi (matplotlib.axes.Axes): Matplotlib Axes object for plotting.\n",
    "        cultivators (list): List of unique cultivar names.\n",
    "        color_mapping (dict): Dictionary mapping cultivar names to colors.\n",
    "\n",
    "    Returns:\n",
    "        None (plots directly to the provided Axes object).\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=2)  # Initialize PCA with 2 components\n",
    "    scores = pca.fit_transform(X)  # Perform PCA and get the scores\n",
    "\n",
    "    for cultivator in cultivators:\n",
    "        # Filter scores for the current cultivar\n",
    "        xscores = scores[data[\"Cultivator\"] == cultivator, 0]\n",
    "        yscores = scores[data[\"Cultivator\"] == cultivator, 1]\n",
    "\n",
    "        # Plot the scores as a scatter plot\n",
    "        axi.scatter(\n",
    "            xscores, yscores, color=color_mapping[cultivator], label=cultivator\n",
    "        )\n",
    "    # Calculate explained variance ratios\n",
    "    perc = pca.explained_variance_ratio_ * 100\n",
    "    # Set axis labels with explained variance percentages\n",
    "    axi.set_xlabel(f\"Scores PC1 ({perc[0]:.2f}%)\")\n",
    "    axi.set_ylabel(f\"Scores PC2 ({perc[1]:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4e82e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure1, axes1 = plt.subplots(constrained_layout=True, ncols=2, figsize=(8, 4))\n",
    "\n",
    "plot_spectra(\n",
    "    data,\n",
    "    all_spectra,\n",
    "    wavelengths,\n",
    "    cultivators,\n",
    "    color_mapping,\n",
    "    axes1[0],\n",
    "    legend=True,\n",
    ")\n",
    "run_pca_plot_scores(data, all_spectra, axes1[1], cultivators, color_mapping)\n",
    "\n",
    "axes1[0].set_xlabel(\"Wavelength (nm)\")\n",
    "axes1[0].set_ylabel(\"Absorbance\")\n",
    "axes1[0].set_title(\"Original spectra\", loc=\"left\")\n",
    "axes1[1].set_title(\"PCA, Original spectra\", loc=\"left\")\n",
    "sns.despine(fig=figure1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3874a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a696a08",
   "metadata": {},
   "source": [
    "#### Your answer to question 7.1(a): Is there a clear cultivar separation in the scores plot?\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dad47d",
   "metadata": {},
   "source": [
    "### 7.1(b)\n",
    "\n",
    "**Task: Observe the impact of normalisation on the spectra and PCA results. In the PCA scores plot, are there any noticeable groupings that suggest cultivar separation?**\n",
    "\n",
    "**Hint:**\n",
    "1. Apply the provided normalization function to scale the spectra to the range $[-1, 1]$, for instance,\n",
    "```python\n",
    "normed = normalise_spectra(all_spectra)\n",
    "```\n",
    "2. Plot the normalised spectra and the corresponding PCA results side-by-side. For instance,\n",
    "```python\n",
    "figure2, axes2 = plt.subplots(constrained_layout=True, ncols=2, figsize=(8, 4))\n",
    "plot_spectra(data, normed, wavelengths, cultivators, color_mapping, axes2[0])\n",
    "run_pca_plot_scores(data, normed, axes2[1], cultivators, color_mapping)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbe1884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "def normalise_spectra(spectra):\n",
    "    \"\"\"\n",
    "    Normalises the given spectra using MinMaxScaler, scaling each spectrum to the range [-1, 1].\n",
    "\n",
    "    Args:\n",
    "        spectra (numpy.ndarray): Matrix of spectra, where each row is a spectrum.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Normalised spectra matrix.\n",
    "    \"\"\"\n",
    "    scaled = np.zeros_like(spectra)\n",
    "    for i, spectrum in enumerate(spectra):\n",
    "        scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "        scaled[i] = scaler.fit_transform(spectrum.reshape(-1, 1)).flatten()\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ff65a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda59d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "normed = normalise_spectra(all_spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee93b8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure2, axes2 = plt.subplots(constrained_layout=True, ncols=2, figsize=(8, 4))\n",
    "plot_spectra(data, normed, wavelengths, cultivators, color_mapping, axes2[0])\n",
    "run_pca_plot_scores(data, normed, axes2[1], cultivators, color_mapping)\n",
    "\n",
    "axes2[0].set_xlabel(\"Wavelength (nm)\")\n",
    "axes2[0].set_ylabel(\"Normalised Absorbance\")\n",
    "axes2[0].set_title(\"Normalised spectra\", loc=\"left\")\n",
    "axes2[1].set_title(\"PCA, normalised spectra\", loc=\"left\")\n",
    "sns.despine(fig=figure2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da80184e",
   "metadata": {},
   "source": [
    "#### Your answer to question 7.1(b): Is there a clear cultivar separation in the scores plot?\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb82fb73",
   "metadata": {},
   "source": [
    "### 7.1(c)\n",
    "\n",
    "**Task: Observe the impact of multiplicative scatter correction (MSC) on the spectra and PCA results. In the PCA scores plot, are there any noticeable groupings that suggest cultivar separation?**\n",
    "\n",
    "**Hint:**\n",
    "1. Apply the provided MSC function to correct the spectra, for instance,\n",
    "```python\n",
    "corrected = multiplicative_scatter_correction(all_spectra)\n",
    "```\n",
    "2. Plot the corrected spectra and the corresponding PCA results side-by-side. For instance,\n",
    "```python\n",
    "figure3, axes3 = plt.subplots(constrained_layout=True, ncols=2, figsize=(8, 4))\n",
    "plot_spectra(data, corrected, wavelengths, cultivators, color_mapping, axes3[0])\n",
    "run_pca_plot_scores(data, corrected, axes3[1], cultivators, color_mapping)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835e5c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplicative_scatter_correction(spectra):\n",
    "    \"\"\"\n",
    "    Applies Multiplicative Scatter Correction (MSC) to the input spectra.\n",
    "\n",
    "    MSC is a preprocessing technique used to reduce the effects of scatter in spectral data.\n",
    "    It corrects for variations in path length and particle size, which can affect the\n",
    "    baseline and slope of the spectra.\n",
    "\n",
    "    Args:\n",
    "        spectra (numpy.ndarray): Matrix of spectra, where each row is a spectrum.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: MSC-corrected spectra matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    mean = np.mean(spectra, axis=0)  # Calculate the mean spectrum\n",
    "    msc_spectra = np.zeros_like(\n",
    "        spectra\n",
    "    )  # Initialise an array to store MSC-corrected spectra\n",
    "    for i, spectrum in enumerate(spectra):\n",
    "        # Fit a linear regression model to each spectrum against the mean spectrum\n",
    "        param = np.polyfit(mean, spectrum, 1)\n",
    "        # Apply the MSC correction: (spectrum - intercept) / slope\n",
    "        msc_spectra[i] = (spectrum - param[1]) / (param[0])\n",
    "    return msc_spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2b31fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfd1dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected = multiplicative_scatter_correction(all_spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8cd394",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure3, axes3 = plt.subplots(constrained_layout=True, ncols=2, figsize=(8, 4))\n",
    "plot_spectra(\n",
    "    data, corrected, wavelengths, cultivators, color_mapping, axes3[0]\n",
    ")\n",
    "run_pca_plot_scores(data, corrected, axes3[1], cultivators, color_mapping)\n",
    "\n",
    "axes3[0].set_xlabel(\"Wavelength (nm)\")\n",
    "axes3[0].set_ylabel(\"Corrected absorbance\")\n",
    "axes3[0].set_title(\"MSC spectra\", loc=\"left\")\n",
    "axes3[1].set_title(\"PCA, MSC spectra\", loc=\"left\")\n",
    "sns.despine(fig=figure3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62871c9",
   "metadata": {},
   "source": [
    "#### Your answer to question 7.1(c): Is there a clear cultivar separation in the scores plot?\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ab6e77",
   "metadata": {},
   "source": [
    "### 7.1(d)\n",
    "\n",
    "**Task: Investigate the impact of applying a second derivative transformation on the spectra and PCA results. In the PCA scores plot, are there any noticeable groupings that suggest cultivar separation?**\n",
    "\n",
    "**Hint:**\n",
    "1. Use the provided code to calculate the second derivative of the original spectra, for instance,\n",
    "\n",
    "```python\n",
    "dspectra = derivative(wavelengths, all_spectra, deriv=2)\n",
    "```\n",
    "2. Plot the resulting second derivative spectra and the corresponding PCA results side-by-side. For instance,\n",
    "```python\n",
    "figure4, axes4 = plt.subplots(constrained_layout=True, ncols=2, figsize=(8, 4))\n",
    "plot_spectra(data, dspectra, wavelengths, cultivators, color_mapping, axes4[0])\n",
    "run_pca_plot_scores(data, dspectra, axes4[1], cultivators, color_mapping)\n",
    "```\n",
    "\n",
    "**Note:** The derivative is computed using the [Savitzky-Golay filter](https://en.wikipedia.org/wiki/Savitzky%E2%80%93Golay_filter). This method smooths the data by fitting a polynomial to a moving window of points and then calculates the derivative of that fitted polynomial. The method, as implemented here, assumes evenly spaced data points. It may produce inaccurate results if your wavelengths are unevenly spaced. In such cases, alternative methods like B-spline derivatives or other interpolation-based approaches might be more suitable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a283d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative(wavelengths, spectra, window_length=21, polyorder=3, deriv=2):\n",
    "    \"\"\"\n",
    "    Calculates the derivative of the input spectra using the Savitzky-Golay filter.\n",
    "\n",
    "    This function applies the Savitzky-Golay filter to smooth and differentiate the\n",
    "    input spectra. The filter is used to reduce noise and enhance spectral features.\n",
    "\n",
    "    Args:\n",
    "        wavelengths (numpy.ndarray): Array of wavelengths corresponding to the spectra.\n",
    "        spectra (numpy.ndarray): Matrix of spectra, where each row is a spectrum.\n",
    "        window_length (int): The length of the filter window (must be odd).\n",
    "        polyorder (int): The order of the polynomial used to fit the samples.\n",
    "        deriv (int, optional): The order of the derivative to compute. Defaults to 2 (second derivative).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Matrix of derivative spectra.\n",
    "    \"\"\"\n",
    "\n",
    "    derivative = np.zeros_like(\n",
    "        spectra\n",
    "    )  # Initialize an array to store derivative spectra\n",
    "\n",
    "    for i, spectrum in enumerate(spectra):\n",
    "        # Apply Savitzky-Golay filter to calculate the derivative\n",
    "        derivative[i] = savgol_filter(\n",
    "            spectrum,\n",
    "            window_length,\n",
    "            polyorder,\n",
    "            deriv=deriv,\n",
    "            delta=wavelengths[1] - wavelengths[0],  # Wavelength spacing\n",
    "            mode=\"nearest\",  # Extrapolation mode at the edges\n",
    "        )\n",
    "\n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b6890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d73e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dspectra = derivative(wavelengths, all_spectra, deriv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a598a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure4, axes4 = plt.subplots(constrained_layout=True, ncols=2, figsize=(8, 4))\n",
    "plot_spectra(data, dspectra, wavelengths, cultivators, color_mapping, axes4[0])\n",
    "run_pca_plot_scores(data, dspectra, axes4[1], cultivators, color_mapping)\n",
    "\n",
    "axes4[0].set_xlabel(\"Wavelength (nm)\")\n",
    "axes4[0].set_ylabel(\"Second derivative of absorbance\")\n",
    "axes4[0].set_title(\"Second derivative of spectra\", loc=\"left\")\n",
    "axes4[1].set_title(\"PCA, second derivative of spectra\", loc=\"left\")\n",
    "sns.despine(fig=figure4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c0a567",
   "metadata": {},
   "source": [
    "#### Your answer to question 7.1(d): Is there a clear cultivar separation in the scores plot?\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6112e1",
   "metadata": {},
   "source": [
    "### 7.1(e)\n",
    "\n",
    "**Task: Explain how the Savitzky-Golay filter uses polynomial fitting to smooth data and compute derivatives.**\n",
    "\n",
    "**Hint:** See page 149 in our text book."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069d4a78",
   "metadata": {},
   "source": [
    "#### Your answer to question 7.1(e): Your explanation for Savitzky-Golay filtering?\n",
    "\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787f980a",
   "metadata": {},
   "source": [
    "### 7.1(f)\n",
    "\n",
    "**Task: The figure below displays the results of the preprocessing steps from exercise [7.1(a)](#7.1(a)) to [7.1(d)](#7.1(d)). Based on these results, which preprocessing method appears most promising for building a classifier?**\n",
    "\n",
    "![Preprocessing NIR results](results7.1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff977844",
   "metadata": {},
   "source": [
    "#### Your answer to question 7.1(f): Which preprocessing step appears most promising?\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dfeb41",
   "metadata": {},
   "source": [
    "## Exercise 7.2\n",
    "\n",
    "In this exercise, we will smooth and differentiate a noisy signal. We will use a test signal generated from the following analytical function:\n",
    "\n",
    "$$y(t) = \\sin (8t) - 1.8t^2 + 0.5t^3.$$\n",
    "\n",
    "The noise-free signal data is available in the file [signal.txt](signal.txt). The file contains two columns: the first column represents time ($t$), and the second column represents the signal $y(t)$.\n",
    "\n",
    "A noisy version of this signal is provided in the file [signal_noise.txt](signal_noise.txt), which also contains two columns: time ($t$) and the signal $y(t)$ with added noise.\n",
    "\n",
    "The example code below demonstrates how to load and plot the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df2a610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_theme(style=\"ticks\", context=\"notebook\", palette=\"colorblind\")\n",
    "\n",
    "t_clean, y_clean = np.loadtxt(\"signal.txt\", unpack=True)\n",
    "t_noisy, y_noisy = np.loadtxt(\"signal_noise.txt\", unpack=True)\n",
    "\n",
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "ax.plot(t_noisy, y_noisy, label=\"With noise (signal_noise.txt)\", alpha=0.5)\n",
    "ax.plot(t_clean, y_clean, label=\"Without noise (signal.txt)\", lw=3)\n",
    "ax.set(xlabel=\"Time (t)\", ylabel=\"Signal (y(t))\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6508d1",
   "metadata": {},
   "source": [
    "### 7.2(a)\n",
    "\n",
    "**Task: Smooth the signal with noise using a B-spline. Compare the result to the noise-free signal by plotting both signals.**\n",
    "\n",
    "**Hint:** You can create the B-spline basis set using the `bbase` function from Eilers and Marx (see the code cell below). You can use this function to create the smoothed signal by completing the following steps:\n",
    "\n",
    "1. First calculate the B-spline design matrix `X`:\n",
    "```python\n",
    "ndx = 20  # Number of B-spline segments\n",
    "degree = 3  # B-spline degree\n",
    "X = bbase(t_noisy, ndx=ndx, deg=degree)\n",
    "```\n",
    "\n",
    "2. Create the penalty matrix `Dn` (typically, we use D2 or D3 for better interpolation):\n",
    "```python\n",
    "n = X.shape[1]\n",
    "order = 2  # Order of the penalty (1, 2, or 3)\n",
    "Dn = np.diff(np.eye(n), n=order, axis=0)\n",
    "```\n",
    "\n",
    "3. Create the augmented matrix `Xaug` that combines the design matrix `X` obtained from `bbase` with the scaled penalty matrix `sqrt(gamma)*D`, and the augmented column vector `yaug` that combines the y-values from the data set with a vector of zeros equal in length to the number of rows of D:\n",
    "```python\n",
    "# Create the augmented matrix Xaug\n",
    "gamma = 1  # Adjust this to control smoothing\n",
    "Xaug = np.vstack([X, np.sqrt(gamma) * Dn])\n",
    "# Create the augmented column vector yaug\n",
    "yaug = np.concatenate([y_noisy, np.zeros(Dn.shape[0])])\n",
    "```\n",
    "\n",
    "4. Find the coefficients that best fit the data set by solving the linear equation `Xaug*beta_hat = yaug`.\n",
    "```python\n",
    "# Solve the linear equation Xaug * beta_hat = yaug\n",
    "beta_hat = np.linalg.lstsq(Xaug, yaug, rcond=None)[0]\n",
    "```\n",
    "\n",
    "5. Find the smoothed data `yhat` by calculating `yhat = X*beta_hat`.\n",
    "```python\n",
    "# Calculate the smoothed data yhat\n",
    "y_smooth = X @ beta_hat\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2f84bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import factorial\n",
    "\n",
    "\n",
    "def tpower(x, t, p):\n",
    "    \"\"\"Generate degree-p truncated power function.\"\"\"\n",
    "    return np.where(x > t, (x - t) ** p, 0.0)\n",
    "\n",
    "\n",
    "def bbase(x, xl=None, xr=None, ndx=20, deg=3):\n",
    "    \"\"\"Construct a B-spline basis of degree `deg`.\n",
    "\n",
    "    Construct a B-spline basis matrix of a specified degree. This method\n",
    "    is adapted from:\n",
    "\n",
    "    Eilers, P.H.C. and Marx, B.D. (2010), Splines, knots, and penalties.\n",
    "    WIREs Comp Stat, 2: 637-653. https://doi.org/10.1002/wics.125\n",
    "\n",
    "     Args:\n",
    "        x: A sequence or array of data points where the basis functions are evaluated.\n",
    "        xl: The lower boundary for the knots.\n",
    "        xr: The upper boundary for the knots.\n",
    "        ndx: The number of intervals between xl and xr.\n",
    "        deg: The degree of the B-spline.\n",
    "\n",
    "    Returns:\n",
    "        A NumPy array representing the B-spline basis matrix.\n",
    "        Each column is a basis function evaluated at the points in x.\n",
    "        The shape is (len(x), number_of_basis_functions).\n",
    "\n",
    "    \"\"\"\n",
    "    if xl is None:\n",
    "        xl = np.min(x)\n",
    "    if xr is None:\n",
    "        xr = np.max(x)\n",
    "    # Generate knot sequence (extends outside boundaries)\n",
    "    dx = (xr - xl) / ndx\n",
    "    left = xl - deg * dx\n",
    "    right = xr + deg * dx\n",
    "    num_knots = int(round((right - left) / dx)) + 1\n",
    "    knots = np.linspace(left, right, num_knots)\n",
    "\n",
    "    # Compute matrix of TPFs\n",
    "    P = np.zeros((len(x), len(knots)))\n",
    "    for i in range(len(knots)):\n",
    "        P[:, i] = tpower(x, knots[i], deg)\n",
    "\n",
    "    # Compute matrix of b-splines\n",
    "    n = P.shape[1]\n",
    "    D = np.diff(np.eye(n), deg + 1, axis=0) / (factorial(deg) * dx**deg)\n",
    "    B = (-1) ** (deg + 1) * P @ D.T\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dded2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f185f8a",
   "metadata": {},
   "source": [
    "#### Your answer to question 7.2(a): How does the smoothed signal compare to the noise-free signal?\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d88f687",
   "metadata": {},
   "source": [
    "### 7.2(b)\n",
    "\n",
    "**Task: We could attempt to estimate the derivative of the noisy signal directly using a finite difference approximation, such as the forward difference method:**\n",
    "\n",
    "$$y'(t_i) \\approx \\frac{y(t_{i+1}) - y(t_i)}{t_{i+1} - t_i}$$\n",
    "\n",
    "**Explain the potential problem(s) associated with this approach when applied to a signal containing substantial noise.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d737a73",
   "metadata": {},
   "source": [
    "#### Your answer to question 7.2(b): What are the potential problem(s) when using the finite difference approximation directly with a noisy signal?\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64df308b",
   "metadata": {},
   "source": [
    "### 7.2(c)\n",
    "\n",
    "**Task: Calculate the derivative of the smoothed signal from 7.2(a) using the B-spline representation. Compare the derivative to the analytical derivative of the noise-free signal (by plotting both derivatives).**\n",
    "\n",
    "**Hint:**\n",
    "1. The analytical derivative of the noise-free signal is:\n",
    "\n",
    "   $$ y^\\prime(t) = 8\\cos(8t) - 3.6t + 1.5t^2,$$\n",
    "\n",
    "   with Python: \n",
    "```python\n",
    "def analytical_derivative(t):\n",
    "    \"\"\"Calculate the analytical derivative of the noise-free signal.\"\"\"\n",
    "    return 8 * np.cos(8 * t) - 3.6 * t + 1.5 * t**2\n",
    "```\n",
    "\n",
    "2. You can find the first derivative of the B-spline using\n",
    "   ```python\n",
    "   (1 / h) * X_ @ (D1 @ beta_hat\n",
    "   ```\n",
    "   where:\n",
    "   \n",
    "   * `h` is the spacing (same as `dx` in `bbase`):\n",
    "   ```python\n",
    "   h = (t_noisy.max() - t_noisy.min()) / ndx\n",
    "   ```\n",
    "   * `X_` is the design matrix (of degree one less than you used for finding the coefficients `beta_hat`):\n",
    "   ```python\n",
    "   X_ = bbase(t_noisy, ndx=ndx, deg=degree-1)\n",
    "   ```\n",
    "   \n",
    "   * `D1` is the first order derivative matrix given by\n",
    "   ```python\n",
    "   D1 = np.diff(np.eye(X.shape[1]), n=1, axis=0)\n",
    "   ```\n",
    "\n",
    "   Combined example:\n",
    "```python\n",
    "h = (t_noisy.max() - t_noisy.min()) / ndx\n",
    "D1 = np.diff(np.eye(X.shape[1]), n=1, axis=0)\n",
    "X_ = bbase(t_noisy, ndx=ndx, deg=degree - 1)\n",
    "derivative_smooth = (1 / h) * X_ @ (D1 @ beta_hat)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba477307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7508c62",
   "metadata": {},
   "source": [
    "#### Your answer to question 7.2(c): How does the computed derivative compare to the analytical derivative?\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ba7c30",
   "metadata": {},
   "source": [
    "### 7.2(d)\n",
    "\n",
    "**Task: Smooth the signal and obtain its derivative using a Savitzky-Golay filter. Compare the smoothness and accuracy of both methods (Savitzky-Golay and B-splines) by plotting the results.**\n",
    "\n",
    "**Hint:** The Savitzky-Golay filter can be applied as follows:\n",
    "```python\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "y_smooth_sg = savgol_filter(\n",
    "    y_noisy,\n",
    "    window_length=51,  # Length of window to use for smoothing\n",
    "    polyorder=3,  #  Polynomial order to use.\n",
    ")\n",
    "\n",
    "delta_t = t_noisy[1] - t_noisy[0]\n",
    "derivative_smooth_sg = savgol_filter(\n",
    "    y_noisy,\n",
    "    delta=delta_t,  # Sample spacing, needed for the derivative.\n",
    "    window_length=101,  # Length of window to use for smoothing\n",
    "    polyorder=3,  #  Polynomial order to use.\n",
    "    deriv=1,  # Compute the first (1) derivative.\n",
    ")\n",
    "# Note: Please experiment with different window lengths and order for the polynomial.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4219339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcb1a0c",
   "metadata": {},
   "source": [
    "#### Your answer to question 7.2(d): How do the results from applying the Savitzky-Golay filter compare to the B-splines results\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf0cb9b",
   "metadata": {},
   "source": [
    "## Your feedback for Exercise 7\n",
    "\n",
    "1. **Time & Difficulty:**\n",
    "* Length (1=too short, 5=too long): 1  2  3  4  5\n",
    "* Difficulty (1=too easy, 5=too difficult): 1  2  3  4  5\n",
    "* Most challenging part: ________________________\n",
    "\n",
    "2. **Code Examples:**\n",
    "* More or less example code?  More  Less  About Right\n",
    "* Areas where more examples would be helpful: ________________________\n",
    "\n",
    "3. **Errors/Inconsistencies:** Did you encounter any?  Yes  No  If yes, please describe: ________________________\n",
    "    \n",
    "4. **Suggestions:** How could this exercise be improved? ________________________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "717bf838",
   "metadata": {},
   "source": [
    "# Exercise 11\n",
    "\n",
    "\n",
    "> In this exercise, we will have a look at penguins! We will attempt to figure out the species of penguins based\n",
    "> on their bill length, bill depth, flipper length, and body mass.\n",
    "> The data is from a paper by \n",
    "> [Gorman, Williams, and Fraser](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0090081)\n",
    "> and can also be found in the R package [palmerpenguins](https://github.com/allisonhorst/palmerpenguins).\n",
    "> Here, we will use a version of the data set [penguins.csv](./Data/penguins.csv) where missing\n",
    "> values have been removed.\n",
    ">\n",
    "> The exercise is structured as follows:\n",
    "> * [11.1 Initial exploration (of the data set)](#11.1-Initial-exploration)\n",
    "> * [11.2 Creating a decision tree for determining the species](#11.2-Creating-a-decision-tree-for-determining-the-species)\n",
    "> * [11.3 Exploring the penguins with partial least squares discriminant analysis (PLS-DA)](#11.3-Exploring-the-penguins-with-partial-least-squares-discriminant-analysis-(PLS-DA))\n",
    ">\n",
    "> In [11.3](#11.3-Exploring-the-penguins-with-partial-least-squares-discriminant-analysis-(PLS-DA))\n",
    "> you will mostly run some code (to perform the analysis) and then interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f23d5e",
   "metadata": {},
   "source": [
    "## 11.1 Initial exploration\n",
    "\n",
    "The penguins belong to three species: [Adelie](https://en.wikipedia.org/wiki/Ad%C3%A9lie_penguin),\n",
    "[Chinstrap](https://en.wikipedia.org/wiki/Chinstrap_penguin), and [Gentoo](https://en.wikipedia.org/wiki/Gentoo_penguin), and the figure below shows the three islands where these penguins can be found (click the image to make it larger): \n",
    "\n",
    "\n",
    "\n",
    "| <a href=\"./Figures/penguins.png\"><img src=\"./Figures/penguins2.png\" width=\"50%\"></a>           |\n",
    "|:-:|\n",
    "| **Fig. 1** *Location of islands and images of the penguin species.*    |\n",
    "\n",
    "You will find seven columns in the [penguins.csv](./Data/penguins.csv) data file. Each row is a measurement for\n",
    "a single penguin for the seven variables found in the columns:\n",
    "\n",
    "\n",
    "| Column            |  Description                                                        |\n",
    "|:------------------|--------------------------------------------------------------------:|\n",
    "| species           | The species (Adelie/Chinstrap/Gentoo)                               |\n",
    "| island            | The island where the observation was made (Dream/Torgersen/Biscoe)  |\n",
    "| bill_length_mm    | (See the illustration below) (measured in mm)                       |\n",
    "| bill_depth_mm     | (See the illustration below) (measured in mm)                       |\n",
    "| flipper_length_mm | (See the illustration below) (measured in mm)                       |\n",
    "| body_mass_g       | The weight of the penguin (in grams)                                |\n",
    "| sex               | Female/Male                                                         |\n",
    "\n",
    "\n",
    "| <img src=\"./Figures/bill.png\" width=\"50%\">                                   |\n",
    "|:-:|\n",
    "| **Fig. 2** *Illustration of bill length, bill depth, and flipper length. (The foot is not used in this data set.)*    |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1e8223",
   "metadata": {},
   "source": [
    "### 11.1(a) Loading the data\n",
    "\n",
    "First, load the data set on the penguins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5beddb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import black\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load(\n",
    "    lab=False,\n",
    "    line_length=79,\n",
    "    verbosity=\"DEBUG\",\n",
    "    target_version=black.TargetVersion.PY310,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d29e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"Data/penguins.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31980189",
   "metadata": {},
   "source": [
    "After loading the data set, verify the following:\n",
    "\n",
    "1. We have data from three distinct islands (Dream, Torgersen, and Biscoe).\n",
    "\n",
    "1. We have data from three penguin species (Adelie, Chinstrap, and Gentoo).\n",
    "\n",
    "1. On the island Dream, the only species are Adelie and Chinstrap.\n",
    "\n",
    "1. On the island Torgersen, the only specie is Adelie.\n",
    "\n",
    "1. On the island of Biscoe, the only species are Adelie and Gentoo.\n",
    "\n",
    "Here are some hints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57512248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the unique elements in a column, we can do:\n",
    "print(data[\"species\"].unique())\n",
    "# Or we can do:\n",
    "print(set(data[\"species\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1597a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get more information on different islands, we can use the groupby method for pandas:\n",
    "group = data.groupby(\"species\")\n",
    "print(group.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6214648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method also works with several columns:\n",
    "group = data.groupby([\"island\", \"species\"])\n",
    "print(group.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e8f923",
   "metadata": {},
   "source": [
    "#### Answer to question 11.1(a):\n",
    "\n",
    "> 1. We have data from three distinct islands (Dream, Torgersen, and Biscoe).\n",
    "\n",
    "Yes, the following code list these 3 islands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed278e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. The islands:\n",
    "print(data[\"island\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a172b5db",
   "metadata": {},
   "source": [
    "> 2. We have data from three different penguin species (Adelie, Chinstrap, and Gentoo).\n",
    "\n",
    "Yes, the following code list the three species:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb73db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Penguin species:\n",
    "print(data[\"species\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0be5a7",
   "metadata": {},
   "source": [
    "> 3. On the island Dream, the only species are Adelie and Chinstrap.\n",
    "> 4. On the island Torgersen, the only specie is Adelie.\n",
    "> 5. On the island of Biscoe, the only species are Adelie and Gentoo.\n",
    "\n",
    "Yes to all; the code below says:\n",
    "\n",
    "* There are 55 Adelie and 68 Chinstraps penguins on Dearm.\n",
    "\n",
    "* There are 47 Adelie penguins on Torgersen.\n",
    "\n",
    "* There are 44 Adelie and 119 Gentoo penguins on Biscoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75aa212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-5. Penguins on islands:\n",
    "group = data.groupby([\"island\", \"species\"])\n",
    "print(group.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aa200d",
   "metadata": {},
   "source": [
    "### 11.1(b) Exploring by plotting\n",
    "\n",
    "Create figures to see if the variables `bill_length_mm`, `bill_depth_mm`,\n",
    "`flipper_length_mm`, and `body_mass_g` can be used to separate the different\n",
    "species. Here, you can, for instance, create the scatter plot matrix,\n",
    "or use [jointplot](https://seaborn.pydata.org/tutorial/introduction.html#multivariate-views-on-complex-datasets)\n",
    "from seaborn. Or maybe a [boxplot](https://seaborn.pydata.org/generated/seaborn.boxplot.html) is useful?\n",
    "\n",
    "If you were to label a penguin as Adelie, Chinstrap, or Gentoo, what \"rules\" would you\n",
    "use for this (keep it simple!) based on the four variables `bill_length_mm`, `bill_depth_mm`,\n",
    "`flipper_length_mm`, and `body_mass_g`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65016319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_theme(style=\"ticks\", context=\"notebook\", palette=\"muted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9fdbe3",
   "metadata": {},
   "source": [
    "#### Example plot 1\n",
    "\n",
    "One way to get an overview is to use the scatter plot matrix, and color the\n",
    "data points according to the species:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d521e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first create a scatter plot matrix with seaborn - here, the parameter \"hue\" is used to\n",
    "# select \"groups\" in the data. You can explore how the data looks if\n",
    "# you select \"island\" or \"sex\" as the hue:\n",
    "grid = sns.pairplot(\n",
    "    data,\n",
    "    corner=True,\n",
    "    hue=\"species\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59efaf5a",
   "metadata": {},
   "source": [
    "#### Example plot 2 - Boxplot for looking at the difference between island and species\n",
    "Here, we will make the [boxplot](https://seaborn.pydata.org/generated/seaborn.boxplot.html) to investigate the distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0ce371",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    constrained_layout=True,\n",
    "    ncols=2,\n",
    "    nrows=2,\n",
    "    figsize=(8, 6),\n",
    "    sharex=True,\n",
    ")\n",
    "axes = axes.flatten()\n",
    "sns.boxplot(\n",
    "    data=data, y=\"bill_length_mm\", x=\"species\", hue=\"island\", ax=axes[0]\n",
    ")\n",
    "axes[0].legend(fontsize=\"x-small\")\n",
    "sns.boxplot(\n",
    "    data=data, y=\"bill_depth_mm\", x=\"species\", hue=\"island\", ax=axes[1]\n",
    ")\n",
    "axes[1].legend([], [], frameon=False)\n",
    "sns.boxplot(\n",
    "    data=data, y=\"flipper_length_mm\", x=\"species\", hue=\"island\", ax=axes[2]\n",
    ")\n",
    "axes[2].legend([], [], frameon=False)\n",
    "sns.boxplot(data=data, y=\"body_mass_g\", x=\"species\", hue=\"island\", ax=axes[3])\n",
    "axes[3].legend([], [], frameon=False)\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be452ac3",
   "metadata": {},
   "source": [
    "#### Example 3 - Jointplot for looking for possible separations of species\n",
    "Here, we will use the [jointplot](https://seaborn.pydata.org/tutorial/introduction.html#multivariate-views-on-complex-datasets) to look for possible separations of the groups. The variables\n",
    "selected here are picked based on the scatter plot matrix made above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49a99dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.jointplot(\n",
    "    data=data, x=\"flipper_length_mm\", y=\"bill_depth_mm\", hue=\"species\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40bea3e",
   "metadata": {},
   "source": [
    "his plot clearly shows that the Gentoo species are separated from the rest! If the flipper length is larger than 210 mm, then it is most likely a Gentoo. If it is smaller than 210 mm, it is most likely a Gentoo if the bill depth is smaller than 16. Let us put these simple rules into the plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b4e3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = grid.fig.axes[0]\n",
    "ax.axvline(x=210, color=\"k\", ls=\":\")\n",
    "ax.axhline(y=16, color=\"k\", ls=\":\")\n",
    "grid.fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b3beb8",
   "metadata": {},
   "source": [
    "These rules could be better, but they can be used to separate the species. Let us also try\n",
    "to find a separation between Adelie and Chinstrap. This seems a bit harder from the scatter plot matrix and the\n",
    "box plot above; it looks like the bill length can be used to separate these two species:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c361fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "sns.swarmplot(data=data, x=\"bill_length_mm\", y=\"species\", hue=\"island\")\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6370e37a",
   "metadata": {},
   "source": [
    "There is some overlap between Adeline and Chinstrap here, but we can largely separate them by a line\n",
    "at a bill length of 44 mm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adff14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "sns.swarmplot(data=data, x=\"bill_length_mm\", y=\"species\", hue=\"island\")\n",
    "ax.axvline(x=44, ls=\":\", color=\"k\")\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20845cb",
   "metadata": {},
   "source": [
    "#### Answer to question 11.1(b):\n",
    "\n",
    "Using the plots above, here are some simple rules:\n",
    "\n",
    "1. If the flipper length is larger than 210 mm or the bill depth is smaller than 16 mm (or both is True), it is most likely a Gentoo.\n",
    "2. If it is not a Gentoo, then it is an Adelie if the bill length is smaller than 43 mm; otherwise, it is a Chinstrap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3d2441",
   "metadata": {},
   "source": [
    "## 11.2 Creating a decision tree for determining the species"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7d8430",
   "metadata": {},
   "source": [
    "### 11.2(a) Coding the species\n",
    "\n",
    "We have three species, and the data we have is categorical. To use the specie in\n",
    "numerical methods, we must represent it with numbers. For decision trees,\n",
    "we can use the numbers 0, 1, and 2 to represent the three species (we are not\n",
    "doing any math with these numbers, and they only have a meaning as labels for the decision tree).\n",
    "\n",
    "Generating numbers for categorical data is a common task, and sklearn has a built-in method for\n",
    "that called [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html). This one can be used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b20920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create some categorical data:\n",
    "raw_data = [\n",
    "    \"bears\",\n",
    "    \"beets\",\n",
    "    \"battlestar galactica\",\n",
    "    \"bears\",\n",
    "    \"bears\",\n",
    "    \"beets\",\n",
    "]\n",
    "# Create the encoder and fit it to the data:\n",
    "encoder = LabelEncoder().fit(raw_data)\n",
    "# Show the classes the encoder found:\n",
    "print(\"Classes are:\", encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3302fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the encoder to transform the raw data to numbers:\n",
    "y = encoder.transform(raw_data)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02511414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also convert back:\n",
    "labels = encoder.inverse_transform(y)\n",
    "print(labels)\n",
    "# Check that we got the same as we started with:\n",
    "print([i == j for i, j in zip(raw_data, labels)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386fce47",
   "metadata": {},
   "source": [
    "Create a new encoder for the species and transform the species in the data to numerical y-values.\n",
    "You will use these y-values in the following to create the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83d2175",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_encoder = LabelEncoder().fit(data[\"species\"])\n",
    "y = species_encoder.transform(data[\"species\"])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028c664d",
   "metadata": {},
   "source": [
    "#### Answer to question 11.2(a):\n",
    "(See the code above)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ed7640",
   "metadata": {},
   "source": [
    "### 11.2(b) Creating the decision tree\n",
    "\n",
    "Create a decision tree for determining the species. Use the numerical y-values you just created\n",
    "for your y, and use `bill_length_mm`, `bill_depth_mm`,\n",
    "`flipper_length_mm`, and `body_mass_g` as your X-variables. Keep the tree as simple as possible so\n",
    "that it is easy to interpret it.\n",
    "\n",
    "After you have created the decision tree, show the **confusion matrix** and calculate\n",
    "the **precision** and **recall**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93869af1",
   "metadata": {},
   "source": [
    "**Note!** We have three species here, which means we have to define how we should calculate these metrics.\n",
    "Let us take recall as an example. For binary classification, where we only have two classes, it is:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{recall} = \\frac{TP}{TP + FN}\n",
    "\\end{equation}\n",
    "\n",
    "where $TP$ is the number of true positives, and $FN$ is the number of false negatives. If we have three classes\n",
    "we will get $TP$ (and $FN$) for classes 0, 1, and 2. We will here consider two possibilities (there are more!) for\n",
    "the averaging into one recall score:\n",
    "\n",
    "* macro-averaging: This will calculate the metric for each class\n",
    "  independently and it will then take the average (all classes treated equally):\n",
    "  \n",
    "  \\begin{equation}\n",
    "  \\text{recall}_0 = \\frac{TP_0}{TP_0 + FN_0}, \\quad \\text{recall}_1 = \\frac{TP_1}{TP_1 + FN_1},\n",
    "  \\quad \\text{recall}_2 = \\frac{TP_2}{TP_2 + FN_2}.\n",
    "  \\end{equation}\n",
    "  \n",
    "  Here $TP_i$ means correct classifications for class $i$, and $FN_i$ means mistakes for class $i$.\n",
    "  \n",
    "  \\begin{equation}\n",
    "  \\text{recall}_\\text{macro} = \\frac{\\text{recall}_0 + \\text{recall}_1 + \\text{recall}_2}{3}\n",
    "  \\end{equation}\n",
    "  \n",
    "\n",
    "\n",
    "* micro-averaging: This will aggregate contributions of all classes and use this to\n",
    "  calculate the average:\n",
    "  \n",
    "  \\begin{equation}\n",
    "  \\text{recall}_\\text{micro} = \\frac{TP_0 + TP_1 + TP_2}{TP_0 + TP_1 + TP_2 + FN_0 + FN_1 + FN_2}\n",
    "  \\end{equation}\n",
    "  \n",
    "\n",
    "Since macro-averaging treats all classes equally, it will not deal well with cases\n",
    "where we have a class imbalance (for instance, if we have few items of one class compared to the others). In\n",
    "such cases, micro-averaging is preferred.\n",
    "\n",
    "Here is a short example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d5f5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "y_true = [0, 0, 1, 1, 2, 2, 2, 2]\n",
    "y_pred = [0, 1, 1, 2, 1, 1, 0, 2]\n",
    "macro = recall_score(y_true, y_pred, average=\"macro\")\n",
    "micro = recall_score(y_true, y_pred, average=\"micro\")\n",
    "print(f\"recall(macro) = {macro}\")\n",
    "print(f\"recall(micro) = {micro}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a049995f",
   "metadata": {},
   "source": [
    "For completeness, let us do this by hand as well:\n",
    "\n",
    "| Class | True positives (correct) | False negatives (mistakes) |\n",
    "|:-:|:-:|:-:|\n",
    "| 0 | 1 | 1 |\n",
    "| 1 | 1 | 1 |\n",
    "| 2 | 1 | 3 |\n",
    "\n",
    "* macro-averaging:\n",
    "  \n",
    "  \\begin{equation}\n",
    "  \\text{recall}_0 = \\frac{TP_0}{TP_0 + FN_0} = \\frac{1}{1+1}=0.5, \\quad \\text{recall}_1 = \\frac{TP_1}{TP_1 + FN_1} =   \\frac{1}{1+1}=0.5,\n",
    "  \\quad \\text{recall}_2 = \\frac{TP_2}{TP_2 + FN_2} = \\frac{1}{1+3}=0.25.\n",
    "  \\end{equation}\n",
    "\n",
    "  \\begin{equation}\n",
    "  \\text{recall}_\\text{macro} = \\frac{0.5 + 0.5 + 0.25}{3} = \\frac{5}{12} = 0.41666\\ldots\n",
    "  \\end{equation}\n",
    " \n",
    "* micro-averaging: \n",
    " \n",
    "  \\begin{equation}\n",
    "  \\text{recall}_\\text{micro} = \\frac{TP_0 + TP_1 + TP_2}{TP_0 + TP_1 + TP_2 + FN_0 + FN_1 + FN_2}\n",
    "  = \\frac{1 + 1 + 1}{1 + 1 + 1 + 1+ 1+3} = \\frac{3}{8} = 0.375\n",
    "  \\end{equation}\n",
    "  \n",
    "\n",
    "Motivated by the fact that we do not have an equal number of samples for the different species, I\n",
    "suggest using micro-averaging in the following. If you use\n",
    "[GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "for finding the optimum depth of your tree, this can be done by setting `scoring=\"recall_micro\"` in\n",
    "`GridSearchCV`. Here is a short example you can adapt to make your decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad68d196",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Use the real data:\n",
    "xvars = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\n",
    "X = data[xvars]\n",
    "# Create test/training sets:\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Set up a grid search:\n",
    "parameters = {\"max_depth\": range(1, 10)}\n",
    "grid = GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    parameters,\n",
    "    scoring=\"recall_micro\",\n",
    ")\n",
    "\n",
    "# Run the grid search:\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Get the best classifier from the grid search:\n",
    "best_tree = grid.best_estimator_\n",
    "print(\"Best tree:\", best_tree)\n",
    "\n",
    "# Use the best classifier for the test set:\n",
    "y_pred = best_tree.predict(X_test)\n",
    "\n",
    "# Calculate the precision etc. for the test set:\n",
    "precision = precision_score(y_test, y_pred, average=\"micro\")\n",
    "recall = recall_score(y_test, y_pred, average=\"micro\")\n",
    "print(f\"precision = {precision}\")\n",
    "print(f\"recall = {recall}\")\n",
    "\n",
    "\n",
    "# Make confusion matrix:\n",
    "fig, axes = plt.subplots(constrained_layout=True, figsize=(12, 4), ncols=3)\n",
    "axes[0].set_title(\"Train\")\n",
    "axes[1].set_title(\"Test\")\n",
    "axes[2].set_title(\"Train & Test\")\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    best_tree,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    display_labels=species_encoder.classes_,\n",
    "    ax=axes[0],\n",
    "    colorbar=False,\n",
    ")\n",
    "fig.colorbar(axes[0].images[0], ax=axes[0], shrink=0.5)\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    best_tree,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    display_labels=species_encoder.classes_,\n",
    "    ax=axes[1],\n",
    "    colorbar=False,\n",
    ")\n",
    "fig.colorbar(axes[1].images[0], ax=axes[1], shrink=0.5)\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    best_tree,\n",
    "    X,\n",
    "    y,\n",
    "    display_labels=species_encoder.classes_,\n",
    "    ax=axes[2],\n",
    "    colorbar=False,\n",
    ")\n",
    "fig.colorbar(axes[2].images[0], ax=axes[2], shrink=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62461845",
   "metadata": {},
   "source": [
    "#### Answer to question 11.2(b):\n",
    "The precision and recall was 0.95 and the depth of the tree was 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb58396",
   "metadata": {},
   "source": [
    "### 11.2(c) Micro-averaged precision vs. recall\n",
    "You may have noted that the precision and recall give the same value when using micro-averaging.\n",
    "Can you explain this from the definitions of the micro-averaged precision and recall,\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{recall}_\\text{micro} = \\frac{\\sum_{i} TP_i}{\\sum_{i} TP_i + \\sum_{i} FN_i}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{precision}_\\text{micro} = \\frac{\\sum_{i} TP_i}{\\sum_{i} TP_i + \\sum_{i} FP_i}\n",
    "\\end{equation}\n",
    "\n",
    "where the sum runs over all classes?\n",
    "\n",
    "**Hint:** Give an argument for the two sums $\\sum_{i} FN_i$ and $\\sum_{i} FP_i$ being equal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef7b3dc",
   "metadata": {},
   "source": [
    "#### Answer to question 11.2(c):\n",
    "\n",
    "Well, according to the definition given in the beginning of problem [11.2(b)](#11.2(b)-Creating-the-decision-tree)\n",
    "there is no distinction between the mistakes as positive, so both the recall and precision are obtained\n",
    "as the number of true positives divided by the total number of positives predicted.\n",
    "\n",
    "In different classification strategies (for instance, the so-called one-vs-rest that\n",
    "splits a multi-class classification\n",
    "into one binary classification per class) a false negative will be a false positive for another class. In this\n",
    "case $\\sum_{i} FN_i = \\sum_{i} FP_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b05c86",
   "metadata": {},
   "source": [
    "### 11.2(d) Visualize your decision tree\n",
    "\n",
    "Visualize your decision tree and compare it with your answer to [11.1(b)](#11.1(b)-Exploring-by-plotting). Are the rules found\n",
    "by the decision tree (this is easier to compare if you did not go all-out on the depth of your decision tree) similar to your rules?\n",
    "\n",
    "Here is an example of how you can visualize a decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64727ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "from IPython.display import SVG\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "dot_data = export_graphviz(\n",
    "    best_tree,\n",
    "    out_file=None,\n",
    "    feature_names=xvars,\n",
    "    class_names=species_encoder.classes_,\n",
    "    rounded=True,\n",
    "    filled=True,\n",
    ")\n",
    "graph = graphviz.Source(dot_data)\n",
    "SVG(graph.pipe(format=\"svg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d8deb7",
   "metadata": {},
   "source": [
    "#### Answer to question 11.2(d):\n",
    "If we make a simplified interpretation of the tree (simplified = only paying attention to where we have\n",
    "most penguins). We see that:\n",
    "\n",
    "1. Gentoo penguins a penguins with a flipper length larger than 207.5 mm\n",
    "2. Adelie penguins are penguins with a flipper length smaller than 207.5 mm and a bill length smaller than 42.35 mm.\n",
    "3. Chinstrap penguins are penguins with a flipper length smaller than 207.5 mm and a bill length larger than 42.35 mm.\n",
    "\n",
    "This compare well to the answer to [11.1(b)](#Answer-to-question-11.1(b):)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7af690",
   "metadata": {},
   "source": [
    "## 11.3 Exploring the penguins with partial least squares discriminant analysis (PLS-DA)\n",
    "\n",
    "Partial least squares discriminant analysis is essentially PLS for categorical y-variables. Since it works with categorical variables, we can use it for classification and we will do that here. For the most part,\n",
    "[11.3](#11.3-Exploring-the-penguins-with-partial-least-squares-discriminant-analysis-(PLS-DA)) only asks you to run some code and observe the results!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7526592",
   "metadata": {},
   "source": [
    "### 11.3(a) Converting categorical data to numerical values\n",
    "\n",
    "First, we will convert the categorical data in the original data set to numerical values. We have to be\n",
    "careful here and remember that PLS will use these numerical values in calculations. We will,\n",
    "therefore, encode them so that the numbers only have meaning in terms of a variable being \"on\" or \"off\".\n",
    "\n",
    "Since this is also a common strategy to deal with categorical data, there is a method in pandas to do just this\n",
    "and this method is called [get_dummies](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec88660",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dum = pd.get_dummies(data)\n",
    "data_dum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb762008",
   "metadata": {},
   "source": [
    "As you can see from the table above, we have now effectively created one variable per category for the categorical\n",
    "variables.\n",
    "\n",
    "For instance, for \"sex\", we now have \"sex_female\" and \"sex_male\" to distinguish between female and\n",
    "male penguins. You will also note that these two new variables are perfectly correlated:\n",
    "If one of them is 1, then the other has to be 0! This means that we have introduced a lot of correlations in our new data set. If we were doing least squares regression, we would have kept only one of the two variables. We could have fixed that automatically by using\n",
    "```python\n",
    "data_dum = pd.get_dummies(data, drop_first=True)\n",
    "```\n",
    "\n",
    "(This also means that as long as we have only two categories for a variable, `pd.get_dummies(data, drop_first=True)` will just be the same as directly coding the variable as zeros and ones.)\n",
    "\n",
    "Since PLS is supposed to deal with correlated variables, we will keep all variables in the following!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c620c7",
   "metadata": {},
   "source": [
    "### 11.3(b) Creating a PLS model and inspecting loadings\n",
    "\n",
    "We will now create the PLS model. Here, we do not attempt to find the best number of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63de1cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "data_dum = pd.get_dummies(data)\n",
    "\n",
    "xvars = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\n",
    "yvars = [i for i in data_dum.columns if i not in xvars]\n",
    "\n",
    "X = scale(data_dum[xvars].to_numpy())\n",
    "Y = data_dum[yvars].to_numpy()\n",
    "pls = PLSRegression(n_components=4, scale=False)\n",
    "pls.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7faa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loadings_plot(pls_model, xvars, yvars, idx1=0, idx2=1, factor=2.5):\n",
    "    \"\"\"Plot the X and Y loadings for a PLS model.\"\"\"\n",
    "    fig, ax = plt.subplots(constrained_layout=True, figsize=(6, 6))\n",
    "\n",
    "    loadingsx = pls_model.x_rotations_\n",
    "    loadingsy = pls_model.y_loadings_\n",
    "\n",
    "    scat = ax.scatter(loadingsx[:, idx1], loadingsx[:, idx2])\n",
    "    for i, xi in enumerate(xvars):\n",
    "        ax.text(loadingsx[i, idx1], loadingsx[i, idx2], xi)\n",
    "\n",
    "    for i, yvar in enumerate(yvars):\n",
    "        ax.plot(\n",
    "            [0, factor * loadingsy[i, idx1]],\n",
    "            [0, factor * loadingsy[i, idx2]],\n",
    "            color=\"red\",\n",
    "        )\n",
    "        text = yvar.split(\"_\")[1]\n",
    "        ax.text(\n",
    "            factor * loadingsy[i, idx1],\n",
    "            factor * loadingsy[i, idx2],\n",
    "            text,\n",
    "            color=\"red\",\n",
    "            va=\"bottom\" if loadingsy[i, idx2] > 0 else \"top\",\n",
    "            ha=\"center\",\n",
    "        )\n",
    "    ax.axhline(y=0, color=\"k\", ls=\":\")\n",
    "    ax.axvline(x=0, color=\"k\", ls=\":\")\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_xlim(-1, 1)\n",
    "    ax.set_ylim(-1, 1)\n",
    "    ax.set(xlabel=f\"PLS component {idx1+1}\", ylabel=f\"PLS component {idx2+1}\")\n",
    "    ax.set_title(\"Loadings\", loc=\"left\")\n",
    "    sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b296a8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_loadings_plot(pls, xvars, yvars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbb58cb",
   "metadata": {},
   "source": [
    "Run the code above and consider the following:\n",
    "\n",
    "1. On the island of Biscoe, what specie do you expect to find the most of? Is there\n",
    "   a specie you do not expect to find on Biscoe?\n",
    "   \n",
    "2. What features distinguish most between female and male penguins?\n",
    "\n",
    "\n",
    "3. Do you agree with the following statement (why/why not):\n",
    "   \"Gentoo penguins are heavier than the other penguin species\".\n",
    "   \n",
    "\n",
    "4. Do you agree with the following statement (why/why not):\n",
    "   \"Gentoo penguins have a larger flipper length and smaller bill depth\n",
    "   than the other penguins\".\n",
    "   \n",
    "\n",
    "5. Do you agree with the following statement (why/why not):\n",
    "   \"The bill length distinguishes Adelie penguins from the other species."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65c5e01",
   "metadata": {},
   "source": [
    "#### Answer to question 11.3(b):\n",
    "\n",
    "\n",
    "> 1. On the island of Biscoe, what specie do you expect to find the most of? Is there\n",
    ">    a specie you do not expect to find on Biscoe?\n",
    "\n",
    "The loading for the island of Biscoe is positively correlated with the loading for Gentoo. It is positively\n",
    "correlated (along PLS component 2) with Adelie and negatively correlated with Chinstrap. Since the\n",
    "correlation is strongest for Gentoo, we expect to find most of these on Biscoe. Also since it is negatively\n",
    "correlated with Chinstrap, we do not expect to find these penguins on Biscoe. This can also be seen from\n",
    "the raw data in [11.1(a)](#Answer-to-question-11.1(a):): there were 44 Adelie samples and 119 Gentoo samples from Biscoe.\n",
    "\n",
    "\n",
    "> 2. What features distinguish most between female and male penguins?\n",
    "\n",
    "Overall, the male loading is positively (and the female is negatively) correlated with bill length and bill depth. There is also a weak positive\n",
    "correlation with the body mass and flipper length. The two most important features seems to be bill length and\n",
    "bill depth - male penguins seem to have larger beaks.\n",
    "\n",
    "\n",
    "> 3. Do you agree with the following statement (why/why not): \"Gentoo penguins are heavier than the\n",
    ">    other penguin species\".\n",
    "\n",
    "Yes, the loading for the body mass is positively correlated with the loading for Gentoo. It is negatively\n",
    "correlated with the two other penguin species.\n",
    "\n",
    "> 4. Do you agree with the following statement (why/why not): \"Gentoo penguins have a larger flipper length and\n",
    ">    smaller bill depth than the other penguins\".\n",
    "   \n",
    "Yes, the loading for Gentoo is positively correlated with the flipper length (along PLS component 1) and\n",
    "negatively correlated with the bill depth.\n",
    "\n",
    "> 5. Do you agree with the following statement (why/why not): \"The bill length distinguish Adelie\n",
    ">    penguins from the other species.\n",
    "\n",
    "Yes, the loading for bill length is negatively correlated with the loading for Adelie. A smaller bill length\n",
    "was also used by the decision tree to classify penguins as Adelie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6af8cd",
   "metadata": {},
   "source": [
    "## 11.3(c) Predicting the sex of penguins\n",
    "\n",
    "In the [original article](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0090081),\n",
    "the authors created several models to predict the sex of different penguin species. Here is an image with their\n",
    "results:\n",
    "\n",
    "\n",
    "| <img src=\"./Figures/penguintable.png\" width=\"100%\">                                   |\n",
    "|:-:|\n",
    "| **Fig. 3** *Regression models for predicting the sex of penguins.*    |\n",
    "\n",
    "**Note:** In Fig. 3 above, the word *Culmen* is used instead of *bill* (i.e., \"culmen length\" is the same as \"bill length\").\n",
    "\n",
    "We will now repeat this with \n",
    "PLS, and we use only the `sex_female` and `sex_male` variables as our Y.\n",
    "First, we create one model for each penguin specie and we will then inspect their\n",
    "regression coefficients and loadings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd922223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models, one per penguin specie:\n",
    "models = {}\n",
    "yvars_ = [\"sex_female\", \"sex_male\"]\n",
    "xvars = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\n",
    "\n",
    "for specie in data[\"species\"].unique():\n",
    "    data_species = data[data[\"species\"] == specie]\n",
    "    data_dum = pd.get_dummies(data_species)\n",
    "\n",
    "    X = scale(data_dum[xvars].to_numpy())\n",
    "    Y = data_dum[yvars_].to_numpy()\n",
    "    pls_model = PLSRegression(n_components=4, scale=False)\n",
    "    pls_model.fit(X, Y)\n",
    "    models[specie] = pls_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464d835b",
   "metadata": {},
   "source": [
    "### 11.3(c)-1 Regression coefficients and loadings for Adelie penguins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93823fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# First, we create a method for showing regression coefficients:\n",
    "def show_regression_coeffs(pls_model, xvars, yvars):\n",
    "    fig, ax = plt.subplots(constrained_layout=True, figsize=(8, 5))\n",
    "    fig.suptitle(\"Regression coefficients\")\n",
    "    pos = np.arange(len(xvars))\n",
    "\n",
    "    ax.axhline(y=0, ls=\":\", color=\"k\")\n",
    "    width2 = 0.8\n",
    "    width = width2 / 2\n",
    "\n",
    "    B_PLS = pls_model.coef_\n",
    "\n",
    "    r1 = ax.bar(pos - 0.25, B_PLS[0, :], width=width, label=\"Female\")\n",
    "    r2 = ax.bar(pos + 0.25, B_PLS[1, :], width=width, label=\"Male\")\n",
    "\n",
    "    for i in pos:\n",
    "        ax.axvline(x=i + 0.5, ls=\":\", color=\"k\")\n",
    "\n",
    "    ax.set_xticks(pos)\n",
    "    ax.set_xticklabels(xvars, rotation=90)\n",
    "    ax.legend()\n",
    "    sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0a0398",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_regression_coeffs(models[\"Adelie\"], xvars, yvars_)\n",
    "create_loadings_plot(models[\"Adelie\"], xvars, yvars_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59cb4fc",
   "metadata": {},
   "source": [
    "If you have a look at the [image given above](#11.3(c)-Predicting-the-sex-of-penguins)\n",
    "from the original article, you see that the performance of the three models for the Adelie penguins are equal (the same percentage of correct classifications are made). Can you explain this using the plots above (i.e., why do the models not change when the authors introduce more variables)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daaa941",
   "metadata": {},
   "source": [
    "#### Answer to question 11.3(c)-1:\n",
    "In the loadings plot we see that the bill depth and bill length are located on top of each other, and\n",
    "that they are correlated positively (or negatively) with male (or female). Since these variables\n",
    "are so close, it means that\n",
    "they are almost perfectly correlated and they describe the same thing in this model. We would then only need one\n",
    "of them when making a predictive model.\n",
    "\n",
    "The flipper length is located far away from both the male and female loadings. Further, we see that the regression\n",
    "coefficients for this variable are small and do not contribute much.\n",
    "\n",
    "We also see that the body mass is correlated with the male/female distinction, and the size of the regression\n",
    "coefficients suggest that the body mass is important for the distinction.\n",
    "\n",
    "Based on this, we would expect that we can make a good model when including the body mass,\n",
    "excluding the flipper length, and including the bill length or the bill depth. We also expect that the model\n",
    "would not improve when adding the flipper length (as it seems to not contribute much) and if we use both the\n",
    "bill length and bill depth, we will not improve the model since these two variables describe the same thing here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b255972",
   "metadata": {},
   "source": [
    "### 11.3(c)-2 Regression coefficients and loadings for Chinstrap penguins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7860448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_regression_coeffs(models[\"Chinstrap\"], xvars, yvars_)\n",
    "create_loadings_plot(models[\"Chinstrap\"], xvars, yvars_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9855bb",
   "metadata": {},
   "source": [
    "For the model for Chinstrap penguins, the authors used only the bill length and bill depth (see the [image given above](#11.3(c)-Predicting-the-sex-of-penguins)). Do you think the model would improve if you also include the body mass?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c5d3bd",
   "metadata": {},
   "source": [
    "#### Answer to question 11.3(c)-2:\n",
    "No, the regression coefficients for the body mass are small (it does not contribute a lot) and the loading for\n",
    "the body mass is not very strongly correlated with the male/female distinction. There is a weak correlation with\n",
    "the sex, but the other variables seem to be more strongly correlated. Let us check this from the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56e5ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "datag = data[data[\"species\"] == \"Chinstrap\"].groupby(\"sex\")\n",
    "fig, axes = plt.subplots(constrained_layout=True, ncols=4, figsize=(8, 2))\n",
    "for x, ax in zip(xvars, axes):\n",
    "    datag[x].plot(kind=\"kde\", legend=(x == \"body_mass_g\"), ax=ax, lw=3)\n",
    "    ax.set_xlabel(x)\n",
    "axes[-1].legend(fontsize=\"x-small\")\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d2c5fc",
   "metadata": {},
   "source": [
    "From the figure above, we see that the flipper length and body mass are not too different for the female/male \n",
    "distinction, and that the bill length and depth separated better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd5bb81",
   "metadata": {},
   "source": [
    "### 11.3(c)-3 Regression coefficients and loadings for Gentoo penguins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42d6547",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_regression_coeffs(models[\"Gentoo\"], xvars, yvars_)\n",
    "create_loadings_plot(models[\"Gentoo\"], xvars, yvars_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5503d21d",
   "metadata": {},
   "source": [
    "For their model for Gentoo penguins, the authors (see the [image given above](#11.3(c)-Predicting-the-sex-of-penguins)) included the bill length (and excluded the flipper length). Do you think the bill length is\n",
    "needed in the model of Gentoo penguins?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5894d9bd",
   "metadata": {},
   "source": [
    "#### Answer to question 11.3(c)-3:\n",
    "We see here that the flipper length and bill length are located close to each other in the loading plot and\n",
    "we expect that these two variables would be of equal importance to the model. This can also be seen from the\n",
    "regression coefficients that are of similar size for these two variables.\n",
    "\n",
    "Thus, if we exclude the flipper length, we should also probably exclude the bill length as it does not seem to\n",
    "be any more important than the flipper length."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6842f379",
   "metadata": {},
   "source": [
    "## 11.4 Building a logistic regression model for Gentoo penguins\n",
    "\n",
    "As a follow-up of [11.3(c)-3](#11.3(c)-3-Regression-coefficients-and-loadings-for-Gentoo-penguins),\n",
    "let us build the\n",
    "same type of\n",
    "[models as the original authors](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0090081#s2),\n",
    "and compare the effect of including the bill length or not. In the original article,\n",
    "the authors used [Logistic regression]() which essentially is least squares + \"something\" \n",
    "that squashes the straight least squares line into binary results (0 or 1, so that we can use the results\n",
    "for classification). Usually, that \"something\" is a sigmoid function\n",
    "(an \"S\" shaped function).\n",
    "\n",
    "\n",
    "Since the authors report the \"% correctly classified\"\n",
    "(see the [image given above](#11.3(c)-Predicting-the-sex-of-penguins))\n",
    "we will here use the accuracy (for a test set) as our metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6517d128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "xvars1 = [\"bill_length_mm\", \"bill_depth_mm\", \"body_mass_g\"]\n",
    "xvars2 = [\"bill_depth_mm\", \"body_mass_g\"]\n",
    "\n",
    "data_gentoo = data[data[\"species\"] == \"Gentoo\"]\n",
    "\n",
    "X1 = scale(data_gentoo[xvars1])\n",
    "X2 = scale(data_gentoo[xvars2])\n",
    "\n",
    "y = LabelEncoder().fit_transform(data_gentoo[\"sex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a62180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def make_model(X_data, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y, stratify=y)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3763e9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just repeat making the model 10 times:\n",
    "scores1 = [make_model(X1, y) for _ in range(10)]\n",
    "print(f\"Model 1 (X = {xvars1})\")\n",
    "print(f\"\\tAccuracy: {np.mean(scores1):.3g} ± {np.std(scores1):.2g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da511374",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2 = [make_model(X2, y) for _ in range(10)]\n",
    "print(f\"Model 2 (X = {xvars2})\")\n",
    "print(f\"\\tAccuracy: {np.mean(scores2):.3g} ± {np.std(scores2):.2g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52421112",
   "metadata": {},
   "source": [
    "Based on the results above, would you say that there is a big effect of including the bill length in the\n",
    "model for Gentoo penguins?\n",
    "Is this in agreement with your answer to [11.3(c)-3](#Answer-to-question-11.3(c)-3:)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ee7993",
   "metadata": {},
   "source": [
    "#### Answer to question 11.4:\n",
    "\n",
    "The accuracy of these two models seem to approximately be the same, especially if we consider the\n",
    "standard deviation in the accuracy. This supports our answer to [11.3(c)-3](#Answer-to-question-11.3(c)-3:) \n",
    "where we said that we probably did not need the bill length."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdeef0fd",
   "metadata": {},
   "source": [
    "# Least squares for a more difficult case\n",
    "Here, we will try to predict the age of [abalone](https://en.wikipedia.org/wiki/Abalone) from physical measurements. The data is taken from the\n",
    "[UCI Machine Learning Repository](https://doi.org/10.24432/C55C7W), and to quote that page, \n",
    "\n",
    "> The age of abalone is determined by cutting the shell through the cone, staining it, and counting the number of rings through a microscope -- a boring and time-consuming task. Other measurements, which are easier to obtain, are used to predict the age. Further information, such as weather patterns and location (hence food availability) may be required to solve the problem.\n",
    "\n",
    "The data we have available contains 4177 samples, and the following information is available:\n",
    "\n",
    "\n",
    "| name           | description                           | units   |\n",
    "|:---------------|:--------------------------------------|:--------|\n",
    "| Sex            | (M)ale, (F)emale, and (I)nfant        |         |\n",
    "| Length         | Longest shell measurement             | mm      |\n",
    "| Diameter       | Perpendicular to length               | mm      |\n",
    "| Height         | With meat in shell                    | mm      |\n",
    "| Whole_weight   | Whole abalone                         | grams   |\n",
    "| Shucked_weight | Weight of meat                        | grams   |\n",
    "| Viscera_weight | Gut weight (after bleeding)           | grams   |\n",
    "| Shell_weight   | After being dried                     | grams   |\n",
    "| Rings          | +1.5 gives the age in years           |         |\n",
    "\n",
    "We will now attempt to predict the age using these variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4095cb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_theme(style=\"ticks\", context=\"notebook\", palette=\"muted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b40539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"abalone.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3720a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"age\"] = data[\"rings\"] + 1.5\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeaec4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877a57d8",
   "metadata": {},
   "source": [
    "## Initial exploration\n",
    "\n",
    "Before we start making models, we must have a look at our raw data. We are going to check for missing values, patterns or anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81013de",
   "metadata": {},
   "source": [
    "### Missing values?\n",
    "\n",
    "Missing values are like \"holes\" in our data and many methods can not be applied if data is missing.\n",
    "\n",
    "One way to check if there are missing values is to ask pandas to check if\n",
    "some columns contain one or more [Not a number (NaN)](https://en.wikipedia.org/wiki/NaN):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17144d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd2bde2",
   "metadata": {},
   "source": [
    "We can also ask pandas to write out how many NaN's there are in each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465d306b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34ba0b6",
   "metadata": {},
   "source": [
    "We are lucky! There are no missing numbers and we do not have to deal with the potential problems this may cause. How to deal with missing numbers will be a topic for a later lecture in the course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685fc5ed",
   "metadata": {},
   "source": [
    "### Interesting distributions?\n",
    "\n",
    "Before we model, we should look at distributions of the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398b1900",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data, x=\"age\", kind=\"kde\", hue=\"sex\")\n",
    "# test with hue and kind and y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6b6a22",
   "metadata": {},
   "source": [
    "### Scatter plot matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9bc4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.pairplot(data, diag_kind=\"kde\", hue=\"sex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dec158",
   "metadata": {},
   "source": [
    "### Correlations\n",
    "\n",
    "The Scatter Plot Matrix can be difficult to read for many variables. We can reduce the plots to just numbers by\n",
    "calculating correlations between different pairs of variables. We will here use the\n",
    "[Pearson correlation coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient). This\n",
    "is a number between -1 and 1 that quantifies the correlation between a pair of variables. Here is a picture\n",
    "from Wikipedia that shows different situations:\n",
    "\n",
    "![Pearson correlation coefficient - picture](https://upload.wikimedia.org/wikipedia/commons/thumb/3/34/Correlation_coefficient.png/600px-Correlation_coefficient.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d730953",
   "metadata": {},
   "outputs": [],
   "source": [
    "xvariables = [\n",
    "    \"length\",\n",
    "    \"diameter\",\n",
    "    \"height\",\n",
    "    \"whole weight\",\n",
    "    \"shucked weight\",\n",
    "    \"viscera weight\",\n",
    "    \"shell weight\",\n",
    "]\n",
    "yvariables = [\"age\"]\n",
    "\n",
    "variables = xvariables + yvariables\n",
    "corr = data[variables].corr()\n",
    "corr.style.background_gradient(cmap=\"vlag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fabf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    cmap=\"vlag\",\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    annot=True,\n",
    "    ax=ax,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fa3fcd",
   "metadata": {},
   "source": [
    "## Model 1: Least squares using all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ba5f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f54f7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xvariables = [\n",
    "    \"length\",\n",
    "    \"diameter\",\n",
    "    \"height\",\n",
    "    \"whole weight\",\n",
    "    \"shucked weight\",\n",
    "    \"viscera weight\",\n",
    "    \"shell weight\",\n",
    "]\n",
    "y = data[\"age\"]\n",
    "X = data[xvariables]\n",
    "model1 = LinearRegression(fit_intercept=True)\n",
    "model1.fit(X, y)\n",
    "y_hat = model1.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0802bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(model, X, y_true):\n",
    "    \"\"\"Caclulate some metrics for a model and plot predicted values and residuals.\"\"\"\n",
    "    y_predict = model.predict(X)\n",
    "    fig, (ax1, ax2) = plt.subplots(\n",
    "        constrained_layout=True, ncols=2, figsize=(6, 3), sharex=True\n",
    "    )\n",
    "    r2 = r2_score(y_true, y_predict)\n",
    "\n",
    "    try:\n",
    "        coefficients = model.coef_\n",
    "    except:\n",
    "        reg = model.named_steps[\"regression\"]\n",
    "        coefficients = reg.coef_\n",
    "    n = len(X)\n",
    "    r2_adj = 1 - (1 - r2) * (n - 1) / (n - len(coefficients) - 1)\n",
    "\n",
    "    mse = mean_squared_error(y_true, y_predict)\n",
    "    ax1.scatter(y_predict, y_true)\n",
    "    ax1.set_title(\n",
    "        f\"R² = {r2:.3f}, R²(adj) = {r2_adj:.3f},\\nMSE = {mse:.3f}\", loc=\"left\"\n",
    "    )\n",
    "    ax1.set(xlabel=\"ŷ\", ylabel=\"y\")\n",
    "    ax2.scatter(y_predict, y_true - y_predict)\n",
    "    ax2.axhline(y=0, ls=\":\", color=\"k\")\n",
    "    ax2.set(xlabel=\"ŷ\", ylabel=\"(y - ŷ)\")\n",
    "    ax2.set_title(\"Residuals\", loc=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa49cdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_model(model1, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3931c424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_coefficients(model, variables=None, add_label=True):\n",
    "    \"\"\"Display coefficients for a linear model.\"\"\"\n",
    "    figi, axi = plt.subplots(constrained_layout=True)\n",
    "    try:\n",
    "        coefficients = model.coef_\n",
    "    except:\n",
    "        reg = model.named_steps[\"regression\"]\n",
    "        coefficients = reg.coef_\n",
    "        # Attempt to generate variable names:\n",
    "        poly = model.named_steps[\"polynomial\"]\n",
    "        variables = poly.get_feature_names_out(input_features=variables)\n",
    "\n",
    "    pos = list(range(len(variables)))\n",
    "    bars = axi.bar(pos, coefficients)\n",
    "    if add_label:\n",
    "        axi.bar_label(bars, fmt=\"{:.2f}\")\n",
    "    axi.axhline(y=0, ls=\":\", color=\"k\")\n",
    "    axi.set_xticks(pos)\n",
    "    axi.set_xticklabels(variables, rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6254b92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_coefficients(model1, variables=xvariables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7410e9e1",
   "metadata": {},
   "source": [
    "### Model 1.1: Does it help changing variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e81cf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_SELECTION = [\"length\"]\n",
    "y = data[\"age\"]\n",
    "X = data[MY_SELECTION]\n",
    "\n",
    "model11 = LinearRegression(fit_intercept=True)\n",
    "model11.fit(X, y)\n",
    "\n",
    "show_coefficients(model11, variables=MY_SELECTION)\n",
    "score_model(model11, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2434c03c",
   "metadata": {},
   "source": [
    "### Model 1.2: Does it help focusing on infants?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156dd74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data[data[\"sex\"] == \"I\"]\n",
    "\n",
    "y = data2[\"age\"]\n",
    "X = data2[xvariables]\n",
    "\n",
    "model12 = LinearRegression(fit_intercept=True)\n",
    "model12.fit(X, y)\n",
    "score_model(model12, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5b0e4e",
   "metadata": {},
   "source": [
    "### Model 2: Adding higher order terms\n",
    "The first linear model are not too impressive. We shall now try to add higher order terms and interactions.\n",
    "Interactions are terms of the tyoe (as an example) \"length × diameter\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243676e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_modified = data.copy()\n",
    "data_modified[\"length * diameter\"] = data[\"length\"] * data[\"diameter\"]\n",
    "\n",
    "xvariables = [\n",
    "    \"length\",\n",
    "    \"diameter\",\n",
    "    \"height\",\n",
    "    \"whole weight\",\n",
    "    \"shucked weight\",\n",
    "    \"viscera weight\",\n",
    "    \"shell weight\",\n",
    "    \"length * diameter\",\n",
    "]\n",
    "\n",
    "\n",
    "X = data_modified[xvariables]\n",
    "y = data_modified[\"age\"]\n",
    "\n",
    "model2 = LinearRegression(fit_intercept=True)\n",
    "model2.fit(X, y)\n",
    "show_coefficients(model2, variables=xvariables)\n",
    "score_model(model2, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2e5abc",
   "metadata": {},
   "source": [
    "One way to add many higher order terms is to use [PolynomialFeatures](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) from sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1149c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5562621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all second order terms and interactions\n",
    "\n",
    "xvariables = [\n",
    "    \"length\",\n",
    "    \"diameter\",\n",
    "    \"height\",\n",
    "    \"whole weight\",\n",
    "    \"shucked weight\",\n",
    "    \"viscera weight\",\n",
    "    \"shell weight\",\n",
    "]\n",
    "\n",
    "X = data[xvariables]\n",
    "y = data[\"age\"]\n",
    "\n",
    "polynomial = PolynomialFeatures(degree=7, include_bias=False)\n",
    "steps = [\n",
    "    (\"polynomial\", polynomial),\n",
    "    (\"regression\", LinearRegression(fit_intercept=True)),\n",
    "]\n",
    "model2 = Pipeline(steps=steps)\n",
    "model2.fit(X, y)\n",
    "score_model(model2, X, y)\n",
    "# show_coefficients(model2, variables=xvariables, add_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78312390",
   "metadata": {},
   "source": [
    "## Checking the performance by using a training and test set.\n",
    "We have certainly added many variables now. But the R² value did not improve that much. When adding variables,\n",
    "we might overfit our model. One way to check for this is to use a strategy with training and tests sets. The main\n",
    "idea is: we make our model on one part of the data (the training set), and test it on another (the test set).\n",
    "The test set is not used when creating the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8e6c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d6b477",
   "metadata": {},
   "outputs": [],
   "source": [
    "xvariables = [\n",
    "    \"length\",\n",
    "    \"diameter\",\n",
    "    \"height\",\n",
    "    \"whole weight\",\n",
    "    \"shucked weight\",\n",
    "    \"viscera weight\",\n",
    "    \"shell weight\",\n",
    "]\n",
    "\n",
    "\n",
    "X = scale(data[xvariables])\n",
    "y = scale(data[\"age\"])\n",
    "\n",
    "# Note: For scaling, we should fit the scaler to the training set\n",
    "# and the apply it to the test set. The code above is a\n",
    "# simplification.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e12098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_train_test(model, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Do some scoring for models made with a test and training set.\"\"\"\n",
    "    y_train_predict = model.predict(X_train)\n",
    "    y_test_predict = model.predict(X_test)\n",
    "    r2_train = r2_score(y_train, y_train_predict)\n",
    "    r2_test = r2_score(y_test, y_test_predict)\n",
    "    mse_train = mean_squared_error(y_train, y_train_predict)\n",
    "    mse_test = mean_squared_error(y_test, y_test_predict)\n",
    "    fig, axes = plt.subplots(\n",
    "        ncols=2, nrows=2, constrained_layout=True, sharex=True\n",
    "    )\n",
    "\n",
    "    axes[0, 0].scatter(y_train_predict, y_train)\n",
    "    axes[0, 0].set_title(\n",
    "        f\"Training: R² = {r2_train:.3g}, MSE = {mse_train:.3g}\"\n",
    "    )\n",
    "\n",
    "    axes[0, 1].scatter(y_test_predict, y_test)\n",
    "    axes[0, 1].set_title(f\"Test: R² = {r2_test:.3g}, MSE = {mse_test:.3g}\")\n",
    "\n",
    "    axes[0, 0].set(xlabel=\"ŷ\", ylabel=\"y\")\n",
    "    axes[0, 1].set(xlabel=\"ŷ\", ylabel=\"y\")\n",
    "\n",
    "    axes[1, 0].scatter(y_train_predict, y_train - y_train_predict)\n",
    "    axes[1, 1].scatter(y_test_predict, y_test - y_test_predict)\n",
    "\n",
    "    axes[1, 0].set(xlabel=\"ŷ\", ylabel=\"y-ŷ\")\n",
    "    axes[1, 1].set(xlabel=\"ŷ\", ylabel=\"y-ŷ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07cc848",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LinearRegression(fit_intercept=False)\n",
    "model1.fit(X_train, y_train)\n",
    "score_train_test(model1, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaef6ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [\n",
    "    (\"polynomial\", PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    (\"leastsquares\", LinearRegression(fit_intercept=False)),\n",
    "]\n",
    "model2 = Pipeline(steps=steps)\n",
    "model2.fit(X_train, y_train)\n",
    "score_train_test(model2, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44073994",
   "metadata": {},
   "source": [
    "### Can alternative methods help us?\n",
    "\n",
    "It can be a lot of work to compare different models and try different selections of variables. Let us\n",
    "try an alternative, the [least absolute shrinkage and selection operator (LASSO)](https://en.wikipedia.org/wiki/Lasso_(statistics)).\n",
    "This one modifies the error we minimize. In least squares we minimize the\n",
    "squared errors,\n",
    "\n",
    "\\begin{equation}\n",
    "J = \\frac{1}{N} \\sum_{i=1}^N (y_i - \\hat{y}_i)^2.\n",
    "\\end{equation}\n",
    "\n",
    "where $\\hat{y}_i = b_0 + b_1 x_1 + \\ldots = b_0 + \\sum_{j=1}^m b_j x_j$,\n",
    "while in LASSO, we minimize,\n",
    "\n",
    "\\begin{equation}\n",
    "J = \\frac{1}{N} \\sum_{i=1}^N (y_i - \\hat{y}_i)^2 + \\alpha \\sum_{j=1}^m | b_j | .\n",
    "\\end{equation}\n",
    "\n",
    "The practical outcome of this is that the minimization penalizes large coefficients and can now find solutions where some $b_j$'s are zero (= not important\n",
    "for the model!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82c5002",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "data_p = poly.fit_transform(data[xvariables])\n",
    "\n",
    "\n",
    "data_poly = pd.DataFrame(\n",
    "    data_p,\n",
    "    columns=poly.get_feature_names_out(),\n",
    ")\n",
    "\n",
    "\n",
    "X = scale(data[xvariables])\n",
    "y = scale(data[\"age\"])\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "# Note: For scaling, we should fit the scaler to the training set\n",
    "# and the apply it to the test set. The code above is a\n",
    "# simplification.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df00418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "model3 = Lasso(alpha=0.01, fit_intercept=False, max_iter=10000)\n",
    "model3.fit(X_train, y_train)\n",
    "score_train_test(model3, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ced390",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_coefficients(model3, variables=xvariables, add_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee0d04c",
   "metadata": {},
   "source": [
    "### Concluding remarks\n",
    "OK, we do not have super impressive results. Maybe we should try something completely different?\n",
    "\n",
    "What we have done with the training and test set is completely general. If we try other supervised\n",
    "learning methods, we can still calculate $R^2$, the mean squared error, and use the training/testing strategy.\n",
    "Here are some tests for three extra methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4e1f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR  # Support Vector Machine\n",
    "\n",
    "model5 = SVR()\n",
    "model5.fit(X_train, y_train)\n",
    "score_train_test(model5, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebe5e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor  # A multi-layer Perceptron\n",
    "\n",
    "model7 = MLPRegressor(\n",
    "    max_iter=10000,\n",
    ")\n",
    "model7.fit(X_train, y_train)\n",
    "score_train_test(model7, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cbd6fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "model8 = CatBoostRegressor()\n",
    "model8.fit(X_train, y_train)\n",
    "score_train_test(model8, X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

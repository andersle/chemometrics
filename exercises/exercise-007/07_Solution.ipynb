{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "801b2291",
   "metadata": {},
   "source": [
    "# Solution to exercise set 7\n",
    "\n",
    "The main goal of this exercise is to gain practical experience with signal processing techniques used for preprocessing, for instance, of Near-Infrared (NIR) spectra. Preprocessing methods are important for improving the signal-to-noise ratio, correcting for scattering effects (variations in light path due to particle size, etc.), and enhancing spectral features, which can lead to more reliable analysis and development of robust predictive models. In addition, you will see how we can smooth noisy signals and calculate the derivative of a noisy signal.\n",
    "\n",
    "**Learning Objectives:**\n",
    "\n",
    "After completing this exercise set, you will be able to:\n",
    "\n",
    "- Preprocess spectra by normalisation, multiplicative scatter correction, or taking a second derivative.\n",
    "- Create a spline to smooth a signal and compute its derivative.\n",
    "\n",
    "**To get the exercise approved, complete the following problems:**\n",
    "\n",
    "- [7.1(a)](#7.1(a)) and at least one of [7.1(b)](#7.1(b)), [7.1(c)](#7.1(c)), or [7.1(d)](#7.1(d)): To show that you can apply preprocessing to NIR spectra.\n",
    "- [7.2(a)](#7.2(a)) and [7.2(c)](#7.2(c)): To show that you can create a B-spline to smooth a signal and compute its derivative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0b4748",
   "metadata": {},
   "source": [
    "## Exercise 7.1 Preprocessing NIR spectra\n",
    "\n",
    "We will analyze NIR spectra from two distinct Ethiopian [sorghum](https://en.wikipedia.org/wiki/Sorghum) cultivars to determine if they can be differentiated. Specifically, we will examine how different preprocessing techniques impact the outcome of a principal component analysis (PCA) applied to the spectra. \n",
    "\n",
    "**Note:**\n",
    "\n",
    "1. The dataset used in this exercise is derived from [Kosmowski and Worku\n",
    "](https://doi.org/10.1371/journal.pone.0193620) who used a miniaturised NIR spectrometer to identify Ethiopian crop cultivars. To simplify the analysis, we focus on measurements from only two of the ten sorghum cultivars studied in the original work\n",
    "\n",
    "2. This exercise will mainly ask you to run and observe results from already implemented code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556ace50",
   "metadata": {},
   "source": [
    "### 7.1(a)\n",
    "\n",
    "The following code performs these steps:\n",
    "\n",
    "1. Load the NIR spectra from the data file [nir.csv](./nir.csv).\n",
    "2. Extracts wavelengths, spectra, and cultivar names.\n",
    "3. Defines colors for plotting cultivars.\n",
    "4. Creates a function to plot spectra by cultivar.\n",
    "5. Creates a function to run a PCA on provided spectra and plot the scores of the first two principal components.\n",
    "6. Initializes a figure for results.\n",
    "7. Plots the original spectra and the PCA results.\n",
    "\n",
    "**Task: Execute the code and observe the generated plot. In the PCA scores plot, are there any noticeable groupings that suggest cultivar separation?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f161cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the needed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_theme(style=\"ticks\", context=\"notebook\", palette=\"colorblind\")\n",
    "\n",
    "# Load the raw data:\n",
    "data = pd.read_csv(\"nir.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb1b93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract information from the data\n",
    "\n",
    "variables = [i for i in data.columns if i != \"Cultivator\"]\n",
    "# Wavelengths as numbers:\n",
    "wavelengths = np.array([float(i) for i in variables])\n",
    "print(f\"Number of wavelengths {len(wavelengths)}\")\n",
    "# All spectra as a data matrix:\n",
    "all_spectra = data[variables].to_numpy()\n",
    "print(f\"Size of data matrix: {all_spectra.shape}\")\n",
    "# Name of the two cultivators:\n",
    "cultivators = data[\"Cultivator\"].unique()\n",
    "print(\"Cultivators:\", cultivators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d51d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a color mapping for the two cultivators:\n",
    "colors = sns.color_palette(\"colorblind\", n_colors=len(cultivators))\n",
    "color_mapping = {key: colori for key, colori in zip(cultivators, colors)}\n",
    "# Show the two colors\n",
    "colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7974b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectra(\n",
    "    data, X, wavelengths, cultivators, color_mapping, axi, legend=False\n",
    "):\n",
    "    \"\"\"\n",
    "\n",
    "    Plots NIR spectra from the given data matrix X, color-coded by cultivar.\n",
    "\n",
    "    Args:\n",
    "        data (pandas.DataFrame): DataFrame containing cultivar information.\n",
    "        X (numpy.ndarray): Matrix of NIR spectra, where each row is a spectrum.\n",
    "        wavelengths (numpy.ndarray): Array of corresponding wavelengths for the spectra.\n",
    "        cultivators (list): List of unique cultivar names.\n",
    "        color_mapping (dict): Dictionary mapping cultivar names to colors.\n",
    "        axi (matplotlib.axes.Axes): Matplotlib Axes object for plotting.\n",
    "        legend (bool, optional): Whether to include a legend. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        None (plots directly to the provided Axes object).\n",
    "    \"\"\"\n",
    "    handles, labels = (\n",
    "        [],\n",
    "        [],\n",
    "    )  # Initialize empty lists to store legend handles and labels\n",
    "    for cultivator in cultivators:\n",
    "        # Filter spectra belonging to the current cultivar\n",
    "        spectra_cult = X[data[\"Cultivator\"] == cultivator]\n",
    "        for spectrum in spectra_cult:\n",
    "            # Plot each spectrum with the assigned color\n",
    "            (linei,) = axi.plot(\n",
    "                wavelengths, spectrum, color=color_mapping[cultivator]\n",
    "            )\n",
    "        # Append the line handle and cultivar label for the legend\n",
    "        handles.append(linei)\n",
    "        labels.append(cultivator)\n",
    "    if legend:\n",
    "        # Add a legend to the plot if 'legend' is True\n",
    "        legend = axi.legend(handles, labels, title=\"Cultivator:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c32b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pca_plot_scores(data, X, axi, cultivators, color_mapping):\n",
    "    \"\"\"\n",
    "    Performs Principal Component Analysis (PCA) on the input spectra and plots the scores (color-coded).\n",
    "\n",
    "    Args:\n",
    "        data (pandas.DataFrame): DataFrame containing cultivar information.\n",
    "        X (numpy.ndarray): Matrix of NIR spectra, where each row is a spectrum.\n",
    "        axi (matplotlib.axes.Axes): Matplotlib Axes object for plotting.\n",
    "        cultivators (list): List of unique cultivar names.\n",
    "        color_mapping (dict): Dictionary mapping cultivar names to colors.\n",
    "\n",
    "    Returns:\n",
    "        None (plots directly to the provided Axes object).\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=2)  # Initialize PCA with 2 components\n",
    "    scores = pca.fit_transform(X)  # Perform PCA and get the scores\n",
    "\n",
    "    for cultivator in cultivators:\n",
    "        # Filter scores for the current cultivar\n",
    "        xscores = scores[data[\"Cultivator\"] == cultivator, 0]\n",
    "        yscores = scores[data[\"Cultivator\"] == cultivator, 1]\n",
    "\n",
    "        # Plot the scores as a scatter plot\n",
    "        axi.scatter(\n",
    "            xscores, yscores, color=color_mapping[cultivator], label=cultivator\n",
    "        )\n",
    "    # Calculate explained variance ratios\n",
    "    perc = pca.explained_variance_ratio_ * 100\n",
    "    # Set axis labels with explained variance percentages\n",
    "    axi.set_xlabel(f\"Scores PC1 ({perc[0]:.2f}%)\")\n",
    "    axi.set_ylabel(f\"Scores PC2 ({perc[1]:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4e82e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure1, axes1 = plt.subplots(constrained_layout=True, ncols=2, figsize=(8, 4))\n",
    "\n",
    "plot_spectra(\n",
    "    data,\n",
    "    all_spectra,\n",
    "    wavelengths,\n",
    "    cultivators,\n",
    "    color_mapping,\n",
    "    axes1[0],\n",
    "    legend=True,\n",
    ")\n",
    "run_pca_plot_scores(data, all_spectra, axes1[1], cultivators, color_mapping)\n",
    "\n",
    "axes1[0].set_xlabel(\"Wavelength (nm)\")\n",
    "axes1[0].set_ylabel(\"Absorbance\")\n",
    "axes1[0].set_title(\"Original spectra\", loc=\"left\")\n",
    "axes1[1].set_title(\"PCA, Original spectra\", loc=\"left\")\n",
    "sns.despine(fig=figure1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a696a08",
   "metadata": {},
   "source": [
    "#### Your answer to question 7.1(a): Is there a clear cultivar separation in the scores plot?\n",
    "\n",
    "There is some separation in the scores plot, but the cultivars are not separated (they are overlapping)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dad47d",
   "metadata": {},
   "source": [
    "### 7.1(b)\n",
    "\n",
    "**Task: Observe the impact of normalisation on the spectra and PCA results. In the PCA scores plot, are there any noticeable groupings that suggest cultivar separation?**\n",
    "\n",
    "**Hint:**\n",
    "1. Apply the provided normalization function to scale the spectra to the range $[-1, 1]$, for instance,\n",
    "```python\n",
    "normed = normalise_spectra(all_spectra)\n",
    "```\n",
    "2. Plot the normalised spectra and the corresponding PCA results side-by-side. For instance,\n",
    "```python\n",
    "figure2, axes2 = plt.subplots(constrained_layout=True, ncols=2, figsize=(8, 4))\n",
    "plot_spectra(data, normed, wavelengths, cultivators, color_mapping, axes2[0])\n",
    "run_pca_plot_scores(data, normed, axes2[1], cultivators, color_mapping)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbe1884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "def normalise_spectra(spectra):\n",
    "    \"\"\"\n",
    "    Normalises the given spectra using MinMaxScaler, scaling each spectrum to the range [-1, 1].\n",
    "\n",
    "    Args:\n",
    "        spectra (numpy.ndarray): Matrix of spectra, where each row is a spectrum.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Normalised spectra matrix.\n",
    "    \"\"\"\n",
    "    scaled = np.zeros_like(spectra)\n",
    "    for i, spectrum in enumerate(spectra):\n",
    "        scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "        scaled[i] = scaler.fit_transform(spectrum.reshape(-1, 1)).flatten()\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda59d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "normed = normalise_spectra(all_spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee93b8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure2, axes2 = plt.subplots(constrained_layout=True, ncols=2, figsize=(8, 4))\n",
    "plot_spectra(\n",
    "    data,\n",
    "    normed,\n",
    "    wavelengths,\n",
    "    cultivators,\n",
    "    color_mapping,\n",
    "    axes2[0],\n",
    "    legend=True,\n",
    ")\n",
    "run_pca_plot_scores(data, normed, axes2[1], cultivators, color_mapping)\n",
    "\n",
    "axes2[0].set_xlabel(\"Wavelength (nm)\")\n",
    "axes2[0].set_ylabel(\"Normalised Absorbance\")\n",
    "axes2[0].set_title(\"Normalised spectra\", loc=\"left\")\n",
    "axes2[1].set_title(\"PCA, normalised spectra\", loc=\"left\")\n",
    "sns.despine(fig=figure2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da80184e",
   "metadata": {},
   "source": [
    "#### Your answer to question 7.1(b): Is there a clear cultivar separation in the scores plot?\n",
    "\n",
    "The scores plot shows a clear separation, with `Teshale` samples forming a distinct group on the left and `Gambella_1107` on the right. There is some overlap between the groups, but the separation is significantly improved compared to the unprocessed data in ([7.1(a)](#7.1(a)))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb82fb73",
   "metadata": {},
   "source": [
    "### 7.1(c)\n",
    "\n",
    "**Task: Observe the impact of multiplicative scatter correction (MSC) on the spectra and PCA results. In the PCA scores plot, are there any noticeable groupings that suggest cultivar separation?**\n",
    "\n",
    "**Hint:**\n",
    "1. Apply the provided MSC function to correct the spectra, for instance,\n",
    "```python\n",
    "corrected = multiplicative_scatter_correction(all_spectra)\n",
    "```\n",
    "2. Plot the corrected spectra and the corresponding PCA results side-by-side. For instance,\n",
    "```python\n",
    "figure3, axes3 = plt.subplots(constrained_layout=True, ncols=2, figsize=(8, 4))\n",
    "plot_spectra(data, corrected, wavelengths, cultivators, color_mapping, axes3[0])\n",
    "run_pca_plot_scores(data, corrected, axes3[1], cultivators, color_mapping)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835e5c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplicative_scatter_correction(spectra):\n",
    "    \"\"\"\n",
    "    Applies Multiplicative Scatter Correction (MSC) to the input spectra.\n",
    "\n",
    "    MSC is a preprocessing technique used to reduce the effects of scatter in spectral data.\n",
    "    It corrects for variations in path length and particle size, which can affect the\n",
    "    baseline and slope of the spectra.\n",
    "\n",
    "    Args:\n",
    "        spectra (numpy.ndarray): Matrix of spectra, where each row is a spectrum.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: MSC-corrected spectra matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    mean = np.mean(spectra, axis=0)  # Calculate the mean spectrum\n",
    "    msc_spectra = np.zeros_like(\n",
    "        spectra\n",
    "    )  # Initialise an array to store MSC-corrected spectra\n",
    "    for i, spectrum in enumerate(spectra):\n",
    "        # Fit a linear regression model to each spectrum against the mean spectrum\n",
    "        param = np.polyfit(mean, spectrum, 1)\n",
    "        # Apply the MSC correction: (spectrum - intercept) / slope\n",
    "        msc_spectra[i] = (spectrum - param[1]) / (param[0])\n",
    "    return msc_spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfd1dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected = multiplicative_scatter_correction(all_spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8cd394",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure3, axes3 = plt.subplots(constrained_layout=True, ncols=2, figsize=(8, 4))\n",
    "plot_spectra(\n",
    "    data,\n",
    "    corrected,\n",
    "    wavelengths,\n",
    "    cultivators,\n",
    "    color_mapping,\n",
    "    axes3[0],\n",
    "    legend=True,\n",
    ")\n",
    "run_pca_plot_scores(data, corrected, axes3[1], cultivators, color_mapping)\n",
    "\n",
    "axes3[0].set_xlabel(\"Wavelength (nm)\")\n",
    "axes3[0].set_ylabel(\"Corrected absorbance\")\n",
    "axes3[0].set_title(\"MSC spectra\", loc=\"left\")\n",
    "axes3[1].set_title(\"PCA, MSC spectra\", loc=\"left\")\n",
    "sns.despine(fig=figure3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62871c9",
   "metadata": {},
   "source": [
    "#### Your answer to question 7.1(c): Is there a clear cultivar separation in the scores plot?\n",
    "The scores plot shows a clear separation, with `Teshale` samples forming a distinct group in the upper region and `Gambella_1107` in the lower region. There is some overlap between the groups, but the separation is significantly improved compared to the unprocessed data in ([7.1(a)](#7.1(a))) and similar to the normalisation results in [7.1(b)](#7.1(b))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ab6e77",
   "metadata": {},
   "source": [
    "### 7.1(d)\n",
    "\n",
    "**Task: Investigate the impact of applying a second derivative transformation on the spectra and PCA results. In the PCA scores plot, are there any noticeable groupings that suggest cultivar separation?**\n",
    "\n",
    "**Hint:**\n",
    "1. Use the provided code to calculate the second derivative of the original spectra, for instance,\n",
    "\n",
    "```python\n",
    "dspectra = derivative(wavelengths, all_spectra, deriv=2)\n",
    "```\n",
    "2. Plot the resulting second derivative spectra and the corresponding PCA results side-by-side. For instance,\n",
    "```python\n",
    "figure4, axes4 = plt.subplots(constrained_layout=True, ncols=2, figsize=(8, 4))\n",
    "plot_spectra(data, dspectra, wavelengths, cultivators, color_mapping, axes4[0])\n",
    "run_pca_plot_scores(data, dspectra, axes4[1], cultivators, color_mapping)\n",
    "```\n",
    "\n",
    "**Note:** The derivative is computed using the [Savitzky-Golay filter](https://en.wikipedia.org/wiki/Savitzky%E2%80%93Golay_filter).Â This method smooths the data by fitting a polynomial to a moving window of points and then calculates the derivative of that fitted polynomial. The method, as implemented here, assumes evenly spaced data points. It may produce inaccurate results if your wavelengths are unevenly spaced. In such cases, alternative methods like B-spline derivatives or other interpolation-based approaches might be more suitable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a283d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative(wavelengths, spectra, window_length=21, polyorder=3, deriv=2):\n",
    "    \"\"\"\n",
    "    Calculates the derivative of the input spectra using the Savitzky-Golay filter.\n",
    "\n",
    "    This function applies the Savitzky-Golay filter to smooth and differentiate the\n",
    "    input spectra. The filter is used to reduce noise and enhance spectral features.\n",
    "\n",
    "    Args:\n",
    "        wavelengths (numpy.ndarray): Array of wavelengths corresponding to the spectra.\n",
    "        spectra (numpy.ndarray): Matrix of spectra, where each row is a spectrum.\n",
    "        window_length (int): The length of the filter window (must be odd).\n",
    "        polyorder (int): The order of the polynomial used to fit the samples.\n",
    "        deriv (int, optional): The order of the derivative to compute. Defaults to 2 (second derivative).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Matrix of derivative spectra.\n",
    "    \"\"\"\n",
    "\n",
    "    derivative = np.zeros_like(\n",
    "        spectra\n",
    "    )  # Initialize an array to store derivative spectra\n",
    "\n",
    "    for i, spectrum in enumerate(spectra):\n",
    "        # Apply Savitzky-Golay filter to calculate the derivative\n",
    "        derivative[i] = savgol_filter(\n",
    "            spectrum,\n",
    "            window_length,\n",
    "            polyorder,\n",
    "            deriv=deriv,\n",
    "            delta=wavelengths[1] - wavelengths[0],  # Wavelength spacing\n",
    "            mode=\"nearest\",  # Extrapolation mode at the edges\n",
    "        )\n",
    "\n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d73e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dspectra = derivative(wavelengths, all_spectra, deriv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a598a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure4, axes4 = plt.subplots(constrained_layout=True, ncols=2, figsize=(8, 4))\n",
    "plot_spectra(\n",
    "    data,\n",
    "    dspectra,\n",
    "    wavelengths,\n",
    "    cultivators,\n",
    "    color_mapping,\n",
    "    axes4[0],\n",
    "    legend=True,\n",
    ")\n",
    "run_pca_plot_scores(data, dspectra, axes4[1], cultivators, color_mapping)\n",
    "\n",
    "axes4[0].set_xlabel(\"Wavelength (nm)\")\n",
    "axes4[0].set_ylabel(\"Second derivative of absorbance\")\n",
    "axes4[0].set_title(\"Second derivative of spectra\", loc=\"left\")\n",
    "axes4[1].set_title(\"PCA, second derivative of spectra\", loc=\"left\")\n",
    "sns.despine(fig=figure4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c0a567",
   "metadata": {},
   "source": [
    "#### Your answer to question 7.1(d): Is there a clear cultivar separation in the scores plot?\n",
    "\n",
    "Yes, the different cultivars separate into three well-defined clusters. The separation is significantly clearer than in the preceding cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1644ef",
   "metadata": {},
   "source": [
    "### 7.1(e)\n",
    "\n",
    "**Task: Explain how the Savitzky-Golay filter uses polynomial fitting to smooth data and compute derivatives.**\n",
    "\n",
    "**Hint:** See page 149 in our text book."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec66629",
   "metadata": {},
   "source": [
    "#### Your answer to question 7.1(e): Your explanation for Savitzky-Golay filtering?\n",
    "\n",
    "The Savitzky-Golay filter smooths data by operating on a moving window of data points. Within each window, it fits a polynomial curve to the data using least squares. The center point of the window is then replaced with the corresponding value from the fitted polynomial, effectively smoothing the signal. Derivatives are calculated directly from the fitted polynomial within each window."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787f980a",
   "metadata": {},
   "source": [
    "### 7.1(f)\n",
    "\n",
    "**Task: The figure below displays the results of the preprocessing steps from exercise [7.1(a)](#7.1(a)) to [7.1(d)](#7.1(d)). Based on these results, which preprocessing method appears most promising for building a classifier?**\n",
    "\n",
    "![Preprocessing NIR results](results7.1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff977844",
   "metadata": {},
   "source": [
    "#### Your answer to question 7.1(f): Which preprocessing step appears most promising?\n",
    "\n",
    "The scores plot showing the results when applying the second derivative preprocessing yields three well-separated clusters, corresponding to the different cultivars. This strongly suggests that a pipeline of taking the second derivative followed by PCA would generate scores well-suited for classification model input. However, without building a classifier, we cannot definitively rule out the potential effectiveness of the other preprocessing approaches (or their combination). Nevertheless, the results strongly indicate the second derivative as the most promising."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4d81d7",
   "metadata": {},
   "source": [
    "## Exercise 7.2\n",
    "\n",
    "In this exercise, we will smooth and differentiate a noisy signal. We will use a test signal generated from the following analytical function:\n",
    "\n",
    "$$y(t) = \\sin (8t) - 1.8t^2 + 0.5t^3.$$\n",
    "\n",
    "The noise-free signal data is available in the file [signal.txt](signal.txt). The file contains two columns: the first column represents time ($t$), and the second column represents the signal $y(t)$.\n",
    "\n",
    "A noisy version of this signal is provided in the file [signal_noise.txt](signal_noise.txt), which also contains two columns: time ($t$) and the signal $y(t)$ with added noise.\n",
    "\n",
    "The example code below demonstrates how to load and plot the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514196b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_theme(style=\"ticks\", context=\"notebook\", palette=\"colorblind\")\n",
    "\n",
    "t_clean, y_clean = np.loadtxt(\"signal.txt\", unpack=True)\n",
    "t_noisy, y_noisy = np.loadtxt(\"signal_noise.txt\", unpack=True)\n",
    "\n",
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "ax.plot(t_noisy, y_noisy, label=\"With noise (signal_noise.txt)\", alpha=0.5)\n",
    "ax.plot(t_clean, y_clean, label=\"Without noise (signal.txt)\", lw=3)\n",
    "ax.set(xlabel=\"Time (t)\", ylabel=\"Signal (y(t))\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4eeb8d",
   "metadata": {},
   "source": [
    "### 7.2(a)\n",
    "\n",
    "**Task: Smooth the signal with noise using a B-spline. Compare the result to the noise-free signal by plotting both signals.**\n",
    "\n",
    "**Hint:** You can create the B-spline basis set using the `bbase` function from Eilers and Marx (see the code cell below). You can use this function to create the smoothed signal by completing the following steps:\n",
    "\n",
    "1. First calculate the B-spline design matrix `X`:\n",
    "```python\n",
    "ndx = 20  # Number of B-spline segments\n",
    "degree = 3  # B-spline degree\n",
    "X = bbase(t_noisy, ndx=ndx, deg=degree)\n",
    "```\n",
    "\n",
    "2. Create the penalty matrix `Dn` (typically, we use D2 or D3 for better interpolation):\n",
    "```python\n",
    "n = X.shape[1]\n",
    "order = 2  # Order of the penalty (1, 2, or 3)\n",
    "Dn = np.diff(np.eye(n), n=order, axis=0)\n",
    "```\n",
    "\n",
    "3. Create the augmented matrix `Xaug` that combines the design matrix `X` obtained from `bbase` with the scaled penalty matrix `sqrt(gamma)*D`, and the augmented column vector `yaug` that combines the y-values from the data set with a vector of zeros equal in length to the number of rows of D:\n",
    "```python\n",
    "# Create the augmented matrix Xaug\n",
    "gamma = 1  # Adjust this to control smoothing\n",
    "Xaug = np.vstack([X, np.sqrt(gamma) * Dn])\n",
    "# Create the augmented column vector yaug\n",
    "yaug = np.concatenate([y_noisy, np.zeros(Dn.shape[0])])\n",
    "```\n",
    "\n",
    "4. Find the coefficients that best fit the data set by solving the linear equation `Xaug*beta_hat = yaug`.\n",
    "```python\n",
    "# Solve the linear equation Xaug * beta_hat = yaug\n",
    "beta_hat = np.linalg.lstsq(Xaug, yaug, rcond=None)[0]\n",
    "```\n",
    "\n",
    "5. Find the smoothed data `yhat` by calculating `yhat = X*beta_hat`.\n",
    "```python\n",
    "# Calculate the smoothed data yhat\n",
    "y_smooth = X @ beta_hat\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11016535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import factorial\n",
    "\n",
    "\n",
    "def tpower(x, t, p):\n",
    "    \"\"\"Generate degree-p truncated power function.\"\"\"\n",
    "    return np.where(x > t, (x - t) ** p, 0.0)\n",
    "\n",
    "\n",
    "def bbase(x, xl=None, xr=None, ndx=20, deg=3):\n",
    "    \"\"\"Construct a B-spline basis of degree `deg`.\n",
    "\n",
    "    Construct a B-spline basis matrix of a specified degree. This method\n",
    "    is adapted from:\n",
    "\n",
    "    Eilers, P.H.C. and Marx, B.D. (2010), Splines, knots, and penalties.\n",
    "    WIREs Comp Stat, 2: 637-653. https://doi.org/10.1002/wics.125\n",
    "\n",
    "     Args:\n",
    "        x: A sequence or array of data points where the basis functions are evaluated.\n",
    "        xl: The lower boundary for the knots.\n",
    "        xr: The upper boundary for the knots.\n",
    "        ndx: The number of intervals between xl and xr.\n",
    "        deg: The degree of the B-spline.\n",
    "\n",
    "    Returns:\n",
    "        A NumPy array representing the B-spline basis matrix.\n",
    "        Each column is a basis function evaluated at the points in x.\n",
    "        The shape is (len(x), number_of_basis_functions).\n",
    "\n",
    "    \"\"\"\n",
    "    if xl is None:\n",
    "        xl = np.min(x)\n",
    "    if xr is None:\n",
    "        xr = np.max(x)\n",
    "    # Generate knot sequence (extends outside boundaries)\n",
    "    dx = (xr - xl) / ndx\n",
    "    left = xl - deg * dx\n",
    "    right = xr + deg * dx\n",
    "    num_knots = int(round((right - left) / dx)) + 1\n",
    "    knots = np.linspace(left, right, num_knots)\n",
    "\n",
    "    # Compute matrix of TPFs\n",
    "    P = np.zeros((len(x), len(knots)))\n",
    "    for i in range(len(knots)):\n",
    "        P[:, i] = tpower(x, knots[i], deg)\n",
    "\n",
    "    # Compute matrix of b-splines\n",
    "    n = P.shape[1]\n",
    "    D = np.diff(np.eye(n), deg + 1, axis=0) / (factorial(deg) * dx**deg)\n",
    "    B = (-1) ** (deg + 1) * P @ D.T\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7e33d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndx = 20  # Number of B-spline segments\n",
    "degree = 3  # B-spline degree\n",
    "X = bbase(t_noisy, ndx=ndx, deg=degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511deb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X.shape[1]\n",
    "order = 1  # Order of the penalty (1, 2, or 3)\n",
    "Dn = np.diff(np.eye(n), n=order, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0e8226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the augmented matrix Xaug\n",
    "gamma = 1  # Adjust this to control smoothing\n",
    "Xaug = np.vstack([X, np.sqrt(gamma) * Dn])\n",
    "# Create the augmented column vector yaug\n",
    "yaug = np.concatenate([y_noisy, np.zeros(Dn.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5a4998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve the linear equation Xaug * beta_hat = yaug\n",
    "beta_hat = np.linalg.lstsq(Xaug, yaug, rcond=None)[0]\n",
    "# Calculate the smoothed data yhat\n",
    "y_smooth = X @ beta_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed3123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f216b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(constrained_layout=True, ncols=2, figsize=(8, 4))\n",
    "axes[0].plot(t_noisy, y_noisy, label=\"Signal with noise\", alpha=0.25)\n",
    "axes[0].plot(t_clean, y_clean, label=\"Signal without noise\", lw=3)\n",
    "axes[0].plot(t_noisy, y_smooth, label=\"Smoothed Signal\", linewidth=2)\n",
    "axes[0].set(xlabel=\"t\", ylabel=\"y(t)\")\n",
    "axes[0].legend()\n",
    "# Plot the  noise-free vs smoothed\n",
    "axes[1].scatter(y_clean, y_smooth)\n",
    "rmse = root_mean_squared_error(y_clean, y_smooth)\n",
    "axes[1].set(xlabel=\"Signal without noise\", ylabel=\"Smoothed Signal\")\n",
    "axes[1].set_title(f\"RMSE = {rmse:.3f}\")\n",
    "# Add the x=y line:\n",
    "xlim = axes[1].get_xlim()\n",
    "ylim = axes[1].get_ylim()\n",
    "\n",
    "# Calculate the range for the x=y line\n",
    "min_val = min(min(xlim), min(ylim))\n",
    "max_val = max(max(xlim), max(ylim))\n",
    "\n",
    "# Plot the x=y line within the current axes limits\n",
    "axes[1].plot([min_val, max_val], [min_val, max_val], color=\"k\", ls=\":\")\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b8b38f",
   "metadata": {},
   "source": [
    "#### Your answer to question 7.2(a): How does the smoothed signal compare to the noise-free signal?\n",
    "\n",
    "The smoothed signal compares well to the noise-free signal and the smoothing process has removed much of the noise. The smoothed signal follows the trend of the original signal closely and the root mean squared error (RMSE) between the smoothed and noise-free signal is 0.254 (which is a good fit since the noise-free signal has values between -11 and 1). There are some small deviations (e.g., one \"hump\" is shifted around -1.5) but the overall fit is good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e4e40b",
   "metadata": {},
   "source": [
    "### 7.2(b)\n",
    "\n",
    "**Task: We could attempt to estimate the derivative of the noisy signal directly using a finite difference approximation, such as the forward difference method:**\n",
    "\n",
    "$$y'(t_i) \\approx \\frac{y(t_{i+1}) - y(t_i)}{t_{i+1} - t_i}$$\n",
    "\n",
    "**Explain the potential problem(s) associated with this approach when applied to a signal containing substantial noise.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd769e71",
   "metadata": {},
   "source": [
    "#### Your answer to question 7.2(b): What are the potential problem(s) when using the finite difference approximation directly with a noisy signal?\n",
    "\n",
    "The noise makes the signal jump up and down a lot between points. If we take the difference between these jumping points we can get large fluctuations. Assuming that the size of the error is $\\varepsilon_i$, so that the measured points are $y(t_i) =y^\\ast (t_i) \\pm \\varepsilon_i$, where $y^\\ast (t_i)$ is the true noise-free value, then we could potentially compute the derivative as (worst-case),\n",
    "\n",
    "$$y'(t_i) \\approx \\frac{(y^\\ast(t_{i+1}) - y^\\ast(t_i)) +  (\\varepsilon_{i+1}+\\varepsilon_i)}{t_{i+1} - t_i}$$\n",
    "\n",
    "meaning that we get an error proportional to the time step. For small time differences and large errors (compared to $y^\\ast$), this can significantly increase and dominate the derivative. The noise gets amplified, and the real derivative gets lost in the noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4c1082",
   "metadata": {},
   "source": [
    "### 7.2(c)\n",
    "\n",
    "**Task: Calculate the derivative of the smoothed signal from 7.2(a) using the B-spline representation. Compare the derivative to the analytical derivative of the noise-free signal (by plotting both derivatives).**\n",
    "\n",
    "**Hint:**\n",
    "1. The analytical derivative of the noise-free signal is:\n",
    "\n",
    "   $$ y^\\prime(t) = 8\\cos(8t) - 3.6t + 1.5t^2,$$\n",
    "\n",
    "   with Python: \n",
    "```python\n",
    "def analytical_derivative(t):\n",
    "    \"\"\"Calculate the analytical derivative of the noise-free signal.\"\"\"\n",
    "    return 8 * np.cos(8 * t) - 3.6 * t + 1.5 * t**2\n",
    "```\n",
    "\n",
    "2. You can find the first derivative of the B-spline using\n",
    "   ```python\n",
    "   (1 / h) * X_ @ (D1 @ beta_hat\n",
    "   ```\n",
    "   where:\n",
    "   \n",
    "   * `h` is the spacing (same as `dx` in `bbase`):\n",
    "   ```python\n",
    "   h = (t_noisy.max() - t_noisy.min()) / ndx\n",
    "   ```\n",
    "   * `X_` is the design matrix (of degree one less than you used for finding the coefficients `beta_hat`):\n",
    "   ```python\n",
    "   X_ = bbase(t_noisy, ndx=ndx, deg=degree-1)\n",
    "   ```\n",
    "   \n",
    "   * `D1` is the first order derivative matrix given by\n",
    "   ```python\n",
    "   D1 = np.diff(np.eye(X.shape[1]), n=1, axis=0)\n",
    "   ```\n",
    "\n",
    "   Combined example:\n",
    "```python\n",
    "h = (t_noisy.max() - t_noisy.min()) / ndx\n",
    "D1 = np.diff(np.eye(X.shape[1]), n=1, axis=0)\n",
    "X_ = bbase(t_noisy, ndx=ndx, deg=degree - 1)\n",
    "derivative_smooth = (1 / h) * X_ @ (D1 @ beta_hat)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5816e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analytical_derivative(t):\n",
    "    \"\"\"Calculate the analytical derivative of the noise-free signal.\"\"\"\n",
    "    return 8 * np.cos(8 * t) - 3.6 * t + 1.5 * t**2\n",
    "\n",
    "\n",
    "derivative_noisefree = analytical_derivative(t_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f127a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = (t_noisy.max() - t_noisy.min()) / ndx\n",
    "D1 = np.diff(np.eye(X.shape[1]), n=1, axis=0)\n",
    "X_ = bbase(t_noisy, ndx=ndx, deg=degree - 1)\n",
    "derivative_smooth = (1 / h) * X_ @ (D1 @ beta_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b275d695",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(constrained_layout=True, ncols=2, figsize=(8, 4))\n",
    "axes[0].plot(t_noisy, derivative_noisefree, label=\"Analytical\", lw=3)\n",
    "axes[0].plot(\n",
    "    t_noisy,\n",
    "    derivative_smooth,\n",
    "    label=\"Numerical (spline)\",\n",
    "    linewidth=3,\n",
    "    ls=\"--\",\n",
    ")\n",
    "axes[0].set(xlabel=\"t\", ylabel=\"y'(t)\")\n",
    "axes[0].legend()\n",
    "# Plot the  noise-free vs smoothed\n",
    "axes[1].scatter(derivative_noisefree, derivative_smooth)\n",
    "rmse = root_mean_squared_error(derivative_noisefree, derivative_smooth)\n",
    "axes[1].set_title(f\"RMSE = {rmse:.3f}\")\n",
    "axes[1].set(\n",
    "    xlabel=\"Aanalytical\",\n",
    "    ylabel=\"Numerical (spline)\",\n",
    ")\n",
    "\n",
    "# Add the x=y line:\n",
    "xlim = axes[1].get_xlim()\n",
    "ylim = axes[1].get_ylim()\n",
    "\n",
    "# Calculate the range for the x=y line\n",
    "min_val = min(min(xlim), min(ylim))\n",
    "max_val = max(max(xlim), max(ylim))\n",
    "\n",
    "# Plot the x=y line within the current axes limits\n",
    "axes[1].plot([min_val, max_val], [min_val, max_val], color=\"k\", ls=\":\")\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab6e2c7",
   "metadata": {},
   "source": [
    "#### Your answer to question 7.2(c): How does the computed derivative compare to the analytical derivative?\n",
    "\n",
    "The computed derivative shows a qualitative correspondence with the analytical derivative, accurately reflecting its overall trend, including the location and nature of its local extrema.\n",
    "\n",
    "Quantitatively, the Root Mean Squared Error (RMSE) provides a measure of the average deviation, calculated to be approximately 1.9. Considering the RMSE value in the context of the analytical derivative's range (-11 to 17), this value suggests a reasonably close match and a reasonable agreement between the two derivatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c30f02",
   "metadata": {},
   "source": [
    "### 7.2(d)\n",
    "\n",
    "**Task: Smooth the signal and obtain its derivative using a Savitzky-Golay filter. Compare the smoothness and accuracy of both methods (Savitzky-Golay and B-splines) by plotting the results.**\n",
    "\n",
    "**Hint:** The Savitzky-Golay filter can be applied as follows:\n",
    "```python\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "y_smooth_sg = savgol_filter(\n",
    "    y_noisy,\n",
    "    window_length=51,  # Length of window to use for smoothing\n",
    "    polyorder=3,  #  Polynomial order to use.\n",
    ")\n",
    "\n",
    "delta_t = t_noisy[1] - t_noisy[0]\n",
    "derivative_smooth_sg = savgol_filter(\n",
    "    y_noisy,\n",
    "    delta=delta_t,  # Sample spacing, needed for the derivative.\n",
    "    window_length=101,  # Length of window to use for smoothing\n",
    "    polyorder=3,  #  Polynomial order to use.\n",
    "    deriv=1,  # Compute the first (1) derivative.\n",
    ")\n",
    "# Note: Please experiment with different window lengths and order for the polynomial.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d92f6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "\n",
    "y_smooth_sg = savgol_filter(\n",
    "    y_noisy,\n",
    "    window_length=51,  # Length of window to use for smoothing\n",
    "    polyorder=3,  #  Polynomial order to use.\n",
    ")\n",
    "\n",
    "delta_t = t_noisy[1] - t_noisy[0]\n",
    "derivative_smooth_sg = savgol_filter(\n",
    "    y_noisy,\n",
    "    delta=delta_t,  # Sample spacing, needed for the derivative.\n",
    "    window_length=101,  # Length of window to use for smoothing\n",
    "    polyorder=3,  #  Polynomial order to use.\n",
    "    deriv=1,  # Compute the first (1) derivative.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20872321",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(constrained_layout=True, ncols=2, figsize=(8, 4))\n",
    "axes[0].plot(t_noisy, y_noisy, label=\"Signal with noise\", alpha=0.25)\n",
    "axes[0].plot(t_clean, y_clean, label=\"Signal without noise\", lw=3)\n",
    "axes[0].plot(t_noisy, y_smooth, label=\"Smoothed Signal (spline)\", linewidth=2)\n",
    "axes[0].plot(\n",
    "    t_noisy,\n",
    "    y_smooth_sg,\n",
    "    label=\"Smoothed Signal (Savitzky-Golay)\",\n",
    "    linewidth=2,\n",
    "    ls=\"--\",\n",
    ")\n",
    "axes[0].set(xlabel=\"t\", ylabel=\"y(t)\")\n",
    "axes[0].legend()\n",
    "# Plot the  noise-free vs smoothed\n",
    "\n",
    "rmse_1 = root_mean_squared_error(y_clean, y_smooth)\n",
    "rmse_2 = root_mean_squared_error(y_clean, y_smooth_sg)\n",
    "\n",
    "axes[1].scatter(y_clean, y_smooth, label=f\"Spline (RMSE = {rmse_1:.3f})\")\n",
    "axes[1].scatter(\n",
    "    y_clean,\n",
    "    y_smooth_sg,\n",
    "    label=f\"Savitzky-Golay (RMSE = {rmse_2:.3f})\",\n",
    ")\n",
    "axes[1].set(xlabel=\"Signal without noise\", ylabel=\"Smoothed Signal\")\n",
    "axes[1].legend()\n",
    "# Add the x=y line:\n",
    "xlim = axes[1].get_xlim()\n",
    "ylim = axes[1].get_ylim()\n",
    "\n",
    "# Calculate the range for the x=y line\n",
    "min_val = min(min(xlim), min(ylim))\n",
    "max_val = max(max(xlim), max(ylim))\n",
    "\n",
    "# Plot the x=y line within the current axes limits\n",
    "axes[1].plot([min_val, max_val], [min_val, max_val], color=\"k\", ls=\":\")\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1fc240",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(constrained_layout=True, ncols=2, figsize=(8, 4))\n",
    "axes[0].plot(t_noisy, derivative_noisefree, label=\"Analytical\", lw=3)\n",
    "axes[0].plot(\n",
    "    t_noisy,\n",
    "    derivative_smooth,\n",
    "    label=\"Numerical (spline)\",\n",
    "    linewidth=3,\n",
    "    ls=\"--\",\n",
    ")\n",
    "axes[0].plot(\n",
    "    t_noisy,\n",
    "    derivative_smooth_sg,\n",
    "    label=\"Numerical (Savitzky-Golay)\",\n",
    ")\n",
    "axes[0].set(xlabel=\"t\", ylabel=\"y'(t)\")\n",
    "axes[0].legend()\n",
    "# Plot the  noise-free vs smoothed\n",
    "\n",
    "rmse_1 = root_mean_squared_error(derivative_noisefree, derivative_smooth)\n",
    "rmse_2 = root_mean_squared_error(derivative_noisefree, derivative_smooth_sg)\n",
    "axes[1].scatter(\n",
    "    derivative_noisefree,\n",
    "    derivative_smooth,\n",
    "    label=f\"Spline (RMSE = {rmse_1:.3f})\",\n",
    ")\n",
    "axes[1].scatter(\n",
    "    derivative_noisefree,\n",
    "    derivative_smooth_sg,\n",
    "    label=f\"Savitzky-Golay (RMSE = {rmse_2:.3f})\",\n",
    ")\n",
    "axes[1].legend()\n",
    "axes[1].set(\n",
    "    xlabel=\"Analytical\",\n",
    "    ylabel=\"Numerical\",\n",
    ")\n",
    "# Add the x=y line:\n",
    "xlim = axes[1].get_xlim()\n",
    "ylim = axes[1].get_ylim()\n",
    "\n",
    "# Calculate the range for the x=y line\n",
    "min_val = min(min(xlim), min(ylim))\n",
    "max_val = max(max(xlim), max(ylim))\n",
    "\n",
    "# Plot the x=y line within the current axes limits\n",
    "axes[1].plot([min_val, max_val], [min_val, max_val], color=\"k\", ls=\":\")\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472d3a48",
   "metadata": {},
   "source": [
    "#### Your answer to question 7.2(d): How do the results from applying the Savitzky-Golay filter compare to the B-splines results\n",
    "\n",
    "Overall, the Savitzky-Golay filter and B-spline methods produce qualitatively similar results. Both methods effectively smooth the noisy signal and yield derivatives that closely resemble the analytical derivative.\n",
    "\n",
    "Quantitatively, the root mean squared errors (RMSEs) between the smoothed and noise-free signals are also comparable, indicating similar levels of accuracy.\n",
    "\n",
    "Both methods require parameter tuning, (the `window_length` and `polyorder` for Savitzky-Golay and the smoothing factor for B-splines). The B-spline appears to better reproduce the peaks and valleys in the signal and also appears smoother."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

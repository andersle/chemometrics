{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93e2b5f9",
   "metadata": {},
   "source": [
    "# Partial least squares regression \"by hand\"\n",
    "\n",
    "Here, we will find the latent variables in partial least squares (PLS) regression by hand. As an\n",
    "example we will consider the solubility data again but in reduced form:\n",
    "\n",
    "* We will only consider alcohols\n",
    "\n",
    "* We use only logP and the number of atoms in the molecule as our X\n",
    "\n",
    "* We use the solubility and the molecular weight as our Y\n",
    "\n",
    "From the regression we did on the full data set, we know that logP is important for predicting the\n",
    "solubility, and we also expect that the molecular weight is correlated with the number of atoms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2af7e74",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "The data we will use can be found in the file [solubility_alc.csv](./solubility_alc.csv):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d24b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy.linalg import svd\n",
    "from numpy.linalg import norm\n",
    "\n",
    "\n",
    "%matplotlib notebook\n",
    "sns.set_theme(style=\"ticks\", context=\"notebook\", palette=\"muted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61976b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"solubility_alc.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0331dc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "xvars = [\"MolLogP\", \"nAtom\"]\n",
    "yvars = [\"solubility (mol/L)\", \"Molecular Weight\"]\n",
    "\n",
    "scaler_x, scaler_y = StandardScaler(), StandardScaler()\n",
    "\n",
    "Y = scaler_y.fit_transform(data[yvars].to_numpy())\n",
    "X = scaler_x.fit_transform(data[xvars].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42a6675",
   "metadata": {},
   "source": [
    "### Plotting X- and Y-data\n",
    "\n",
    "Before we start, let us first plot the X- and Y-data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb3d38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(constrained_layout=True, ncols=2, figsize=(8, 4))\n",
    "axes[0].scatter(X[:, 0], X[:, 1])\n",
    "axes[0].set(xlabel=xvars[0], ylabel=xvars[1])\n",
    "axes[0].set_title(\"X-data\", loc=\"left\")\n",
    "\n",
    "axes[1].scatter(Y[:, 0], Y[:, 1])\n",
    "axes[1].set(xlabel=yvars[0], ylabel=yvars[1])\n",
    "axes[1].set_title(\"Y-data\", loc=\"left\")\n",
    "\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a688800",
   "metadata": {},
   "source": [
    "## Finding a latent variable for PLS\n",
    "\n",
    "\n",
    "In PLS, we are looking for scores $\\mathbf{t}$ (for X) and $\\mathbf{u}$ (for y) so that the covariance\n",
    "is maximized. The main idea is that the scores should explain the variance in X, Y, and the\n",
    "covariance between X and Y.\n",
    "\n",
    "The covariance can be calculated by $\\mathbf{t}^\\top \\mathbf{u}$ (the dot product between\n",
    "the scores). Further, the scores are calculated using the *weights* $\\mathbf{w}_x$ (for X) and $\\mathbf{w}_y$ (for Y):\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{t} &= \\mathbf{X} \\mathbf{w}_x \\\\\n",
    "\\mathbf{u} &= \\mathbf{Y} \\mathbf{w}_y\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "Note that we refer to $\\mathbf{w}_x$ and $\\mathbf{w}_y$ as *weights*. In PCA, we can invert the relation\n",
    "giving the scores by multiplying with the transpose of the *loadings*.\n",
    "In PLS, this is no longer valid for the weights, and PLS introduces\n",
    "separate *loadings* to do this. For instance, the loadings $\\mathbf{p}$ for X so that we can write $\\mathbf{X} = \\mathbf{t} \\mathbf{p}^\\top$.\n",
    "\n",
    "What we will do now, is to create some $\\mathbf{w}_x$ and $\\mathbf{w}_y$ vectors by hand, and check what\n",
    "the correlation is (by calculating the correlation and by plotting the scores $\\mathbf{t}$ vs. $\\mathbf{u}$).\n",
    "Both $\\mathbf{X}$ and $\\mathbf{Y}$ have\n",
    "dimensions $n \\times 2$ (we have $n$ samples and $2$ variables). So if $\\mathbf{w}_x$ and $\\mathbf{w}_y$\n",
    "have dimensions $2 \\times 1$ (that is, they are *column* vectors), then the scores will\n",
    "have a dimension of $(n \\times 2) \\times (2 \\times 1) = n \\times 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d81cd53",
   "metadata": {},
   "source": [
    "## A short example\n",
    "\n",
    "We set set $\\mathbf{w}_x = (0.0, 1.0)^\\top$ and $\\mathbf{w}_y = (0.0, 1.0)^\\top$. Then \n",
    "the product $\\mathbf{X} \\mathbf{w}_x$ will just pick out\n",
    "the second column of $\\mathbf{X}$ (just the number of atoms) and $\\mathbf{Y} \\mathbf{w}_y$ will\n",
    "pick out the second column of $\\mathbf{Y}$ (just the molecular weight). Then a plot of\n",
    "$\\mathbf{t}$ vs. $\\mathbf{q}$ will show how the number of atoms is correlated with the\n",
    "molecular weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf6dce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot(X, Y, wx, wy):\n",
    "    \"\"\"Plot X, Y and t vs. u (calculated using wx and wy)\"\"\"\n",
    "    fig, axes = plt.subplots(constrained_layout=True, ncols=3, figsize=(9, 3), sharex=True, sharey=True)\n",
    "    axes[0].scatter(X[:, 0], X[:, 1])\n",
    "    axes[0].set(xlabel=xvars[0], ylabel=xvars[1], title='X')\n",
    "\n",
    "    axes[1].scatter(Y[:, 0], Y[:, 1])\n",
    "    axes[1].set(xlabel=yvars[0], ylabel=yvars[1], title='Y')\n",
    "\n",
    "    axes[0].quiver(0, 0, wx[0][0], wx[1][0], color='black',\n",
    "                   angles='xy', scale_units='xy', scale=0.25, width=0.015)\n",
    "    \n",
    "    axes[1].quiver(0, 0, wy[0][0], wy[1][0], color='red',\n",
    "                   angles='xy', scale_units='xy', scale=0.25, width=0.015)\n",
    "\n",
    "    \n",
    "    \n",
    "    t = X @ (wx / norm(wx)) \n",
    "    u = Y @ (wy / norm(wy))\n",
    "    # Technical detail: we norm both w and q here to get similar reults from different methods\n",
    "    \n",
    "    cov = t.T @ u\n",
    "\n",
    "    axes[2].scatter(t[:, 0], u[:, 0])\n",
    "    axes[2].set(\n",
    "        xlabel='X-scores (t)',\n",
    "        ylabel='Y-scores (u)',\n",
    "        title=f'Covariance: {cov[0][0]:.2f}')\n",
    "    sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f982c6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights by hand:\n",
    "wx = np.array([0.0, 1.0])\n",
    "wx = wx.reshape(2, -1)  # Make it a column vector\n",
    "    \n",
    "wy = np.array([1.0, 1.0])\n",
    "wy = wy.reshape(2, -1)  # Make it a column vector\n",
    "\n",
    "print(f\"wx.T = {wx.T}, shape of w: {wx.shape}\")\n",
    "print(f\"wy.T = {wy.T}, shape of q: {wy.shape}\")\n",
    "make_plot(X, Y, wx, wy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b78880d",
   "metadata": {},
   "source": [
    "In the plot above, the X-data is projected onto the black vector and this gives the X-scores (t). In the\n",
    "same way, the Y-data is projected onto the red vector and this gives the Y-scores.\n",
    "The rightmost plot show the scores plotted against each other.\n",
    "\n",
    "Here, we see that we can use the X-scores to predict the Y-scores. And we would probably make a good prediction.\n",
    "But our aim is to predict the whole $\\mathbf{Y}$! If we convert the Y-scores to $\\mathbf{Y}$, we would probably\n",
    "predict the molecular weight quite good, but fail at predicting the solubility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1027fc",
   "metadata": {},
   "source": [
    "Below, you will find the same code for creating $\\mathbf{w}$ and $\\mathbf{q}$ as above. Can you find\n",
    "two other vectors that give a larger correlation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4cd3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wx = np.array([0.0, 1.0])\n",
    "wx = wx.reshape(2, -1)  # Make it a column vector\n",
    "    \n",
    "wy = np.array([0.0, 1.0])\n",
    "wy = wy.reshape(2, -1)  # Make it a column vector\n",
    "\n",
    "make_plot(X, Y, wx, wy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33acdc76",
   "metadata": {},
   "source": [
    "## Making use of `PLSRegression` from `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1452d1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PLSRegression(scale=False, n_components=2)\n",
    "model.fit(X, Y)\n",
    "make_plot(X, Y, model.x_weights_, model.y_weights_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f0c695",
   "metadata": {},
   "source": [
    "## Calculating the loadings\n",
    "\n",
    "The covariance between $\\mathbf{t}$ and $\\mathbf{u}$ is\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{t}^\\top \\mathbf{u} = (\\mathbf{X} \\mathbf{w}_x)^\\top (\\mathbf{Y} \\mathbf{w}_y)\n",
    "= \\mathbf{w}_x^\\top \\mathbf{X}^\\top \\mathbf{Y} \\mathbf{w}_y\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "is the same as finding the\n",
    "[singular value decomposition](https://en.wikipedia.org/wiki/Singular_value_decomposition)\n",
    "of $\\mathbf{X}^\\top \\mathbf{Y}$. Let us also try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295692b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "U, _, Vt = np.linalg.svd(X.T @ Y)  # Find the singular value decomposition.\n",
    "\n",
    "wx = U[:, 0].reshape(2, -1)\n",
    "wy = Vt[0, :].reshape(2, -1)\n",
    "make_plot(X, Y, -wx, -wy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb36eb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpls(X, Y, n_components=2):\n",
    "    row_x, col_x = X.shape\n",
    "    if Y.ndim == 1:\n",
    "        Y = Y.reshape(-1, 1)\n",
    "    row_y, col_y = Y.shape\n",
    "    assert row_x == row_y\n",
    "    \n",
    "    Y0 = Y - np.mean(Y, axis=0)\n",
    "    S = X.T @ Y0\n",
    "    \n",
    "    R = np.zeros((col_x, n_components))  # Weights\n",
    "    P = np.zeros((col_x, n_components))  # Loadings\n",
    "    T = np.zeros((row_x, n_components))  # Scores\n",
    "        \n",
    "    Q = np.zeros((col_y, n_components))  # Weights\n",
    "    U = np.zeros((row_y, n_components))  # Loadings\n",
    "    V = np.zeros((col_x, n_components))  # Scores\n",
    "\n",
    "\n",
    "    for i in range(n_components):\n",
    "        left, _, _ = np.linalg.svd(S.T @ S, full_matrices=False)\n",
    "        wy = left[:, 0]#\n",
    "        wy = wy.reshape(col_y, -1)\n",
    "        r = S @ wy\n",
    "        t = X @ r\n",
    "        t = t - np.mean(t, axis=0)\n",
    "        normt = norm(t)\n",
    "        \n",
    "        t /= normt\n",
    "        r /= normt\n",
    "        \n",
    "        p = X.T @ t\n",
    "        q = Y0.T @ t\n",
    "        u = Y0 @ q\n",
    "        v = np.copy(p)\n",
    "        if i > 0:\n",
    "            v = v - V @ (V.T @ p)\n",
    "            u = u - T @ (T.T @ u)\n",
    "        v /= norm(v)\n",
    "        S = S - v @ (v.T @ S)\n",
    "        R[:, i] = r.flatten()\n",
    "        P[:, i] = p.flatten()\n",
    "        Q[:, i] = q.flatten()\n",
    "        T[:, i] = t.flatten()\n",
    "        U[:, i] = u.flatten()\n",
    "        V[:, i] = v.flatten()\n",
    "        print(p.shape, r.shape)\n",
    "    B = R @ Q.T\n",
    "    h = np.diag(T @ T.T) + 1.0 / row_x\n",
    "    varX = np.diag(P.T @ P) / (row_x - 1.0)\n",
    "    varY = np.diag(Q.T @ Q) / (row_x - 1.0)\n",
    "    return R, P, Q, T, U, V, B, h, varX, varY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4facf4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "R, P, Q, T, U, V, B, h, varX, varY = simpls(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c588b5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbaf10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wx = R[:, 0]\n",
    "wy = Q[:, 0]\n",
    "wx /= norm(wx)\n",
    "wy /= norm(wy)\n",
    "wx = wx.reshape(2, -1)\n",
    "wy = wy.reshape(2, -1)\n",
    "make_plot(X, Y, wx, wy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e100b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(B / model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c22d9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "Y_hat = X @ B\n",
    "Y_hat2 = model.predict(X)\n",
    "fig, axes = plt.subplots(constrained_layout=True, ncols=2, sharex=True, sharey=True)\n",
    "axes[0].scatter(Y[:, 0], Y_hat[:, 0], label=f'R² = {r2_score(Y[:, 0], Y_hat[:, 0]):.3f}')\n",
    "axes[0].scatter(Y[:, 1], Y_hat[:, 1], label=f'R² = {r2_score(Y[:, 1], Y_hat[:, 1]):.3f}')\n",
    "axes[0].legend()\n",
    "axes[1].scatter(Y[:, 0], Y_hat2[:, 0], label=f'R² = {r2_score(Y[:, 0], Y_hat2[:, 0]):.3f}')\n",
    "axes[1].scatter(Y[:, 1], Y_hat2[:, 1], label=f'R² = {r2_score(Y[:, 1], Y_hat2[:, 1]):.3f}')\n",
    "axes[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb37fb2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

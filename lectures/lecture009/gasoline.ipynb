{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting octane numbers from NIR spectra\n",
    "\n",
    "In this example, we will predict [octane numbers](https://en.wikipedia.org/wiki/Octane_rating) from measured NIR spectra. Specifically, we will compare a least squares model to a partial least squares (PLS) model and we will\n",
    "use cross-validation to check the performance of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the raw data\n",
    "\n",
    "The raw data can be found in the file [gasoline.csv](./gasoline.csv). We load it with pandas and\n",
    "extract the octane number, the spectra, and the wavelengths for the spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "sns.set_theme(style=\"ticks\", context=\"notebook\", palette=\"colorblind\")\n",
    "%matplotlib notebook\n",
    "\n",
    "np.random.seed(2025)  # Set random state to get the same results for each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data set:\n",
    "data = pd.read_csv(\"gasoline.csv\")\n",
    "# Each row contains a measured spectrum and a corresponding octane number:\n",
    "# 1. extract the octane numbers:\n",
    "yvars = [\"octane\"]\n",
    "octane = data[yvars].to_numpy()\n",
    "# 2. extract the spectra (intensities):\n",
    "xvars = [i for i in data.columns if i not in yvars]\n",
    "spectra = data[xvars].to_numpy()\n",
    "# 3. get the wavelengths:\n",
    "wavelengths = np.array([int(i.split()[0].split(\".\")[1]) for i in xvars])\n",
    "print(f\"Number of wavelengths measured: {len(xvars)}\")\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let us visualize the spectra, just to see what we have to work with:\n",
    "# We add some color, so we can color the spectra according to\n",
    "# the octane numbers:\n",
    "norm = mpl.colors.Normalize(vmin=octane.min(), vmax=octane.max())\n",
    "cmap = mpl.cm.ScalarMappable(norm=norm, cmap=\"coolwarm\")\n",
    "\n",
    "fig, axi = plt.subplots(constrained_layout=True)\n",
    "axi.set_title(\"NIR spectra\")\n",
    "for i, speci in enumerate(spectra):\n",
    "    axi.plot(wavelengths, speci, color=cmap.to_rgba(octane[i]))\n",
    "axi.set(xlabel=\"Wavelength (nm)\", ylabel=\"Absorbance\")\n",
    "# axi.set_facecolor(\"0.975\")\n",
    "fig.colorbar(cmap, ax=axi, label=\"Octane numbers\")\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spectra show variations in intensities related to octane number (for instance, around 1200-1220 nm where the samples with lower octane number have higher absorbances compared to samples with higher octane numbers). We proceed to explore the feasibility of constructing regression models that accurately predict octane values from these spectral data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing least squares, partial least squares, and LASSO regression with cross-validation for predicting octane numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create testing and training sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create training and test sets:\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    spectra, octane, test_size=0.33, random_state=2025\n",
    ")\n",
    "\n",
    "# To scale X:\n",
    "#scaler_x = StandardScaler().fit(X_train)\n",
    "#X_train = scaler_x.transform(X_train)\n",
    "#X_test = scaler_x.transform(X_test)\n",
    "\n",
    "# To scale y:\n",
    "scaler_y = StandardScaler().fit(Y_train)\n",
    "Y_train = scaler_y.transform(Y_train)\n",
    "Y_test = scaler_y.transform(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a least squares model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "leastsquares = LinearRegression(fit_intercept=False)\n",
    "leastsquares.fit(X_train, Y_train)\n",
    "B_MLR = leastsquares.coef_[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a partial least squares model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PLS model and use cross-validation to find\n",
    "# the best number of pls components to use:\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "parameters = {\n",
    "    \"n_components\": range(1, 11),\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    PLSRegression(scale=False),\n",
    "    parameters,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    refit=True,\n",
    ")\n",
    "\n",
    "grid.fit(X_train, Y_train)\n",
    "print(grid.best_params_)\n",
    "pls_model_optimized = grid.best_estimator_\n",
    "B_PLS = pls_model_optimized.coef_[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axi = plt.subplots(constrained_layout=True)\n",
    "score = grid.cv_results_[\"mean_test_score\"]\n",
    "score_std = grid.cv_results_[\"std_test_score\"]\n",
    "axi.errorbar(\n",
    "    parameters[\"n_components\"],\n",
    "    score,\n",
    "    yerr=score_std,\n",
    "    marker=\"o\",\n",
    ")\n",
    "axi.set_xticks(parameters[\"n_components\"])\n",
    "axi.set(\n",
    "    xlabel=\"PLS components\", ylabel=\"score\", title=\"Results from grid search\"\n",
    ")\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pls_model_optimized = PLSRegression(n_components=3).fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a LASSO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "parameters_lasso = {\"alpha\": np.logspace(-3, 2, 10)}\n",
    "\n",
    "grid_lasso = GridSearchCV(\n",
    "    Lasso(fit_intercept=False, max_iter=10000, random_state=2025),\n",
    "    parameters_lasso,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    refit=True,\n",
    ")\n",
    "grid_lasso.fit(X_train, Y_train)\n",
    "print(grid_lasso.best_params_)\n",
    "lasso_model_optimized = grid_lasso.best_estimator_\n",
    "B_lasso = lasso_model_optimized.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check performance with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    constrained_layout=True, ncols=3, sharex=True, sharey=True, figsize=(9, 3)\n",
    ")\n",
    "\n",
    "axes[0].set_title(\"Partial least squares\", loc=\"left\")\n",
    "axes[1].set_title(\"Least squares\", loc=\"left\")\n",
    "axes[2].set_title(\"Lasso\", loc=\"left\")\n",
    "\n",
    "models = [pls_model_optimized, leastsquares, lasso_model_optimized]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    cv_results = cross_validate(\n",
    "        model,\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        scoring=(\"r2\", \"neg_mean_squared_error\"),\n",
    "        return_train_score=True,\n",
    "        cv=5,\n",
    "    )\n",
    "    axes[i].plot(cv_results[\"train_r2\"], label=\"Training\", marker=\"o\")\n",
    "    axes[i].plot(cv_results[\"test_r2\"], label=\"Test\", marker=\"o\")\n",
    "    axes[i].set_xlabel(\"CV no.\")\n",
    "axes[0].set_ylabel(\"R²\")\n",
    "axes[0].legend()\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "def get_scores(y, y_hat):\n",
    "    r2 = r2_score(y, y_hat)\n",
    "    rmse = root_mean_squared_error(y, y_hat)\n",
    "    return r2, rmse\n",
    "\n",
    "\n",
    "def add_scores(model, X_train, y_train, X_test, y_test, ax):\n",
    "    \"\"\"Plot y vs y_hat for test and training.\"\"\"\n",
    "    y_hat_train = model.predict(X_train)\n",
    "    y_hat_test = model.predict(X_test)\n",
    "\n",
    "    r2_train, rmsec = get_scores(y_train, y_hat_train)\n",
    "    r2_test, rmsep = get_scores(y_test, y_hat_test)\n",
    "\n",
    "    txt_train = f\"R²(train) = {r2_train:.2f}\\nRMSEC = {rmsec:.2f}\"\n",
    "    txt_test = f\"R²(test) = {r2_test:.2f}\\nRMSEP = {rmsep:.2f}\"\n",
    "\n",
    "    ax.scatter(Y_train, y_hat_train, label=txt_train)\n",
    "    ax.scatter(Y_test, y_hat_test, label=txt_test)\n",
    "    ax.legend(fontsize=\"small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    constrained_layout=True,\n",
    "    ncols=3,\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    "    figsize=(9, 3),\n",
    ")\n",
    "\n",
    "axes[0].set_title(\"Partial least squares\", loc=\"left\")\n",
    "axes[1].set_title(\"Least squares\", loc=\"left\")\n",
    "axes[2].set_title(\"Lasso\", loc=\"left\")\n",
    "\n",
    "models = [pls_model_optimized, leastsquares, lasso_model_optimized]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    axes[i].set_aspect(\"equal\")\n",
    "    add_scores(model, X_train, Y_train, X_test, Y_test, axes[i])\n",
    "    axes[i].set_xlabel(\"y\")\n",
    "axes[0].set_ylabel(\"ŷ\")\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    constrained_layout=True,\n",
    "    nrows=3,\n",
    "    sharex=True,\n",
    "    figsize=(9,6)\n",
    ")\n",
    "\n",
    "axes[0].set_title(\"Partial least squares\", loc=\"left\")\n",
    "axes[1].set_title(\"Least squares\", loc=\"left\")\n",
    "axes[2].set_title(\"Lasso\", loc=\"left\")\n",
    "\n",
    "coeffs = [B_PLS, B_MLR, B_lasso]\n",
    "\n",
    "for i, coef in enumerate(coeffs):\n",
    "    axes[i].plot(wavelengths, coef)\n",
    "    axes[i].axhline(y=0.0, ls=\":\", color=\"k\")\n",
    "    axes[i].set_ylabel(\"Regression\\ncoefficient\")\n",
    "axes[2].set_xlabel(\"Wavelength (nm)\")\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = mpl.colors.Normalize(vmin=octane.min(), vmax=octane.max())\n",
    "cmap = mpl.cm.ScalarMappable(norm=norm, cmap=\"coolwarm\")\n",
    "fig, axi = plt.subplots(constrained_layout=True)\n",
    "axi.set_title(\"NIR spectra\")\n",
    "for i, speci in enumerate(spectra):\n",
    "    axi.plot(wavelengths, speci, color=cmap.to_rgba(octane[i]))\n",
    "\n",
    "# axi.plot(wavelengths, B_lasso)\n",
    "axi.set(xlabel=\"Wavelength (nm)\", ylabel=\"Absorbance\")\n",
    "# axi.set_facecolor(\"0.975\")\n",
    "fig.colorbar(cmap, ax=axi, label=\"Octane numbers\")\n",
    "sns.despine(fig=fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

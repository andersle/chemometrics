{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e39f9ab9",
   "metadata": {},
   "source": [
    "# Forensic discrimination of lipsticks\n",
    "\n",
    "![Illustration of method](method.png)\n",
    "\n",
    "\n",
    "The [raw data](https://doi.org/10.25917/5bee60501fdf0) contains spectroscopic measurements of red- and nude-shaded lipsticks. Here, we will make a model to identify the lipstick brand from infrared spectroscopy (ATR-FTIR). The original authors collecting the data have made similar models in their [publication](https://doi.org/10.1016/j.forsciint.2019.02.044). One motivation behind their work was to create a \"non-destructive characterisation of lipstics for forensic purposes\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c8a77b",
   "metadata": {},
   "source": [
    "# 1. Inspecting the raw data\n",
    "\n",
    "The raw data can be downloaded from the repository linked above with DOI: [10.25917/5bee60501fdf0](https://doi.org/10.25917/5bee60501fdf0). Assuming that the data has been downloaded, we will focus on the files with ATR-FTIR data. We will use:\n",
    "\n",
    "* `ATR-FTIR - Calibration.xlsx` for creating the model(s).\n",
    "* `ATR-FTIR - Validation.xlsx` for testing the model(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2f5a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "sns.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5f937d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_excel(\"ATR-FTIR - Calibration.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7451a6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fcd443",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1[\"Brand\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebd1a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1[\"Product\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ac6e64",
   "metadata": {},
   "source": [
    "For plotting, we first extract the wavenumber and then the intensities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c27026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavenumber = [\n",
    "    i for i in data1.columns if i not in (\"Sample\", \"Product\", \"Brand\")\n",
    "]\n",
    "spectra = data1[wavenumber].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743f4d15",
   "metadata": {},
   "source": [
    "Let us check how many spectra we have and how many wavenumbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b5e4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa43a1e8",
   "metadata": {},
   "source": [
    "And we plot each individual spectrum (here the color is just used to distinguish them):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636711ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = sns.color_palette(\"hls\", len(spectra))\n",
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "for i, (row, colori) in enumerate(zip(spectra, colors)):\n",
    "    ax.plot(wavenumber, row, color=colori, label=f\"Sample {i}\", lw=2)\n",
    "ax.set(xlabel=\"Wavenumber / cm$^{-1}$\", ylabel=\"Shifted intensity / a.u.\")\n",
    "sns.despine(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26493af7",
   "metadata": {},
   "source": [
    "# 2. Simplification of the data by dimensionality reduction.\n",
    "\n",
    "Before we do the analysis, we attempt to reduce the number of variables to see if we can learn \"something\" about our data. We first take care of the different intensities, by normalizing all spectra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe99c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data1[wavenumber].to_numpy()\n",
    "norms = np.linalg.norm(X, axis=1)\n",
    "\n",
    "X_normed = X / norms[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca10f30e",
   "metadata": {},
   "source": [
    "And then we use a method called PCA for reducing the number of variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7248b299",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "scores = pca.fit_transform(X_normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231ef321",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_key = \"Brand\"\n",
    "\n",
    "targets = data1[target_key].unique()\n",
    "\n",
    "colors = sns.color_palette(\"hls\", len(targets))\n",
    "color_map = {key: colors[i] for i, key in enumerate(targets)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769803d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scores(component1=0, component2=1):\n",
    "    fig, ax = plt.subplots(constrained_layout=True)\n",
    "    for target in targets:\n",
    "        xpos = scores[data1[target_key] == target, component1]\n",
    "        ypos = scores[data1[target_key] == target, component2]\n",
    "        ax.scatter(\n",
    "            xpos,\n",
    "            ypos,\n",
    "            color=color_map[target],\n",
    "            label=f\"{target}\",\n",
    "            s=90,\n",
    "        )\n",
    "    ax.legend(fontsize=\"x-small\", ncols=2)\n",
    "    var1 = pca.explained_variance_ratio_[component1]\n",
    "    var2 = pca.explained_variance_ratio_[component2]\n",
    "    ax.set(\n",
    "        xlabel=f\"Scores, component {component1+1} ({var1*100:.2f}%)\",\n",
    "        ylabel=f\"Scores, component {component2+1} ({var2*100:.2f}%)\",\n",
    "    )\n",
    "    sns.despine(fig=fig)\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "fig, _ = plot_scores(component1=0, component2=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed7a7cd",
   "metadata": {},
   "source": [
    "**Note**: We can interpret the two new axes above in terms of the original variables (the wavenumbers). This is a topic for later in the course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e891df",
   "metadata": {},
   "source": [
    "Assuming that we do not know what brand the samples in `ATR-FTIR - Validation.xlsx` are, we can make some guesses by comparing where these samples fall in the reduced dimensionality space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2983886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_excel(\"ATR-FTIR - Validation.xlsx\")\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a591ad63",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = data2[wavenumber].to_numpy()\n",
    "norms = np.linalg.norm(X_val, axis=1)\n",
    "\n",
    "X_normed_val = X_val / norms[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa869429",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = sns.color_palette(\"hls\", len(spectra))\n",
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "for row, colori in zip(spectra, colors):\n",
    "    ax.plot(wavenumber, row, color=colori)\n",
    "\n",
    "ax.plot(wavenumber, X_val[0, :], color=\"k\")\n",
    "ax.set(xlabel=\"Wavenumber / cm$^{-1}$\", ylabel=\"Intensity / a.u.\")\n",
    "sns.despine(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b87ed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_val = pca.transform(X_normed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ec7e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_scores(component1=0, component2=1)\n",
    "\n",
    "ax.scatter(\n",
    "    scores_val[:, 0],\n",
    "    scores_val[:, 1],\n",
    "    marker=\"s\",\n",
    "    facecolor=\"none\",\n",
    "    edgecolor=\"k\",\n",
    "    label=\"Unknown\",\n",
    ")\n",
    "\n",
    "ax.legend(fontsize=\"x-small\", ncols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ee0c6e",
   "metadata": {},
   "source": [
    "# 3. Classification models\n",
    "\n",
    "A classification model is a supervised model that predicts the class/type. We will create some classification models in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805cb8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3642566b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder().fit(data1[target_key])\n",
    "y = encoder.transform(data1[target_key])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45164a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_normed, y, test_size=0.2, stratify=y\n",
    ")\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6a8506",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce = PCA(n_components=10).fit(X_train)\n",
    "X_train_pca = reduce.transform(X_train)\n",
    "X_test_pca = reduce.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b360e5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "\n",
    "\n",
    "def score_model(model, X, y_true, y_pred=None):\n",
    "    if y_pred is None:\n",
    "        y_pred = model.predict(X)\n",
    "\n",
    "    score = {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"f1\": f1_score(y_true, y_pred, average=\"macro\"),\n",
    "        \"recall\": recall_score(y_true, y_pred, average=\"macro\"),\n",
    "        \"precision\": precision_score(y_true, y_pred, average=\"macro\"),\n",
    "    }\n",
    "    return score\n",
    "\n",
    "\n",
    "def add_scores(add_to, model, X, y_true):\n",
    "    name = model.__class__.__name__\n",
    "\n",
    "    scores = score_model(model, X, y_true)\n",
    "\n",
    "    for key, val in scores.items():\n",
    "        add_to[key].append(val)\n",
    "    add_to[\"model\"].append(name)\n",
    "\n",
    "\n",
    "keep_scores_test = {\n",
    "    \"model\": [],\n",
    "    \"accuracy\": [],\n",
    "    \"f1\": [],\n",
    "    \"recall\": [],\n",
    "    \"precision\": [],\n",
    "}\n",
    "\n",
    "all_models = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9251936",
   "metadata": {},
   "source": [
    "## 3.1 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d717ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "bayes = GaussianNB()\n",
    "\n",
    "bayes.fit(X_train_pca, y_train)\n",
    "\n",
    "all_models.append(bayes)\n",
    "\n",
    "add_scores(keep_scores_test, bayes, X_test_pca, y_test)\n",
    "pd.DataFrame(keep_scores_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e986ece",
   "metadata": {},
   "source": [
    "## 3.2 RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425538ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "parameters = {\"n_estimators\": [10, 50, 100], \"max_depth\": [None, 3, 6, 9, 100]}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    RandomForestClassifier(), parameters, cv=2, scoring=\"accuracy\", refit=True\n",
    ")\n",
    "\n",
    "grid.fit(X_train_pca, y_train)\n",
    "\n",
    "forest = grid.best_estimator_\n",
    "\n",
    "all_models.append(forest)\n",
    "\n",
    "\n",
    "add_scores(keep_scores_test, forest, X_test_pca, y_test)\n",
    "pd.DataFrame(keep_scores_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c049b6",
   "metadata": {},
   "source": [
    "## 3.3 Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82c0e84",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "parameters = {\"C\": [0.001, 0.1, 0.5, 1.0], \"kernel\": [\"poly\", \"rbf\"]}\n",
    "\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    SVC(probability=True), parameters, cv=2, scoring=\"accuracy\", refit=True\n",
    ")\n",
    "\n",
    "grid.fit(X_train_pca, y_train)\n",
    "\n",
    "support = grid.best_estimator_\n",
    "print(support)\n",
    "\n",
    "all_models.append(support)\n",
    "\n",
    "add_scores(keep_scores_test, support, X_test_pca, y_test)\n",
    "pd.DataFrame(keep_scores_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4628ee89",
   "metadata": {},
   "source": [
    "## 3.4 Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b02375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "cat = CatBoostClassifier(verbose=0)\n",
    "cat.fit(X_train_pca, y_train)\n",
    "\n",
    "all_models.append(cat)\n",
    "\n",
    "add_scores(keep_scores_test, cat, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7b3d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(keep_scores_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c24f852",
   "metadata": {},
   "source": [
    "## 3.5 KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e2c5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "parameters = {\n",
    "    \"n_neighbors\": range(1, 11),\n",
    "}\n",
    "\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    KNeighborsClassifier(), parameters, cv=2, scoring=\"accuracy\", refit=True\n",
    ")\n",
    "\n",
    "grid.fit(X_train_pca, y_train)\n",
    "\n",
    "knn = grid.best_estimator_\n",
    "all_models.append(knn)\n",
    "\n",
    "add_scores(keep_scores_test, knn, X_test_pca, y_test)\n",
    "pd.DataFrame(keep_scores_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1ecd93",
   "metadata": {},
   "source": [
    "# 4. Try the models on validation data\n",
    "\n",
    "We have not used the data in `ATR-FTIR - Validation.xlsx` to create the model. This means that we can use it to check how well the model is performing. So we will now check what brands our models are predicting for this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14fca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = encoder.transform(data2[\"Brand\"])\n",
    "\n",
    "X_val_pca = reduce.transform(X_normed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c7213d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_validation = {\n",
    "    \"model\": [],\n",
    "    \"accuracy\": [],\n",
    "    \"f1\": [],\n",
    "    \"recall\": [],\n",
    "    \"precision\": [],\n",
    "}\n",
    "\n",
    "\n",
    "for model in all_models:\n",
    "    y_pred = model.predict(X_val_pca)\n",
    "    add_scores(scores_validation, model, X_val_pca, y_val)\n",
    "\n",
    "results = pd.DataFrame(scores_validation)\n",
    "results.sort_values(by=\"accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

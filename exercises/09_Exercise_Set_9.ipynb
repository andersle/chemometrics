{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise set 9\n",
    "\n",
    "> * The goal of the first part of the exercise is to gain familiarity with partial least\n",
    "squares regression. For this, we will make\n",
    "a model that can predict the concentrations in a mixture from near-infrared spectra.\n",
    "> \n",
    "> * In the second part of the exercise, you will do a PCA analysis of gene expressions.\n",
    "This part is to get more experience with PCA, particularly interpreting results from PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9.1\n",
    "\n",
    "[Windig and Stephenson](https://doi.org/10.1021/ac00046a015) measured near-infrared spectra\n",
    "for 140 mixtures of the solvents methylene chloride, 2-butanol, methanol,\n",
    "dichloropropane, and acetone. Here, we will predict the compositions of the mixtures from the spectra.\n",
    "Each spectrum was sampled at 700 wavelengths\n",
    "between 1100 and 2500~nm. The file\n",
    "[`Data/windig.csv`](Data/windig.csv) contains the raw data:\n",
    "Each row in this file\n",
    "contains a spectrum (the columns starting with `wavelength.`) and the\n",
    "corresponding concentrations (the columns starting with `conc.`).\n",
    "\n",
    "The data can be loaded as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_context(\"notebook\")\n",
    "\n",
    "data = pd.read_csv(\"Data/windig.csv\")\n",
    "X = data.filter(like=\"wavelength\", axis=1).values  # NIR spectra\n",
    "Y = data.filter(like=\"conc\", axis=1).values  # Concentrations\n",
    "print(f\"No. of spectra: {X.shape[0]}\")\n",
    "print(f\"No. of wavelengths: {X.shape[1]}\")\n",
    "print(f\"No of concentration samples: {Y.shape[0]}\")\n",
    "print(f\"No of species in each sample: {Y.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot the spectra:\n",
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "for spectrum in X:\n",
    "    ax.plot(spectrum)\n",
    "ax.set(xlabel=\"Wavelength (no unit)\", ylabel=\"Absorbance\")\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1(a)\n",
    "Create a partial least squares regression (PLSR) model for predicting\n",
    "the concentrations. Use 1 PLS component for your first model and\n",
    "assess it using $R^2$, RMSEC, RMSECV and RMSEP.  An example\n",
    "of how this can be done are given below.\n",
    "\n",
    "These values (RMSEC, RMSECV, and RMSEP) are all based on calculating the\n",
    "root mean squared error (RMSE) given by,\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^N (y_i - \\hat{y}_i)^2},\n",
    "\\tag{1}\\end{equation}\n",
    "\n",
    "where $y_i$ are our measured $y$-values and $\\hat{y}_i$ are the\n",
    "values predicted by our model. The difference between RMSEC,\n",
    "RMSEP, and RMSECV lie in the part of the data we use to\n",
    "calculate them. This is based on first splitting the data into\n",
    "a *training* and *test* set, and then\n",
    "performing what we call\n",
    "[*cross-validation*](https://scikit-learn.org/stable/modules/cross_validation.html) using\n",
    "the training set:\n",
    "\n",
    "\n",
    "* When we use the training set to create our model, we are doing\n",
    "  a *calibration*. If we calculate RMSE based on using\n",
    "  the training set, we refer to this as the RMSEC (root mean squared\n",
    "  error of calibration).\n",
    "  This number\n",
    "  quantifies the error we get in connection with making (calibrating)\n",
    "  the model.\n",
    "  \n",
    "* When we use the test set to test our model, we are\n",
    "  checking how well our model *predicts* \"new\" samples\n",
    "  (that is, samples not used when making the model). If\n",
    "  we calculate RMSE based on the training set, we refer to \n",
    "  this as the RMSEP (root mean squared error of prediction). This\n",
    "  number quantifies the error we can expect to make when using\n",
    "  our model for predicting new samples.\n",
    "  \n",
    "* Cross-validation is based on further splitting the training set. Typically, we divide the\n",
    "  training set into $k$ smaller subsamples, and we repeat the fitting of the\n",
    "  model $k$ times. Each time we repeat the fitting, we retain a single\n",
    "  subsample for validation, and we fit the model using\n",
    "  the $k-1$ other subsamples. For the subsample we retained\n",
    "  for validation, we can calculate the RMSE value of how\n",
    "  well our model predicts it. Since we repeat this $k$ times,\n",
    "  we can make it so that each of the $k$ subsamples is\n",
    "  used exactly once for validation. Finally, we can\n",
    "  obtain the average RMSE of the $k$ fittings, and we\n",
    "  refer to this value as the RMSECV (root mean squared error\n",
    "  of cross-validation). This number also estimates how well the model predicts new cases, and   we also get information on how sensitive the model is to model parameters and the part of   \n",
    "  the training set used. We can also use cross-validation to optimize the parameters in the \n",
    "  model (for instance, the number of PLS components).\n",
    "\n",
    "Luckily, methods for splitting our data into training and test\n",
    "sets, calculating RMSE, and doing cross-validation are already\n",
    "available in sklearn. Note: Splitting the data into training\n",
    "and test sets and performing cross-validation involves some randomness, and your answers will probably change if you rerun\n",
    "your code.\n",
    "\n",
    "Here is a visualization of the splitting:\n",
    "![cross](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, here is how you can split into a testing and training set:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X,\n",
    "    Y,\n",
    "    test_size=0.33,  # Use 33 % of the data (one third) for the test set.\n",
    "    shuffle=True,  # Randomly shuffle the data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a PLS model:\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "model = PLSRegression(n_components=4)  # Set up a PLS model with 4 components\n",
    "model.fit(X_train, Y_train)  # Fit/make the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate scores for the model:\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "Y_hat_train = model.predict(X_train)  # Predict for the training set\n",
    "Y_hat_test = model.predict(X_test)  # Predict for the test set\n",
    "\n",
    "# Calculate R²:\n",
    "r2_train = r2_score(Y_train, Y_hat_train)\n",
    "print(f\"R² for training set: {r2_train}\")\n",
    "r2_test = r2_score(Y_test, Y_hat_test)\n",
    "print(f\"R² for test set: {r2_test}\")\n",
    "\n",
    "# Calculate RMSE:\n",
    "rmsec = mean_squared_error(Y_train, Y_hat_train, squared=False)\n",
    "print(f\"RMSEC: {rmsec}\")\n",
    "rmsep = mean_squared_error(Y_test, Y_hat_test, squared=False)\n",
    "print(f\"RMSEP: {rmsep}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for cross-validation:\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Run cross-validation:\n",
    "cvscore = cross_val_score(\n",
    "    model,  # Select the model we are going to score\n",
    "    X_train,  # Give the X-training set\n",
    "    Y_train,  # Give the y-training set\n",
    "    scoring=\"neg_mean_squared_error\",  # select scoring method\n",
    "    cv=5,  # Number of splits to make\n",
    ")\n",
    "# Note: the scoring is here \"neg_mean_squared_error\".\n",
    "# This is the negative of the MSE!\n",
    "# The cross_val_score method is often used in\n",
    "# connection with optimization where we would like to\n",
    "# maximize something, and the score can be used to pick\n",
    "# the best value. Since we usually do not want to\n",
    "# maximize the error, this method is made so that it\n",
    "# calculates the negative of the error.\n",
    "\n",
    "cvscore = np.sqrt(-cvscore)  # Account for the negative sign.\n",
    "rmsecv = cvscore.mean()\n",
    "rmsecv_std = np.std(cvscore)\n",
    "print(f\"\\nRMSECV: {rmsecv} ± {rmsecv_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 9.1(a): ($R^2$, RMSEC, RMSECV and RMSEP)\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1(b)\n",
    "Improve your PLSR model by including more\n",
    "PLS components.\n",
    "Try components from 2 up to 15 and compare the different models. How many\n",
    "PLS components are you satisfied with? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 9.1(b):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1(c)\n",
    "Plot the regression coefficients for the model you found in [9.1(b)](#9.1(b))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can get the regression coefficients with:\n",
    "B = model.coef_\n",
    "# To get the coefficients for solvent no. i, you can do:\n",
    "# B[i, :]  # this selects all rows for column i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 9.1(c):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1(d)\n",
    "Optimize the number of PLS components by a cross-validated grid search of the number of\n",
    "PLS components. Is this optimized model different from the PLS model you found in [9.1(b)](#9.1(b))?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the code for running the optimalization. This will try out\n",
    "# the number of PLS components and score the model with cross validation.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# First, we define a range of PLS components to try, let us\n",
    "# do 1, 2, ..., 20, 25, 50, 75, 100:\n",
    "parameters = {\"n_components\": list(range(1, 20)) + [25, 50, 75, 100]}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    PLSRegression(),  # the model we will make\n",
    "    parameters,  # the parameters to investigate\n",
    "    cv=5,  # number of splits for cross-validation\n",
    "    scoring=\"r2\",  # select the model with highest R²\n",
    "    refit=True,  # refit the best model for the whole training set\n",
    ")\n",
    "grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best estimator us:\n",
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is also a good idea to plot the scores to see where it levels off:\n",
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "ax.errorbar(\n",
    "    parameters[\"n_components\"],\n",
    "    grid.cv_results_[\"mean_test_score\"],\n",
    "    yerr=grid.cv_results_[\"std_test_score\"],\n",
    "    marker=\"o\",\n",
    ")\n",
    "ax.set(xlabel=\"No. of PLS components\", ylabel=\"Test score (R²)\")\n",
    "sns.despine(fig=fig)\n",
    "# Hint: It may be a good idea to zoom in on the part (1, 20) for the x-axis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 9.1(d):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1(e)\n",
    "Assume that you are given a spectrum from a mixture with unknown concentrations of the solvents. How well would your model\n",
    "predict the unknown concentrations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 9.1(e):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1(f)\n",
    "Create a least squares model for predicting the concentrations.\n",
    "Assess it using $R^2$, RMSEC, RMSECV and RMSEP. Does this model\n",
    "perform as you expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 9.1(f):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9.2\n",
    "\n",
    "[Schummer *et al.*](https://doi.org/10.1016/S0378-1119(99)00342-X) sstudied ovarian cancer by measuring gene expression values for 1536 genes in both non-cancer and cancer tissues. One of their goals was to investigate whether specific genes were overexpressed in cancer samples compared to non-cancer ones.\n",
    "This knowledge may be used for diagnosis, and we will here see if we\n",
    "can find such genes by performing a PCA. The raw data can be\n",
    "found in the file [`Data/ovo.csv`](Data/ovo.csv).\n",
    "Each row in the data file contains a tissue sample's gene expressions (for 1536 genes). Each column corresponds to a specific gene, named `X.1`, `X.2`, and so on.\n",
    "The classification of tissue as non-cancer (`N`) or cancer (`C`) can\n",
    "be found in the column `class`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load the data set.\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"Data/ovo.csv\")\n",
    "classes = data[\"class\"]  # Classification of samples.\n",
    "X = data.filter(like=\"X.\", axis=1)  # Gene expressions for samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2(a)\n",
    " \n",
    "Perform a principal component analysis (PCA) on the gene expression data\n",
    "and plot the explained variance as a function of the number of components.\n",
    "\n",
    "Center the data before performing the PCA. This can be\n",
    "done as follows with the `scale` method\n",
    "from `sklearn.preprocessing`:\n",
    "\n",
    "```python\n",
    "X = scale(X, with_std=False)\n",
    "```\n",
    "Here, all the variables are in the same units, so we do not need\n",
    "to scale the variance (we set `with_std=False`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "\n",
    "X = scale(X, with_std=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 9.2(a):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2(b)\n",
    "Inspect the data by plotting the scores and loadings for\n",
    "principal component\n",
    "number 1 and principal component number 2:\n",
    "\n",
    "\n",
    "* (i) Can you observe any clustering\n",
    "  of the samples? Here, it may be helpful to colour the samples\n",
    "  according to their classification as non-cancer or cancer.\n",
    "\n",
    "\n",
    "* (ii) Are there any outliers among the samples?\n",
    "\n",
    "\n",
    "* (iii) Can you identify some overexpressed genes in cancer tissue? \n",
    "\n",
    "\n",
    "* (iv) Can you identify some underexpressed genes in cancer tissue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 9.2(b):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2(c)\n",
    "Based on your answer in [9.2(b)](#9.2(b)), can\n",
    "you identify some pairs of genes that distinguish between\n",
    "non-cancer and cancer tissues? Support your findings by plotting the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 9.2(c):\n",
    "*Double click here*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "717bf838",
   "metadata": {},
   "source": [
    "# Exercise 11\n",
    "\n",
    "\n",
    "> In this exercise, we will have a look at penguins! We will attempt to figure out the species of penguins, based\n",
    "> on their bill length, bill depth, flipper length, and body mass.\n",
    "> The data is from a paper by \n",
    "> [Gorman, Williams, and Fraser](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0090081)\n",
    "> and can also be found in the R package [palmerpenguins](https://github.com/allisonhorst/palmerpenguins).\n",
    "> Here, we will use a version of the data set [penguins.csv](./Data/penguins.csv) where missing\n",
    "> values have been removed.\n",
    ">\n",
    "> The exercise is structured as follows:\n",
    "> * [11.1 Initial exploration (of the data set)](#11.1-Initial-exploration)\n",
    "> * [11.2 Creating a decision tree for determining the species](#11.2-Creating-a-decision-tree-for-determining-the-species)\n",
    "> * [11.3 Exploring the penguins with partial least squares discriminant analysis (PLS-DA)](#11.3-Exploring-the-penguins-with-partial-least-squares-discriminant-analysis-(PLS-DA))\n",
    ">\n",
    "> In [11.3](#11.3-Exploring-the-penguins-with-partial-least-squares-discriminant-analysis-(PLS-DA))\n",
    "> you will mostly run some code (to perform the analysis) and then interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f23d5e",
   "metadata": {},
   "source": [
    "## 11.1 Initial exploration\n",
    "\n",
    "The penguins belong to three species: [Adelie](https://en.wikipedia.org/wiki/Ad%C3%A9lie_penguin),\n",
    "[Chinstrap](https://en.wikipedia.org/wiki/Chinstrap_penguin), and [Gentoo](https://en.wikipedia.org/wiki/Gentoo_penguin), and the figure below show the three islands where these penguins can be found (click the image to make it larger): \n",
    "\n",
    "\n",
    "\n",
    "| <a href=\"./Figures/penguins.png\"><img src=\"./Figures/penguins2.png\" width=\"50%\"></a>           |\n",
    "|:-:|\n",
    "| **Fig. 1** *Location of islands and images of the penguin species.*    |\n",
    "\n",
    "In the [penguins.csv](./Data/penguins.csv) data file you will find 7 columns. Each row is a measurement for\n",
    "a single penguin for the 7 variables found in the columns:\n",
    "\n",
    "\n",
    "| Column            |  Description                                                        |\n",
    "|:------------------|--------------------------------------------------------------------:|\n",
    "| species           | The species (Adelie/Chinstrap/Gentoo)                               |\n",
    "| island            | The island where the observation was made (Dream/Torgersen/Biscoe)  |\n",
    "| bill_length_mm    | (See the illustration below) (measured in mm)                       |\n",
    "| bill_depth_mm     | (See the illustration below) (measured in mm)                       |\n",
    "| flipper_length_mm | (See the illustration below) (measured in mm)                       |\n",
    "| body_mass_g       | The weight of the penguin (in grams)                                |\n",
    "| sex               | Female/Male                                                         |\n",
    "\n",
    "\n",
    "| <img src=\"./Figures/bill.png\" width=\"50%\">                                   |\n",
    "|:-:|\n",
    "| **Fig. 2** *Illustration of bill length, bill depth, and flipper length. (The foot is not used in this data set.)*    |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1e8223",
   "metadata": {},
   "source": [
    "### 11.1(a) Loading the data\n",
    "\n",
    "First, load the data set on the penguins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d29e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"Data/penguins.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31980189",
   "metadata": {},
   "source": [
    "After loading the data set, verify the following:\n",
    "\n",
    "1. We have data from three distinct islands (Dream, Torgersen, and Biscoe).\n",
    "\n",
    "1. We have data from three different penguin species (Adelie, Chinstrap, and Gentoo).\n",
    "\n",
    "1. On the island Dream, the only species are Adelie and Chinstrap.\n",
    "\n",
    "1. On the island Torgersen, the only specie is Adelie.\n",
    "\n",
    "1. On the island of Biscoe, the only species are Adelie and Gentoo.\n",
    "\n",
    "Here are some hints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57512248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the unique elements in a column, we can do:\n",
    "print(data[\"species\"].unique())\n",
    "# Or we can do:\n",
    "print(set(data[\"species\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1597a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get more information on different islands, we can use the groupby method for pandas:\n",
    "group = data.groupby(\"species\")\n",
    "print(group.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6214648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method also works with several columns:\n",
    "group = data.groupby([\"island\", \"species\"])\n",
    "print(group.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246b560a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e8f923",
   "metadata": {},
   "source": [
    "#### Your answer to question 11.1(a):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aa200d",
   "metadata": {},
   "source": [
    "### 11.1(b) Exploring by plotting\n",
    "\n",
    "Investigate some plots to see if the variables `bill_length_mm`, `bill_depth_mm`,\n",
    "`flipper_length_mm`, and `body_mass_g` can be used to separate the different\n",
    "species. Below you will find 3 examples of plots you can create.\n",
    "\n",
    "If you were to label a penguin as Adelie, Chinstrap, or Gentoo, what \"rules\" would you\n",
    "use for this (keep it simple!) based on the 4 variables `bill_length_mm`, `bill_depth_mm`,\n",
    "`flipper_length_mm`, and `body_mass_g`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65016319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib notebook\n",
    "sns.set_theme(style=\"ticks\", context=\"notebook\", palette=\"muted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7b68b5",
   "metadata": {},
   "source": [
    "#### Example plot 1\n",
    "\n",
    "One way to get an overview is to use the scatter plot matrix, and color the\n",
    "data points according to the species:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86acd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first create a scatter plot matrix with seaborn - here, the parameter \"hue\" is used to\n",
    "# select \"groups\" in the data. You can explore how the data looks if\n",
    "# you select \"island\" or \"sex\" as the hue:\n",
    "grid = sns.pairplot(\n",
    "    data,\n",
    "    corner=True,\n",
    "    hue=\"species\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f22d8c",
   "metadata": {},
   "source": [
    "#### Example plot 2 - plotting grouped data\n",
    "Here, we will plot the grouped data for each variable. If we use the\n",
    "[groupby](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html) method\n",
    "for data frames in pandas, we can automagically plot things according to the\n",
    "groups that were created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4a1b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group input species and island and plot for one variable, the \"bill_depth_mm\"\n",
    "datag = data.groupby([\"species\", \"island\",])\n",
    "datag[\"bill_depth_mm\"].plot(kind=\"kde\", figure=plt.figure(), legend=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e9b259",
   "metadata": {},
   "source": [
    "Here is a more complex version of the same plot. Essentially, we are here just taking care\n",
    "to move the legend out of the plot and to remove the first `None, None` line from the legend (this line\n",
    "is just there due to the structure of what we get back from groupby and is not plotted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498ef298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec  # For more control of the axes in a figure.\n",
    "\n",
    "\n",
    "def plot_variable_group(vari, datag):\n",
    "    \"\"\"Plot distribution for the selected variable vari for grouped data datag.\"\"\"\n",
    "    fig = plt.figure(constrained_layout=True, figsize=(8, 5))  # Create empty figure\n",
    "    grid = GridSpec(ncols=1, nrows=4, figure=fig)  # Create a grid for the axes.\n",
    "    # This grid is created here so we can manually relocate the legend to the top:\n",
    "    # 1. create axes for putting the legend into:\n",
    "    ax_top = fig.add_subplot(grid[0, 0])\n",
    "    ax_top.axis(\"off\")  # Turn off the lines\n",
    "    # 2. Create axes for the actual plot:\n",
    "    ax = fig.add_subplot(grid[1:, :])\n",
    "    ax.set_xlabel(vari)  # Add the variable name to the x-axis:\n",
    "    # 3. Plot the grouped data for the selected variable:\n",
    "    datag[vari].plot(kind=\"kde\", ax=ax, legend=True, lw=3)\n",
    "    # 4. Move the legend to the top (to get it out of the way):\n",
    "    handles, labels = ax.get_legend_handles_labels()  # Copy legend\n",
    "    ax_top.legend(handles, labels, ncol=3)  # Place legend in the top axis\n",
    "    ax.get_legend().remove()  # Remove legend from original axis\n",
    "    sns.despine(fig=fig)  # Update seaborn style to remove spines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df016e11",
   "metadata": {},
   "source": [
    "The method above can be used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380080b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "datag = data.groupby([\"species\", \"island\",]) \n",
    "# Note, you can also select \"sex\" here to include this group as well, or remove \"island\" to make\n",
    "# the plot easier to read.\n",
    "plot_variable_group(\"bill_depth_mm\", datag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb87ec95",
   "metadata": {},
   "source": [
    "#### Example 3 - plotting data for a specific island\n",
    "Here is another example where we group data, but first, we select a specific island:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af06622",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dream = data[data[\"island\"] == \"Dream\"]  # Select one island\n",
    "datag = data_dream.groupby([\"species\", \"sex\"])  # Group data for plotting:\n",
    "datag[\"bill_depth_mm\"].plot(kind=\"kde\", figure=plt.figure(), legend=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550f1a33",
   "metadata": {},
   "source": [
    "Here is a more complex version of the same plot, where we plot all four variables\n",
    "next to each other for a single island:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f8726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we will also create a method that will plot penguin data\n",
    "# for a specific island.\n",
    "\n",
    "\n",
    "def plot_island_data(data, island):\n",
    "    \"\"\"Plot distributions for all variables for a selected island.\"\"\"\n",
    "    xvars = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\n",
    "\n",
    "    datai = data[data[\"island\"] == island]  # Select island\n",
    "    datag = datai.groupby([\"species\", \"sex\"])  # Group the data for plotting\n",
    "\n",
    "    # Set up empty figure:\n",
    "    fig = plt.figure(constrained_layout=True, figsize=(9, 3))\n",
    "    fig.suptitle(f\"Island: {island}\")\n",
    "    grid = GridSpec(ncols=len(xvars), nrows=2, figure=fig)\n",
    "    # Create 4 axes (on for each variable):\n",
    "    axes = [fig.add_subplot(grid[0, i]) for i in range(len(xvars))]\n",
    "    # Create one axis (below the 4 axes just created) to hold a legend\n",
    "    axes_bottom = fig.add_subplot(grid[1, :])\n",
    "    axes_bottom.axis(\"off\")  # Turn off lines etc. for the bottom axis.\n",
    "\n",
    "    # Plot the 4 variables\n",
    "    for i, (vari, ax) in enumerate(zip(xvars, axes)):\n",
    "        datag[vari].plot(\n",
    "            kind=\"kde\",\n",
    "            ax=ax,\n",
    "            legend=(i == 0),  # Just put a legend for the first one\n",
    "            lw=3,\n",
    "        )\n",
    "        ax.set_xlabel(vari)\n",
    "        if i == 0:  # Steal the legend from the axis and move it to the bottom\n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "            axes_bottom.legend(handles, labels, ncol=4)\n",
    "            ax.get_legend().remove()\n",
    "        else:\n",
    "            # The y-label is the same for all plots, so only keep it for the first plot:\n",
    "            ax.set_ylabel(\"\")  # Remove y-label\n",
    "    sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63417bf8",
   "metadata": {},
   "source": [
    "This method can be used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c899123a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_island_data(data, \"Dream\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d521e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20845cb",
   "metadata": {},
   "source": [
    "#### Your answer to question 11.1(b):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3d2441",
   "metadata": {},
   "source": [
    "## 11.2 Creating a decision tree for determining the species"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7d8430",
   "metadata": {},
   "source": [
    "### 11.2(a) Coding the species\n",
    "\n",
    "We have three species, and the data we have is categorical. To use the specie in\n",
    "numerical methods, we will need to represent it with numbers. For decision trees,\n",
    "we can simply use the numbers 0, 1, and 2 to represent the three species (we are not\n",
    "doing any math with these numbers and they only have a meaning as labels for the decision tree).\n",
    "\n",
    "Generating numbers for categorical data is a common task and sklearn has a built-in method for\n",
    "that called [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html). This one can be used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b20920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create some categorical data:\n",
    "raw_data = [\"bears\", \"beets\", \"battlestar galactica\", \"bears\", \"bears\", \"beets\"]\n",
    "# Create the encoder and fit it to the data:\n",
    "encoder = LabelEncoder().fit(raw_data)\n",
    "# Show the classes the encoder found:\n",
    "print(\"Classes are:\", encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3302fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the encoder to transform the raw data to numbers:\n",
    "y = encoder.transform(raw_data)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02511414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also convert back:\n",
    "labels = encoder.inverse_transform(y)\n",
    "print(labels)\n",
    "# Check that we got the same as we started with:\n",
    "print([i == j for i, j in zip(raw_data, labels)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386fce47",
   "metadata": {},
   "source": [
    "Create a new encoder for the species and transform the species in the data to numerical y-values.\n",
    "You will use these y-values in the following to create the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83d2175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028c664d",
   "metadata": {},
   "source": [
    "#### Your answer to question 11.2(a):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ed7640",
   "metadata": {},
   "source": [
    "### 11.2(b) Creating the decision tree\n",
    "\n",
    "Create a decision tree for determining the species. Use the numerical y-values you just created\n",
    "for your y, and use `bill_length_mm`, `bill_depth_mm`,\n",
    "`flipper_length_mm`, and `body_mass_g` as your X-variables. Keep the tree as simple as possible so\n",
    "that it is easy to interpret it.\n",
    "\n",
    "After you have created the decision tree, show the **confusion matrix** and calculate\n",
    "the **precision** and **recall**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93869af1",
   "metadata": {},
   "source": [
    "**Note!** We have here 3 species. This means that we have to define how we should calculate these metrics.\n",
    "Let us take the recall as an example. For binary classification where we only have two classes it is:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{recall} = \\frac{TP}{TP + FN}\n",
    "\\end{equation}\n",
    "\n",
    "where $TP$ is the number of true positives and $FN$ is the number of false negatives. If we have 3 classes\n",
    "we will get $TP$ (or $FN$) for class 0, 1, and 2. We will here consider two possibilities (there are more!) for\n",
    "the averaging into one recall score:\n",
    "\n",
    "* macro-averaging: This will calculate the metric (for instance, the recall) for each class\n",
    "  independently and it will then take the average (all classes are treated equally):\n",
    "  \n",
    "  \\begin{equation}\n",
    "  \\text{recall}_0 = \\frac{TP_0}{TP_0 + FN_0}, \\quad \\text{recall}_1 = \\frac{TP_1}{TP_1 + FN_1},\n",
    "  \\quad \\text{recall}_2 = \\frac{TP_2}{TP_2 + FN_2}.\n",
    "  \\end{equation}\n",
    "  \n",
    "  Here $TP_i$ means correct classifications for class $i$ and $FN_i$ means mistakes for class $i$.\n",
    "  \n",
    "  \\begin{equation}\n",
    "  \\text{recall}_\\text{macro} = \\frac{\\text{recall}_0 + \\text{recall}_1 + \\text{recall}_2}{3}\n",
    "  \\end{equation}\n",
    "  \n",
    "\n",
    "\n",
    "* micro-averaging: This will aggregate contributions of all classes and use this to\n",
    "  calculate the average:\n",
    "  \n",
    "  \\begin{equation}\n",
    "  \\text{recall}_\\text{micro} = \\frac{TP_0 + TP_1 + TP_2}{TP_0 + TP_1 + TP_2 + FN_0 + FN_1 + FN_2}\n",
    "  \\end{equation}\n",
    "  \n",
    "\n",
    "Since the macro-averaging is treating all classes equally, it will not deal well with cases\n",
    "where we have a class imbalance (for instance, if we have few items of one class compared to the others). In\n",
    "such cases, micro-averaging is preferred.\n",
    "\n",
    "Here is a short example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d5f5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "y_true = [0, 0, 1, 1, 2, 2, 2, 2]\n",
    "y_pred = [0, 1, 1, 2, 1, 1, 0, 2]\n",
    "macro = recall_score(y_true, y_pred, average=\"macro\")\n",
    "micro = recall_score(y_true, y_pred, average=\"micro\")\n",
    "print(f\"recall(macro) = {macro}\")\n",
    "print(f\"recall(micro) = {micro}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a049995f",
   "metadata": {},
   "source": [
    "For completeness, let us do this by hand as well:\n",
    "\n",
    "| Class | True positives (correct) | False negatives (mistakes) |\n",
    "|:-:|:-:|:-:|\n",
    "| 0 | 1 | 1 |\n",
    "| 1 | 1 | 1 |\n",
    "| 2 | 1 | 3 |\n",
    "\n",
    "* macro-averaging:\n",
    "  \n",
    "  \\begin{equation}\n",
    "  \\text{recall}_0 = \\frac{TP_0}{TP_0 + FN_0} = \\frac{1}{1+1}=0.5, \\quad \\text{recall}_1 = \\frac{TP_1}{TP_1 + FN_1} =   \\frac{1}{1+1}=0.5,\n",
    "  \\quad \\text{recall}_2 = \\frac{TP_2}{TP_2 + FN_2} = \\frac{1}{1+3}=0.25.\n",
    "  \\end{equation}\n",
    "\n",
    "  \\begin{equation}\n",
    "  \\text{recall}_\\text{macro} = \\frac{0.5 + 0.5 + 0.25}{3} = \\frac{5}{12} = 0.41666\\ldots\n",
    "  \\end{equation}\n",
    " \n",
    "* micro-averaging: \n",
    " \n",
    "  \\begin{equation}\n",
    "  \\text{recall}_\\text{micro} = \\frac{TP_0 + TP_1 + TP_2}{TP_0 + TP_1 + TP_2 + FN_0 + FN_1 + FN_2}\n",
    "  = \\frac{1 + 1 + 1}{1 + 1 + 1 + 1+ 1+3} = \\frac{3}{8} = 0.375\n",
    "  \\end{equation}\n",
    "  \n",
    "\n",
    "Motivated by the fact that we do not have an equal number of samples for the different species, I\n",
    "suggest using micro-averaging in the following. If you use\n",
    "[GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "for finding the optimum depth of your tree, this can be done by setting `scoring=\"recall_micro\"` in\n",
    "`GridSearchCV`. Here is a short example you can adapt to make your decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad68d196",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Just generate some synthetic classification data for this example:\n",
    "X, y = make_classification(\n",
    "    n_samples=1000, n_classes=3, n_clusters_per_class=1, n_features=2, n_redundant=0\n",
    ")\n",
    "X = scale(X)\n",
    "\n",
    "# Create test/training sets:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "# Set up a grid search:\n",
    "parameters = {\"max_depth\": range(1, 5)}\n",
    "grid = GridSearchCV(\n",
    "    DecisionTreeClassifier(),\n",
    "    parameters,\n",
    "    scoring=\"recall_micro\",\n",
    ")\n",
    "\n",
    "# Run the grid search:\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Get the best classifier from the grid search:\n",
    "best_tree = grid.best_estimator_\n",
    "print(\"Best tree:\", best_tree)\n",
    "\n",
    "# Use the best classifier for the test set:\n",
    "y_pred = best_tree.predict(X_test)\n",
    "\n",
    "# Calculate the precision etc. for the test set:\n",
    "precision = precision_score(y_test, y_pred, average=\"micro\")\n",
    "recall = recall_score(y_test, y_pred, average=\"micro\")\n",
    "print(f\"precision = {precision}\")\n",
    "print(f\"recall = {recall}\")\n",
    "\n",
    "\n",
    "# Make confusion matrix:\n",
    "fig, ax = plt.subplots(constrained_layout=True, figsize=(4, 4))\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    best_tree,\n",
    "    X,\n",
    "    y,\n",
    "    display_labels=[\"Class 0\", \"Class 1\", \"Class 2\"],\n",
    "    ax=ax,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076dfdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62461845",
   "metadata": {},
   "source": [
    "#### Your answer to question 11.1(b):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb58396",
   "metadata": {},
   "source": [
    "### 11.2(c) Micro-averaged precision vs. recall\n",
    "You may have noted that the precision and recall seems to give the same value when we use micro-averaging.\n",
    "Can you explain this from the definitions of the micro-averaged precision and recall,\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{recall}_\\text{micro} = \\frac{\\sum_{i} TP_i}{\\sum_{i} TP_i + \\sum_{i} FN_i}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{precision}_\\text{micro} = \\frac{\\sum_{i} TP_i}{\\sum_{i} TP_i + \\sum_{i} FP_i}\n",
    "\\end{equation}\n",
    "\n",
    "where the sum runs over all classes.\n",
    "\n",
    "Hint: Give an argument for the two sums $\\sum_{i} FN_i$ and $\\sum_{i} FP_i$ being equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa110230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef7b3dc",
   "metadata": {},
   "source": [
    "#### Your answer to question 11.2(c):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b05c86",
   "metadata": {},
   "source": [
    "### 11.2(d) Visualize your decision tree\n",
    "\n",
    "Visualize your decision tree and compare it with your answer to [11.1(b)](#11.1(b)-Exploring-by-plotting). Are the rules found\n",
    "by the decision tree (this is easier to compare if you did not go all-out on the depth of your decision tree) similar to your rules?\n",
    "\n",
    "Here is an example of how you can visualize a decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64727ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "from IPython.display import SVG\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "dot_data = export_graphviz(\n",
    "    best_tree,\n",
    "    out_file=None,\n",
    "    feature_names=[\"Variable 1\", \"Variable 2\"],\n",
    "    class_names=[\"Class 0\", \"Class 1\", \"Class 2\"],\n",
    "    rounded=True,\n",
    "    filled=True,\n",
    ")\n",
    "graph = graphviz.Source(dot_data)\n",
    "SVG(graph.pipe(format=\"svg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765e5985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d8deb7",
   "metadata": {},
   "source": [
    "#### Your answer to question 11.2(d):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7af690",
   "metadata": {},
   "source": [
    "## 11.3 Exploring the penguins with partial least squares discriminant analysis (PLS-DA)\n",
    "\n",
    "Partial least squares discriminant analysis is essentially PLS for categorical y-variables. Since it is working\n",
    "with categorical variables, we can use it in the context of classification. For the most part,\n",
    "[11.3](#11.3-Exploring-the-penguins-with-partial-least-squares-discriminant-analysis-(PLS-DA)) is only asking you to run some code and observe the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7526592",
   "metadata": {},
   "source": [
    "### 11.3(a) Converting categorical data to numerical values\n",
    "\n",
    "First, we will convert the categorical data in the original data set to numerical values. We have to be\n",
    "a bit careful here and keep in mind that these numerical values will be used for calculations by PLS. We will,\n",
    "therefore, encode them so that the numbers only have meaning in terms of a variable being \"on\" or \"off\".\n",
    "\n",
    "Since this is also a common strategy to deal with categorical data, there is a method in pandas to do just this\n",
    "and this method is called [get_dummies](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec88660",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dum = pd.get_dummies(data)\n",
    "data_dum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb762008",
   "metadata": {},
   "source": [
    "As you can see from the table above, we have now effectively created one variable per category for the categorical\n",
    "variables.\n",
    "\n",
    "For instance, for \"sex\" we now have \"sex_female\" and \"sex_male\" to distinguish between female and\n",
    "male penguins. You will also note that these two new variables are perfectly correlated:\n",
    "If one of them is 1, then the other has to be 0! This means that we have introduced a lot of correlations in our\n",
    "new data set. If we were doing least squares regression, we would have kept only one of the two variables. This can\n",
    "be automatically done by `data_dum = pd.get_dummies(data, drop_first=True)`.\n",
    "\n",
    "PLS is not afraid of correlations, so we will in the following keep all variables!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c620c7",
   "metadata": {},
   "source": [
    "### 11.3(b) Creating a PLS model and inspecting loadings\n",
    "\n",
    "We will now create the PLS model. Here, we do not attempt to find the best number of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63de1cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "data_dum = pd.get_dummies(data)\n",
    "\n",
    "xvars = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\n",
    "yvars = [i for i in data_dum.columns if i not in xvars]\n",
    "\n",
    "X = scale(data_dum[xvars].to_numpy())\n",
    "Y = data_dum[yvars].to_numpy()\n",
    "pls = PLSRegression(n_components=4, scale=False)\n",
    "pls.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7faa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loadings_plot(pls_model, xvars, yvars, idx1=0, idx2=1, factor=2.5):\n",
    "    \"\"\"Plot the X and Y loadings for a PLS model.\"\"\"\n",
    "    fig, ax = plt.subplots(constrained_layout=True, figsize=(6, 6))\n",
    "\n",
    "    loadingsx = pls_model.x_rotations_\n",
    "    loadingsy = pls_model.y_loadings_\n",
    "\n",
    "    scat = ax.scatter(loadingsx[:, idx1], loadingsx[:, idx2])\n",
    "    for i, xi in enumerate(xvars):\n",
    "        ax.text(loadingsx[i, idx1], loadingsx[i, idx2], xi)\n",
    "\n",
    "    for i, yvar in enumerate(yvars):\n",
    "        ax.plot(\n",
    "            [0, factor * loadingsy[i, idx1]],\n",
    "            [0, factor * loadingsy[i, idx2]],\n",
    "            color=\"red\",\n",
    "        )\n",
    "        text = yvar.split(\"_\")[1]\n",
    "        ax.text(\n",
    "            factor * loadingsy[i, idx1],\n",
    "            factor * loadingsy[i, idx2],\n",
    "            text,\n",
    "            color=\"red\",\n",
    "            va=\"bottom\" if loadingsy[i, idx2] > 0 else \"top\",\n",
    "            ha=\"center\",\n",
    "        )\n",
    "    ax.axhline(y=0, color=\"k\", ls=\":\")\n",
    "    ax.axvline(x=0, color=\"k\", ls=\":\")\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_xlim(-1, 1)\n",
    "    ax.set_ylim(-1, 1)\n",
    "    ax.set(xlabel=f\"PLS component {idx1+1}\", ylabel=f\"PLS component {idx2+1}\")\n",
    "    ax.set_title(\"Loadings\", loc=\"left\")\n",
    "    sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b296a8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_loadings_plot(pls, xvars, yvars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbb58cb",
   "metadata": {},
   "source": [
    "Run the code above and consider the following:\n",
    "\n",
    "1. On the island of Biscoe, what specie do you expect to find the most of? Is there\n",
    "   a specie you do not expect to find on Biscoe?\n",
    "\n",
    "\n",
    "2. What features distinguish most between female and male penguins?\n",
    "\n",
    "\n",
    "3. Do you agree with the following statement (why/why not): \"Gentoo penguins are heavier than the\n",
    "   other penguin species\".\n",
    "   \n",
    "\n",
    "4. Do you agree with the following statement (why/why not): \"Gentoo penguins have a larger flipper length and\n",
    "   smaller bill depth than the other penguins\".\n",
    "   \n",
    "\n",
    "5. Do you agree with the following statement (why/why not): \"The bill length distinguish Adelie\n",
    "   penguins from the other species."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65c5e01",
   "metadata": {},
   "source": [
    "#### Your answer to question 11.3(b):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6af8cd",
   "metadata": {},
   "source": [
    "## 11.3(c) Predicting the sex of penguins\n",
    "\n",
    "In the [original article](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0090081),\n",
    "the authors created several models to predict the sex of different penguin species. Here is an image with their\n",
    "results:\n",
    "\n",
    "\n",
    "| <img src=\"./Figures/penguintable.png\" width=\"100%\">                                   |\n",
    "|:-:|\n",
    "| **Fig. 3** *Regression models for predicting the sex of penguins.*    |\n",
    "\n",
    "**Note:** In Fig. 3 above, the word `Culmen` is used in place of `bill` (i.e., `culmen length` = `bill length`).\n",
    "\n",
    "We will now repeat this with \n",
    "PLS, and we use only the `sex_female` and `sex_male` variables as our Y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd922223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models, one per penguin specie:\n",
    "models = {}\n",
    "yvars_ = [\"sex_female\", \"sex_male\"]\n",
    "xvars = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\n",
    "\n",
    "for specie in data[\"species\"].unique():\n",
    "    data_species = data[data[\"species\"] == specie]\n",
    "    data_dum = pd.get_dummies(data_species)\n",
    "\n",
    "    X = scale(data_dum[xvars].to_numpy())\n",
    "    Y = data_dum[yvars_].to_numpy()\n",
    "    pls_model = PLSRegression(n_components=4, scale=False)\n",
    "    pls_model.fit(X, Y)\n",
    "    models[specie] = pls_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464d835b",
   "metadata": {},
   "source": [
    "### 11.3(c)-1 Regression coefficients and loadings for Adelie penguins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93823fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# First, we create a method for showing regression coefficients:\n",
    "def show_regression_coeffs(pls_model, xvars, yvars):\n",
    "    fig, ax = plt.subplots(constrained_layout=True, figsize=(8, 5))\n",
    "    fig.suptitle(\"Regression coefficients\")\n",
    "    pos = np.arange(len(xvars))\n",
    "\n",
    "    ax.axhline(y=0, ls=\":\", color=\"k\")\n",
    "    width2 = 0.8\n",
    "    width = width2 / 2\n",
    "\n",
    "    B_PLS = pls_model.coef_\n",
    "\n",
    "    r1 = ax.bar(pos - 0.25, B_PLS[:, 0], width=width, label=\"Female\")\n",
    "    r2 = ax.bar(pos + 0.25, B_PLS[:, 1], width=width, label=\"Male\")\n",
    "\n",
    "    for i in pos:\n",
    "        ax.axvline(x=i + 0.5, ls=\":\", color=\"k\")\n",
    "\n",
    "    ax.set_xticks(pos)\n",
    "    ax.set_xticklabels(xvars, rotation=90)\n",
    "    ax.legend()\n",
    "    sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0a0398",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_regression_coeffs(models[\"Adelie\"], xvars, yvars_)\n",
    "create_loadings_plot(models[\"Adelie\"], xvars, yvars_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59cb4fc",
   "metadata": {},
   "source": [
    "If you have a look at the [image given above](#11.3(c)-Predicting-the-sex-of-penguins) from the original article, you see that the performance of the three models for the Adelie penguins are equal (the same percentage of correct classifications are made). Can you explain this using the plots above (i.e., why do the models not change when the authors introduce more variables)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daaa941",
   "metadata": {},
   "source": [
    "#### Your answer to question 11.3(c)-1:\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b255972",
   "metadata": {},
   "source": [
    "### 11.3(c)-2 Regression coefficients and loadings for Chinstrap penguins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7860448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_regression_coeffs(models[\"Chinstrap\"], xvars, yvars_)\n",
    "create_loadings_plot(models[\"Chinstrap\"], xvars, yvars_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9855bb",
   "metadata": {},
   "source": [
    "For the model for Chinstrap penguins, the authors used only the bill length and bill depth (see the [image given above](#11.3(c)-Predicting-the-sex-of-penguins)). Do you think the model would improve if you also include the body mass?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c5d3bd",
   "metadata": {},
   "source": [
    "#### Your answer to question 11.3(c)-2:\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd5bb81",
   "metadata": {},
   "source": [
    "### 11.3(c)-3 Regression coefficients and loadings for Gentoo penguins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42d6547",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_regression_coeffs(models[\"Gentoo\"], xvars, yvars_)\n",
    "create_loadings_plot(models[\"Gentoo\"], xvars, yvars_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5503d21d",
   "metadata": {},
   "source": [
    "For their model for Gentoo penguins, the authors (see the [image given above](#11.3(c)-Predicting-the-sex-of-penguins)) included the bill length (and excluded the flipper length). Do you think the bill length is\n",
    "needed in the model of Gentoo penguins?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5894d9bd",
   "metadata": {},
   "source": [
    "#### Your answer to question 11.3(c)-3:\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6842f379",
   "metadata": {},
   "source": [
    "## 11.4 Building a logistic regression model for Gentoo penguins\n",
    "\n",
    "As a follow-up of [11.3(c)-3](#11.3(c)-3-Regression-coefficients-and-loadings-for-Gentoo-penguins),\n",
    "let us build the\n",
    "same type of\n",
    "[models as the original authors](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0090081#s2),\n",
    "and compare the effect of including the bill length or not. In the original article,\n",
    "the authors used [Logistic regression]() which essentially is least squares + \"something\" \n",
    "that squashes the straight least squares line into binary results (0 or 1, so that we can use the results\n",
    "for classification). Usually, that \"something\" is a sigmoid function\n",
    "(an \"S\" shaped function).\n",
    "\n",
    "\n",
    "Since the authors report the \"% correctly classified\"\n",
    "(see the [image given above](#11.3(c)-Predicting-the-sex-of-penguins))\n",
    "we will here use the accuracy (for a test set) as our metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6517d128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "xvars1 = [\"bill_length_mm\", \"bill_depth_mm\", \"body_mass_g\"]\n",
    "xvars2 = [\"bill_depth_mm\", \"body_mass_g\"]\n",
    "\n",
    "data_gentoo = data[data[\"species\"] == \"Gentoo\"]\n",
    "\n",
    "X1 = scale(data_gentoo[xvars1])\n",
    "X2 = scale(data_gentoo[xvars2])\n",
    "\n",
    "y = LabelEncoder().fit_transform(data_gentoo[\"sex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a62180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def make_model(X_data, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y, stratify=y)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3763e9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just repeat making the model 10 times:\n",
    "scores1 = [make_model(X1, y) for _ in range(10)]\n",
    "print(f\"Model 1 (X = {xvars1})\")\n",
    "print(f\"\\tAccuracy: {np.mean(scores1):.3g} ± {np.std(scores1):.2g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da511374",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2 = [make_model(X2, y) for _ in range(10)]\n",
    "print(f\"Model 2 (X = {xvars2})\")\n",
    "print(f\"\\tAccuracy: {np.mean(scores2):.3g} ± {np.std(scores2):.2g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52421112",
   "metadata": {},
   "source": [
    "Based on the results above, would you say that there is a big effect of including the bill length in the\n",
    "model for Gentoo penguins?\n",
    "Is this in agreement with your answer to [11.3(c)-3](#Your-answer-to-question-11.3(c)-3:)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ee7993",
   "metadata": {},
   "source": [
    "#### Your answer to question 11.4:\n",
    "*Double click here*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

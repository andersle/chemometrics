{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6f9b7a0",
   "metadata": {},
   "source": [
    "# Initial exploration and removing a \"NaN\" (+ doing some variable selection)\n",
    "\n",
    "This notebook demonstrates two explorative plots:\n",
    "\n",
    "1. The [scatter plot matrix](https://www.itl.nist.gov/div898/handbook/eda/section3/scatplma.htm)\n",
    "   (see also page 235 in our textbook).\n",
    "   \n",
    "2. The correlation heatmap. This will show correlation coefficients calculated between pairs of variables\n",
    "   in a colorful plot. We can choose the type of correlation coefficient - one typical choice is\n",
    "   the [Pearson correlation coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient).\n",
    "   \n",
    "As an example, we will use data for 21 individuals with high blood pressure. The variables are (see table 1):\n",
    "\n",
    "| Column  | Description                                                                 |             Unit |\n",
    "|:--------|:----------------------------------------------------------------------------|-----------------:|\n",
    "| BP      | Blood pressure                                                              |             mmHg |\n",
    "| Age     | Age                                                                         |            years |\n",
    "| Weight  | Weight                                                                      |               kg |\n",
    "| BSA     | Body surface area                                                           |               m² |\n",
    "| DUR     | Duration of hypertension                                                    |            years |\n",
    "| Pulse   | Basal heart rate                                                            | beats per minute |\n",
    "| Stress  | Stress index                                                                |              --- |\n",
    "| random1 | Some random numbers                                                         |              --- |\n",
    "| tide    | Forecasted water levels at high tide the next 20 days in Trondheim          |              m   |\n",
    "||**Table 1:** *Data columns present in the file [bloodpress.csv](bloodpress.csv)*|\n",
    "\n",
    "We will also see what we can do if we are missing one value\n",
    "(say, that we did some mistake when measuring a variable)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6febfd46",
   "metadata": {},
   "source": [
    "## Loading the data and fixing the missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58c9c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"ticks\", context=\"notebook\", palette=\"muted\")\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca0ddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"bloodpress.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ac7d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the data:\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd6754c",
   "metadata": {},
   "source": [
    "We see here that we have 21 observations for all columns, except for the weight. If we look closer at the data table\n",
    "above, we can see that this column contains a [Not a number (NaN)](https://en.wikipedia.org/wiki/NaN).\n",
    "Can ask pandas if this is the case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77e7555",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Do we have a NaN?\", data.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d29895",
   "metadata": {},
   "source": [
    "We do have a NaN in our data. Now, we have to decide what we should do with that. Two common \"solutions\" are:\n",
    "\n",
    "1. Remove this observation (the whole row).\n",
    "2. Remove the affected variable (weight).\n",
    "\n",
    "Usually, we prefer option 1 since the variable might be important and we would like to keep it!\n",
    "We can tell pandas to remove the rows with NaN's using [dropna](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html).\n",
    "By default, this will remove the affected rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2596c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bdb543",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7b28e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Do we have a NaN?\", data.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f95487",
   "metadata": {},
   "source": [
    "## Exploring correlations between pairs of variables - Scatter Plot Matrix\n",
    "Before we do any modeling, we should check if some variables are correlated. To do this,\n",
    "we will create a [Scatter Plot Matrix](https://www.itl.nist.gov/div898/handbook/eda/section3/scatplma.htm) using [seaborn](https://seaborn.pydata.org/).\n",
    "\n",
    "The Scatter Plot Matrix can be used\n",
    "to identify possible variables we can use for prediction or variables that explain the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91505c66",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid = sns.pairplot(\n",
    "    data, kind=\"reg\"\n",
    ")  # Create the scatter plot matrix! Add regression line to help with reading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8972070c",
   "metadata": {},
   "source": [
    "From the above, we see, for instance, that blood pressure is (positively) correlated with weight.\n",
    "So it was good that we did not remove that column to get rid of the NaN\n",
    "since the weight seems to predict the blood pressure!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6746dfb",
   "metadata": {},
   "source": [
    "## Exploring correlations between pairs of variables - Correlations\n",
    "The Scatter Plot Matrix can be difficult to read for many variables. We can reduce the plots to just numbers by\n",
    "calculating correlations between different pairs of variables. We will here use the\n",
    "[Pearson correlation coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient). This\n",
    "is a number between -1 and 1 that quantifies the correlation between a pair of variables. Here is a picture\n",
    "from Wikipedia that shows different situations:\n",
    "\n",
    "![Pearson correlation coefficient - picture](https://upload.wikimedia.org/wikipedia/commons/thumb/3/34/Correlation_coefficient.png/600px-Correlation_coefficient.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe1566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data.corr()  # Calculate correlations between all pairs of variables\n",
    "corr.style.background_gradient(\n",
    "    cmap=\"Blues\"\n",
    ")  # Show the correlations in a colored table:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec6061f",
   "metadata": {},
   "source": [
    "We can also make a nice plot as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfe4ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "sns.heatmap(corr, cmap=\"PiYG\", vmin=-1, vmax=1, annot=True, ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7618d427",
   "metadata": {},
   "source": [
    "From the plot above, we see, for instance, that the blood pressure is most strongly correlated with weight, but\n",
    "also that it is positively correlated with age, body surface area, and eart rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e806376b",
   "metadata": {},
   "source": [
    "## Creating a model for predicting the blood pressure\n",
    "Let us also create a least squares model for the blood pressure, to check if we can predict it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c90cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "y = data[\"BP\"].to_numpy()\n",
    "variables = [i for i in data.columns if i != \"BP\"]\n",
    "X = data[variables].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eba442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = scale(X)\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "model.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d33d32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(y_true, y_pred, k=0):\n",
    "    \"\"\"Calculate some scores for predicted y-values\"\"\"\n",
    "    r2 = r2_score(y_true, y_pred)  # R²\n",
    "    mse = mean_squared_error(y_true, y_pred)  # Mean squared error\n",
    "    n = len(y)\n",
    "    r2_adj = 1 - (1 - r2) * (n - 1) / (n - k - 1)  # R²-adjusted\n",
    "    return r2, r2_adj, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7ea453",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_scaled)\n",
    "scores = score_model(y, y_hat, k=len(variables))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5001195",
   "metadata": {},
   "source": [
    "It is hard to plot the blood pressure as a function of all the variables we have used. This would be a 9-dimensional\n",
    "plot! One useful plot we can make is to plot the predicted and measured y-values against each other.\n",
    "If the prediction is perfect, these points will all fall on the $x=y$ line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5efa244",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axi = plt.subplots(constrained_layout=True)\n",
    "axi.scatter(y_hat, y)\n",
    "axi.set_aspect(\"equal\")  # Make the plot square\n",
    "axi.plot(\n",
    "    [100, 130], [100, 130], ls=\":\", color=\"k\"\n",
    ")  # Plot x=y to help us read the plot\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1dd4b6",
   "metadata": {},
   "source": [
    "We can also show the parameters of the linear model. Since we have scaled the variables, this will\n",
    "tell us something about the importance of the different variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9adbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axi = plt.subplots(constrained_layout=True)\n",
    "pos = range(len(variables))\n",
    "axi.bar(pos, model.coef_)\n",
    "axi.axhline(y=0, ls=\":\", color=\"k\")\n",
    "axi.set_xticks(pos)\n",
    "axi.set_xticklabels(variables)\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4e49a7",
   "metadata": {},
   "source": [
    "Here, we see that the highest coefficients are for age, weight, BSA, and heart rate. This fits well with what\n",
    "we have seen in the correlation plots. But, in those plots, we also see that some of these variables are\n",
    "correlated. We, therefore, expect that we can make simpler models that are almost as good as the one we have just\n",
    "made. Let us try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc49adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "selections = [  # Try some more selections here!\n",
    "    [\"Weight\", \"Age\", \"BSA\"],\n",
    "    [\"Weight\", \"Age\", \"BSA\", \"Pulse\"],\n",
    "]\n",
    "\n",
    "table = {\"variables\": [], \"r2\": [], \"r2(adj)\": [], \"mse\": []}\n",
    "\n",
    "all_models = []\n",
    "\n",
    "for selection in selections:\n",
    "    X_scaled = scale(data[selection].to_numpy())\n",
    "    model_sel = LinearRegression(fit_intercept=True)\n",
    "    model_sel.fit(X_scaled, y)\n",
    "    all_models.append(model_sel)\n",
    "\n",
    "    y_hat = model_sel.predict(X_scaled)\n",
    "    r2, r2_adj, mse = score_model(y, y_hat, k=len(selection))\n",
    "\n",
    "    table[\"variables\"].append(\" & \".join(selection))\n",
    "    table[\"r2\"].append(r2)\n",
    "    table[\"r2(adj)\"].append(r2_adj)\n",
    "    table[\"mse\"].append(mse)\n",
    "\n",
    "\n",
    "table = pd.DataFrame(table)\n",
    "\n",
    "fig, axi = plt.subplots(constrained_layout=True)\n",
    "pos = range(len(table[\"variables\"]))\n",
    "axi.plot(pos, table[\"r2\"], marker=\"o\", label=\"R²\")\n",
    "axi.plot(pos, table[\"r2(adj)\"], marker=\"X\", label=\"R²-adjusted\")\n",
    "axi.legend()\n",
    "axi.set_xticks(pos)\n",
    "axi.set_xticklabels(table[\"variables\"].values)\n",
    "axi.set_ylabel(\"R² & R²-adjusted\")\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5167d316",
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a61d350",
   "metadata": {},
   "source": [
    "If we adhere to [Occam's razor](https://en.wikipedia.org/wiki/Occam%27s_razor), we are happy with a model\n",
    "predicting the blood pressure from just the weight, or the weight & age.\n",
    "\n",
    "**PS!** There are ways of automating the variable (or feature) selection. Please see the scikit-learn documentation\n",
    "on [feature selection](https://scikit-learn.org/stable/modules/feature_selection.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4f5bb5",
   "metadata": {},
   "source": [
    "## Alternative to least squares\n",
    "It can be a lot of work to compare different models and try different selections of variables. Let us\n",
    "try an alternative, the [least absolute shrinkage and selection operator (LASSO)](https://en.wikipedia.org/wiki/Lasso_(statistics)).\n",
    "This one modifies the error we minimize. In least squares we minimize the\n",
    "squared errors,\n",
    "\n",
    "\\begin{equation}\n",
    "J = \\frac{1}{N} \\sum_{i=1}^N (y_i - \\hat{y}_i)^2.\n",
    "\\end{equation}\n",
    "\n",
    "where $\\hat{y}_i = b_0 + b_1 x_1 + \\ldots = b_0 + \\sum_{j=1}^m b_j x_j$,\n",
    "while in LASSO, we minimize,\n",
    "\n",
    "\\begin{equation}\n",
    "J = \\frac{1}{N} \\sum_{i=1}^N (y_i - \\hat{y}_i)^2 + \\alpha \\sum_{j=1}^m | b_j | .\n",
    "\\end{equation}\n",
    "\n",
    "The practical outcome of this is that the minimization penalizes large coefficients and can now find solutions where some $b_j$'s are zero (= not important\n",
    "for the model!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c967a418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2941ed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = scale(X)\n",
    "model_lasso = Lasso(alpha=2)\n",
    "model_lasso.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40370e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axi = plt.subplots(constrained_layout=True)\n",
    "pos = [i for i in range(len(variables))]\n",
    "axi.bar(pos, model_lasso.coef_)\n",
    "axi.axhline(y=0, ls=\":\", color=\"k\")\n",
    "axi.set_xticks(pos)\n",
    "axi.set_xticklabels(variables)\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e39d16",
   "metadata": {},
   "source": [
    "**Conclusion:** The LASSO method \"automatically\" figures out that the age and weight are the variables we need here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

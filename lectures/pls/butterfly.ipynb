{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cfc5edd",
   "metadata": {},
   "source": [
    "# Monarch butterfly population decline in North America: identifying the threatening processes\n",
    "\n",
    "We will here repeat a Partial least squares (PLS) analysis to investigate the decline in the population of the [monarch butterfly](https://en.wikipedia.org/wiki/Monarch_butterfly) in North America. The original study can be found in [Thogmartin et al. (2017). Monarch butterfly population decline in North America: identifying the threatening processes. *Royal Society Open Science*, 4, 170760](https://doi.org/10.1098/rsos.170760).\n",
    "In this article, the authors investigate factors that may have influenced the decline in the monarch butterfly population in North America over the last two decades.\n",
    "The factors include climatic factors, habitat loss, disease, and agricultural\n",
    "insecticide use. So let us see what PLS can tell us about these factors.\n",
    "\n",
    "| <a href=\"https://commons.wikimedia.org/wiki/File:Danaus_plexippus_on_Asclepias_incarnata_4999.jpg\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/5/53/Danaus_plexippus_on_Asclepias_incarnata_4999.jpg\" width=\"50%\"> </a>          |\n",
    "|:-:|\n",
    "|  *R. A. Nonenmacher, CC BY-SA 4.0 https://creativecommons.org/licenses/by-sa/4.0, via Wikimedia Commons*    |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5186f2",
   "metadata": {},
   "source": [
    "## Loading the raw data\n",
    "The raw data is available via [ScienceBase](http://dx.doi.org/10.5066/F7P55M8G). For convenience, it is also included here in the file [butterfly.csv](./butterfly.csv).\n",
    "\n",
    "The population size of the monarch butterfly is based on the size (area) of their overwintering habitat in central Mexico. The data set contains many variables; a description is in the file [butterfly_variables.csv](./butterfly_variables.csv).\n",
    "\n",
    "We start by loading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fc761e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown, display\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_theme(style=\"ticks\", context=\"notebook\", palette=\"muted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e113945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw data and take a peak at it:\n",
    "data = pd.read_csv(\"butterfly.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385bef98",
   "metadata": {},
   "source": [
    "The variable names are a bit cryptic, so let us load [butterfly_variables.csv](./butterfly_variables.csv) to get\n",
    "a description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67618889",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "variable_info = pd.read_csv(\"butterfly_variables.csv\")\n",
    "display(Markdown(variable_info.to_markdown(index=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c00fc20",
   "metadata": {},
   "source": [
    "We see here that `area_pva` contains the area, which we can use as a proxy for the population size. In addition, we see that the variables have a type; for instance, `closum_N` is the pesticide [Clothianidin](https://en.wikipedia.org/wiki/Clothianidin) and `closum_N` quantifies the amount of this chemical used in a particular region.\n",
    "\n",
    "Let us pick out the variables we will use:\n",
    "\n",
    "- `area_pva`: As the y-variable (the one we will predict).\n",
    "\n",
    "\n",
    "- `popgrowth_pva`: We will skip this variable (as per the description: \"not used in analysis\")\n",
    "\n",
    "\n",
    "- `milkweed resource` (and `log milkweed resource`): We will also skip these two. These variables quantify\n",
    "   the amount of [milkweed](https://en.wikipedia.org/wiki/Asclepias), a plant that monarch butterflies\n",
    "   use as a host for their larvae. This is probably described by\n",
    "   variables that quantify habitat loss. On a side note - we could include this variable as an\n",
    "   additional y-variable (to see what influences the amount of milkweed).\n",
    "\n",
    "\n",
    "- `year`: We will skip this variable as we are not interested in seeing the influence of the year\n",
    "  (but rather the influence of factors such as habitat loss). (And we know already that the butterfly population\n",
    "  is decreasing.)\n",
    "\n",
    "\n",
    "- All other variables: These will be our X-variables. We had 81 columns in the original data set,\n",
    "  we are skipping 4 of these, and one is the y-variable - we should then be left with 81 - 4 - 1 = 76 factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d53ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "yvars = [\"area_pva\"]\n",
    "skip = [\"year\", \"popgrowth_pva\", \"milkweed resource\", \"log milkweed resource\"]\n",
    "xvars = [i for i in data.columns if i not in skip + yvars]\n",
    "print(f\"No. of X-variables: {len(xvars)}\")\n",
    "\n",
    "y = data[yvars].to_numpy()\n",
    "X = data[xvars].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621ab872",
   "metadata": {},
   "source": [
    "For convenience, we also make a small \"table\" so that we can look up the type and description for a variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f527d2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_type = {\n",
    "    namei: typei\n",
    "    for namei, typei in zip(\n",
    "        variable_info[\"Variable\"].values, variable_info[\"type\"].values\n",
    "    )\n",
    "}\n",
    "description = {\n",
    "    namei: desci\n",
    "    for namei, desci in zip(\n",
    "        variable_info[\"Variable\"].values, variable_info[\"Description\"].values\n",
    "    )\n",
    "}\n",
    "\n",
    "test_var = \"CRPsum_N\"\n",
    "print(f\"\\nInfo for: {test_var}\")\n",
    "print(f\"Type: {variable_type[test_var]}\")\n",
    "print(f\"Description: {description[test_var]}\")\n",
    "\n",
    "test_var = \"glysum_N\"\n",
    "print(f\"\\nInfo for: {test_var}\")\n",
    "print(f\"Type: {variable_type[test_var]}\")\n",
    "print(f\"Description: {description[test_var]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c40e94",
   "metadata": {},
   "source": [
    "## Preparing the data for partial least squares\n",
    "\n",
    "The variables we have are in very different units (for instance, some are measured in kg, while others are\n",
    "measured in Celsius or Fahrenheit) and we will therefore scale the raw data before using it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100e83b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_x, scaler_y = StandardScaler(), StandardScaler()\n",
    "\n",
    "y = scaler_y.fit_transform(data[yvars].to_numpy())\n",
    "X = scaler_x.fit_transform(data[xvars].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51f8271",
   "metadata": {},
   "source": [
    "## Creating a PLS model\n",
    "\n",
    "Next, we create the partial least squares model. Here, we have few observations - we will, therefore, not\n",
    "split into test/training sets, but we will instead do [Leave-one-out cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)#Leave-one-out_cross-validation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcc7cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d6b27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the PLS model here:\n",
    "# model = PLSRegression(...)\n",
    "model = PLSRegression(scale=False, n_components=2)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e9bf50",
   "metadata": {},
   "source": [
    "### Plot predicted y vs. measured y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8fde1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "y_hat = model.predict(X)\n",
    "for i, yvari in enumerate(yvars):\n",
    "    ax.scatter(\n",
    "        y[:, i],\n",
    "        y_hat[:, i],\n",
    "        label=f\"{yvari} (R² = {r2_score(y[:, i], y_hat[:, i]):.3g})\",\n",
    "    )\n",
    "ax.legend()\n",
    "ax.set(xlabel=\"y\", ylabel=\"ŷ\")\n",
    "ax.set_title(\"Predicted (ŷ) vs. measured (y)\", loc=\"left\")\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b1bd01",
   "metadata": {},
   "source": [
    "### Leave-one-out-cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de011b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "Q = []  # Calculated as R², but with one point left out from the fitting.\n",
    "for train_index, test_index in loo.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model_loo = PLSRegression(**model.get_params())\n",
    "    model_loo.fit(X_train, y_train)\n",
    "    y_hat = model_loo.predict(X)\n",
    "    Q.append(r2_score(y_hat, y))\n",
    "print(f\"Q² = {np.mean(Q)} +- {np.std(Q)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32e8e70",
   "metadata": {},
   "source": [
    "*How would you \"rate\" the R² and Q² here?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed66f63",
   "metadata": {},
   "source": [
    "## Inspecting the PLS model\n",
    "\n",
    "Next, we will inspect the results from the PLS model. We will focus on the [regression coefficients](#Regression-coefficients) and the [loadings](#Inspecting-loadings).\n",
    "\n",
    "To simplify the plotting, the file [fancyplots.py](./fancyplots.py) contains some methods that can be used\n",
    "to plot the regression coefficients and the loadings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52a2abf",
   "metadata": {},
   "source": [
    "### Inspecting regression coefficients\n",
    "\n",
    "The PLS model can be summarized as,\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{Y} = \\mathbf{X} \\mathbf{B}_\\text{PLS}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\mathbf{B}_\\text{PLS}$ contains the PLS regression coefficients. These coefficients\n",
    "give the contributions from the original X-variables for predicting the Y-variables.\n",
    "\n",
    "Here, we will plot these coefficients in a bar chart to compare them. We will also colour the bars\n",
    "according to the type of the variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127dc178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot coefficients:\n",
    "from fancyplots import mpl_plot_coefficients\n",
    "\n",
    "mpl_plot_coefficients(model, xvars, yvars, variable_type=variable_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0349e598",
   "metadata": {},
   "source": [
    "*How would you summarize the influence of pesticides on `area_pva`?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4ea921",
   "metadata": {},
   "source": [
    "The [bokeh](https://docs.bokeh.org/en/latest/) library makes it possible to create interactive\n",
    "visualizations for web browsers. Here, we will use it to make a plot where the name, type, and description\n",
    "of the variables are shown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dddb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import show\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab2bf30",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from fancyplots import bokeh_plot_coefficients\n",
    "\n",
    "figures = bokeh_plot_coefficients(\n",
    "    model, xvars, yvars, variable_type=variable_type, description=description\n",
    ")\n",
    "show(figures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2500a37",
   "metadata": {},
   "source": [
    "### Inspecting loadings\n",
    "\n",
    "In the PLS model, we obtain loadings for both X and Y. We can plot these together for different latent\n",
    "variables to see the contributions from the original variables to the latent variables, and correlations between\n",
    "variables.\n",
    "\n",
    "In terms of the original variables, we have for the X-scores ($\\mathbf{T}$) and Y-scores ($\\mathbf{U}$):\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{T} &= \\mathbf{X} \\mathbf{R}_x \\\\\n",
    "\\mathbf{U} &= \\mathbf{Y} \\mathbf{R}_y\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "where $\\mathbf{R}_x$ and $\\mathbf{R}_y$ are *weights/loadings* that can be applied\n",
    "directly to the original data matrices (in `sklearn`, they are called *rotations*).\n",
    "For instance, the $\\mathbf{R}_x$\n",
    "matrix gives us information on the contributions from the original variables to the scores. We can plot them similarly to how we plot the loadings in PCA (e.g., we can plot them and look for correlations\n",
    "between the X-variables). We can do the same for the Y-rotation $\\mathbf{R}_y$ and look for correlations between\n",
    "the Y-variables. But, if we here are using just one Y-variable, then this is not too interesting (as\n",
    "there are no other Y-variables to look for correlations with).\n",
    "\n",
    "#### Digging deeper\n",
    "\n",
    "If we are making a prediction where we want to *predict* $\\mathbf{Y}_\\text{new}$ from\n",
    "new $\\mathbf{X}_\\text{new}$ values, then\n",
    "the relation for the Y-scores does not seem too helpful, since we need to know the new $\\mathbf{Y}_\\text{new}$ we\n",
    "are trying to predict to find the new Y-scores. If we follow the approach from when we did \"PLS by hand\",\n",
    "then we could do the following to predict $\\mathbf{Y}_\\text{new}$:\n",
    "\n",
    "1. Obtain $\\mathbf{T}_\\text{new}$ from $\\mathbf{T}_\\text{new} = \\mathbf{X}_\\text{new} \\mathbf{R}_x$\n",
    "\n",
    "2. Obtain $\\mathbf{U}_\\text{new}$ from $\\mathbf{T}_\\text{new}$\n",
    "\n",
    "3. Obtain $\\mathbf{Y}_\\text{new}$ from $\\mathbf{U}_\\text{new} = \\mathbf{Y}_\\text{new} \\mathbf{R}_y$\n",
    "   by inverting $\\mathbf{R}_y$.\n",
    "\n",
    "\n",
    "In general, we can not invert $\\mathbf{R}_y$, but we can use the *loadings* ($\\mathbf{Q}$)\n",
    "for this,\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{Y} = \\mathbf{U} \\mathbf{Q}^\\top\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "We can then write,\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{Y}_\\text{new} = \\mathbf{U}_\\text{new} \\mathbf{Q}^\\top = \\mathbf{T}_\\text{new} \\mathbf{Q}^\\top\n",
    "\\end{equation}\n",
    "\n",
    "(note: we \"absorb\" the $g$-factors relating $\\mathbf{U}$ and $\\mathbf{T}$ into $\\mathbf{Q}$).\n",
    "In this equation, we directly relate the X-scores and the predicted Y\n",
    "via the loadings $\\mathbf{Q}$.\n",
    "\n",
    "Let us verify some of these relations before we move on (note: similar to the Y-loadings $\\mathbf{Q}$, there is also a set of X-loadings, $\\mathbf{P}$ we can use\n",
    "for $\\mathbf{X} = \\mathbf{T} \\mathbf{P}^\\top$): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b92d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us first check the transformation from X, y to scores:\n",
    "T, U = model.transform(X, y)  # Get the scores directly from the PLS model\n",
    "Rx = model.x_rotations_\n",
    "Ry = model.y_rotations_\n",
    "T_by_hand = X @ Rx\n",
    "U_by_hand = y @ Ry\n",
    "\n",
    "print(\"X-scores are OK:\", np.allclose(T, T_by_hand))\n",
    "print(\"Y-scores are OK:\", np.allclose(U, U_by_hand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0cf94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us check the predictions:\n",
    "Y_new = model.predict(X)  # Predict Y from the B_PLS coefficients and X\n",
    "Q = model.y_loadings_\n",
    "Y_new_2 = T @ Q.T  # Predict Y from the X-scores and Y-loadings\n",
    "print(\n",
    "    \"Prediction with (X, B_PLS) and (T, Q) are the same:\",\n",
    "    np.allclose(Y_new, Y_new_2),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0956c7b7",
   "metadata": {},
   "source": [
    "We have now two equations for predicting $\\mathbf{Y}_\\text{new}$:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{T}_\\text{new} &= \\mathbf{X}_\\text{new} \\mathbf{R}_x \\\\\n",
    "\\mathbf{Y}_\\text{new} &= \\mathbf{T}_\\text{new} \\mathbf{Q}^\\top \n",
    "\\end{align}\n",
    "\n",
    "* In the first equation, the $\\mathbf{R}_x$ matrix contain information on how the original variables are\n",
    "  used to obtain the X-scores.\n",
    "* In the second equation, the $\\mathbf{Q}$ matrix contain information on how the original variables\n",
    "  (via the scores $\\mathbf{T}_\\text{new}$) are used to predict new $\\mathbf{Y}_\\text{new}$ values. So,\n",
    "  if we plot these loadings (together with $\\mathbf{R}_x$),\n",
    "  we will get information on how X-variables are correlated with\n",
    "  the Y-variables. But that is not all; the $\\mathbf{Q}$ matrix also contains information on\n",
    "  how the Y-variables are correlated with each other.\n",
    "  \n",
    "**Summarized:** If we plot the values from $\\mathbf{R}$ and $\\mathbf{Q}$ for selected latent variables (for\n",
    "instance, the first and second), we get information on:\n",
    "\n",
    "* correlations between the X-variables,\n",
    "* correlations between the Y-variables, and,\n",
    "* correlations between the X and Y-variables.\n",
    "\n",
    "The $\\mathbf{R}_x$ matrix can be accessed via `.x_rotations_` of the sklearn object for the PLS model, and\n",
    "the $\\mathbf{Q}$ matrix can be accessed via `.y_loadings_` of the same object. We will now use these two to\n",
    "create a biplot, showing the correlations between the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88632f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fancyplots import mpl_plot_loadings\n",
    "\n",
    "mpl_plot_loadings(model, xvars, yvars, variable_type, idx1=0, idx2=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78eaef7",
   "metadata": {},
   "source": [
    "### Interactive plot of loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8b0eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fancyplots import bokeh_plot_loadings\n",
    "\n",
    "fig = bokeh_plot_loadings(\n",
    "    model,\n",
    "    xvars,\n",
    "    yvars,\n",
    "    variable_type,\n",
    "    description,\n",
    "    idx1=0,\n",
    "    idx2=1,\n",
    ")\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f2072c",
   "metadata": {},
   "source": [
    "From the previous plot(s):\n",
    "\n",
    "- How is the area of land enrolled in Conservation Reserve Program (variables `CRPsum_N` and `CRPsum_S`)\n",
    "  correlated with the population size?\n",
    "\n",
    "\n",
    "- How is the (cumulative) use of the herbicide Glyphosate (variables `glycum_N` and `glycum_S`)\n",
    "  correlated with the population size?\n",
    "\n",
    "\n",
    "- Locate the variables describing the use of the herbicide dicamba in the northern region\n",
    "  (`DC_N`) and in the southern region (`DC_S`). How are these correlated with the population size?\n",
    "\n",
    "\n",
    "- Include the \"year\" as an additional Y-variable and rerun the analysis. But before that, where\n",
    "  approximately would you expect the \"year\" to show up in the loadings plot above? (Hint: How is it correlated with the population size?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise set 9\n",
    "\n",
    "> * The goal of the first part of the exercise is to gain familiarity with partial least\n",
    "squares regression. For this, we will make\n",
    "a model that can predict the concentrations in a mixture from near-infrared spectra.\n",
    "> \n",
    "> * In the second part of the exercise, you will do a PCA analysis of gene expressions.\n",
    "This part is to get more experience with PCA, particularly interpreting results from PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9.1\n",
    "\n",
    "[Windig and Stephenson](https://doi.org/10.1021/ac00046a015) measured near-infrared spectra\n",
    "for 140 mixtures of the solvents methylene chloride, 2-butanol, methanol,\n",
    "dichloropropane, and acetone. Here, we will predict the compositions of the mixtures from the spectra.\n",
    "Each spectrum was sampled at 700 wavelengths\n",
    "between 1100 and 2500~nm. The file\n",
    "[`Data/windig.csv`](Data/windig.csv) contains the raw data:\n",
    "Each row in this file\n",
    "contains a spectrum (the columns starting with `wavelength.`) and the\n",
    "corresponding concentrations (the columns starting with `conc.`).\n",
    "\n",
    "The data can be loaded as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_context(\"notebook\")\n",
    "\n",
    "data = pd.read_csv(\"Data/windig.csv\")\n",
    "X = data.filter(like=\"wavelength\", axis=1).values  # NIR spectra\n",
    "Y = data.filter(like=\"conc\", axis=1).values  # Concentrations\n",
    "print(f\"No. of spectra: {X.shape[0]}\")\n",
    "print(f\"No. of wavelengths: {X.shape[1]}\")\n",
    "print(f\"No of concentration samples: {Y.shape[0]}\")\n",
    "print(f\"No of species in each sample: {Y.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot the spectra:\n",
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "for spectrum in X:\n",
    "    ax.plot(spectrum)\n",
    "ax.set(xlabel=\"Wavelength (no unit)\", ylabel=\"Absorbance\")\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1(a)\n",
    "Create a partial least squares regression (PLSR) model for predicting\n",
    "the concentrations. Use 1 PLS component for your first model and\n",
    "assess it using $R^2$, RMSEC, RMSECV and RMSEP.  An example\n",
    "of how this can be done are given below.\n",
    "\n",
    "These values (RMSEC, RMSECV, and RMSEP) are all based on calculating the\n",
    "root mean squared error (RMSE) given by,\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^N (y_i - \\hat{y}_i)^2},\n",
    "\\tag{1}\\end{equation}\n",
    "\n",
    "where $y_i$ are our measured $y$-values and $\\hat{y}_i$ are the\n",
    "values predicted by our model. The difference between RMSEC,\n",
    "RMSEP, and RMSECV lie in the part of the data we use to\n",
    "calculate them. This is based on first splitting the data into\n",
    "a *training* and *test* set, and then\n",
    "performing what we call\n",
    "[*cross-validation*](https://scikit-learn.org/stable/modules/cross_validation.html) using\n",
    "the training set:\n",
    "\n",
    "\n",
    "* When we use the training set to create our model, we are doing\n",
    "  a *calibration*. If we calculate RMSE based on using\n",
    "  the training set, we refer to this as the RMSEC (root mean squared\n",
    "  error of calibration).\n",
    "  This number\n",
    "  quantifies the error we get in connection with making (calibrating)\n",
    "  the model.\n",
    "  \n",
    "* When we use the test set to test our model, we are\n",
    "  checking how well our model *predicts* \"new\" samples\n",
    "  (that is, samples not used when making the model). If\n",
    "  we calculate RMSE based on the training set, we refer to \n",
    "  this as the RMSEP (root mean squared error of prediction). This\n",
    "  number quantifies the error we can expect to make when using\n",
    "  our model for predicting new samples.\n",
    "  \n",
    "* Cross-validation is based on further splitting the training set. Typically, we divide the\n",
    "  training set into $k$ smaller subsamples, and we repeat the fitting of the\n",
    "  model $k$ times. Each time we repeat the fitting, we retain a single\n",
    "  subsample for validation, and we fit the model using\n",
    "  the $k-1$ other subsamples. For the subsample we retained\n",
    "  for validation, we can calculate the RMSE value of how\n",
    "  well our model predicts it. Since we repeat this $k$ times,\n",
    "  we can make it so that each of the $k$ subsamples is\n",
    "  used exactly once for validation. Finally, we can\n",
    "  obtain the average RMSE of the $k$ fittings, and we\n",
    "  refer to this value as the RMSECV (root mean squared error\n",
    "  of cross-validation). This number also estimates how well the model predicts new cases, and   we also get information on how sensitive the model is to model parameters and the part of   \n",
    "  the training set used. We can also use cross-validation to optimize the parameters in the \n",
    "  model (for instance, the number of PLS components).\n",
    "\n",
    "Luckily, methods for splitting our data into training and test\n",
    "sets, calculating RMSE, and doing cross-validation are already\n",
    "available in sklearn. Note: Splitting the data into training\n",
    "and test sets and performing cross-validation involves some randomness, and your answers will probably change if you rerun\n",
    "your code.\n",
    "\n",
    "Here is a visualization of the splitting:\n",
    "![cross](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, here is how you can split into a testing and training set:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X,\n",
    "    Y,\n",
    "    test_size=0.33,  # Use 33 % of the data (one third) for the test set.\n",
    "    shuffle=True,  # Randomly shuffle the data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a PLS model:\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "model = PLSRegression(n_components=4)  # Set up a PLS model with 4 components\n",
    "model.fit(X_train, Y_train)  # Fit/make the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate scores for the model:\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "Y_hat_train = model.predict(X_train)  # Predict for the training set\n",
    "Y_hat_test = model.predict(X_test)  # Predict for the test set\n",
    "\n",
    "# Calculate R²:\n",
    "r2_train = r2_score(Y_train, Y_hat_train)\n",
    "print(f\"R² for training set: {r2_train}\")\n",
    "r2_test = r2_score(Y_test, Y_hat_test)\n",
    "print(f\"R² for test set: {r2_test}\")\n",
    "\n",
    "# Calculate RMSE:\n",
    "rmsec = mean_squared_error(Y_train, Y_hat_train, squared=False)\n",
    "print(f\"RMSEC: {rmsec}\")\n",
    "rmsep = mean_squared_error(Y_test, Y_hat_test, squared=False)\n",
    "print(f\"RMSEP: {rmsep}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for cross-validation:\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Run cross-validation:\n",
    "cvscore = cross_val_score(\n",
    "    model,  # Select the model we are going to score\n",
    "    X_train,  # Give the X-training set\n",
    "    Y_train,  # Give the y-training set\n",
    "    scoring=\"neg_mean_squared_error\",  # select scoring method\n",
    "    cv=5,  # Number of splits to make\n",
    ")\n",
    "# Note: the scoring is here \"neg_mean_squared_error\".\n",
    "# This is the negative of the MSE!\n",
    "# The cross_val_score method is often used in\n",
    "# connection with optimization where we would like to\n",
    "# maximize something, and the score can be used to pick\n",
    "# the best value. Since we usually do not want to\n",
    "# maximize the error, this method is made so that it\n",
    "# calculates the negative of the error.\n",
    "\n",
    "cvscore = np.sqrt(-cvscore)  # Account for the negative sign.\n",
    "rmsecv = cvscore.mean()\n",
    "rmsecv_std = np.std(cvscore)\n",
    "print(f\"\\nRMSECV: {rmsecv} ± {rmsecv_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start from the beginning:\n",
    "# 1) Load the data:\n",
    "data = pd.read_csv(\"Data/windig.csv\")\n",
    "X = data.filter(like=\"wavelength\", axis=1).values  # NIR spectra\n",
    "Y = data.filter(like=\"conc\", axis=1).values  # Concentrations\n",
    "\n",
    "# 2) Split the data and scale X:\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.33, shuffle=True\n",
    ")\n",
    "\n",
    "scale_x = StandardScaler()\n",
    "X_train = scale_x.fit_transform(X_train)\n",
    "X_test = scale_x.transform(X_test)\n",
    "\n",
    "\n",
    "# 3) Create PLS model:\n",
    "\n",
    "model0 = PLSRegression(n_components=1)\n",
    "model0.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Calculate the metrics for the model, here we create methods\n",
    "# to do this, so that we can reuse the methods later.\n",
    "\n",
    "\n",
    "def score_model(model, X_train, X_test, Y_train, Y_test):\n",
    "    \"\"\"Score a regression model.\"\"\"\n",
    "    Y_hat_train = model.predict(X_train)\n",
    "    Y_hat_test = model.predict(X_test)\n",
    "    scores = {\n",
    "        \"r²(train)\": r2_score(Y_train, Y_hat_train),\n",
    "        \"r²(test)\": r2_score(Y_test, Y_hat_test),\n",
    "        \"RMSEC\": mean_squared_error(Y_train, Y_hat_train, squared=False),\n",
    "        \"RMSEP\": mean_squared_error(Y_test, Y_hat_test, squared=False),\n",
    "    }\n",
    "    scores_cv = cross_val_score(\n",
    "        model,\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "        cv=10,\n",
    "    )\n",
    "    scores_cv = np.sqrt(-scores_cv)\n",
    "    scores[\"RMSECV\"] = scores_cv.mean()\n",
    "    scores[\"RMSECV_std\"] = scores_cv.std()\n",
    "    return scores\n",
    "\n",
    "\n",
    "def score_models(models, X_train, X_test, Y_train, Y_test):\n",
    "    \"\"\"Score a set of models, and return a pandas DataFrame with results.\"\"\"\n",
    "    scores = {\"PLS components\": []}\n",
    "    for model in models:\n",
    "        scores[\"PLS components\"].append(model.n_components)\n",
    "        new_scores = score_model(model, X_train, X_test, Y_train, Y_test)\n",
    "        for key, val in new_scores.items():\n",
    "            if key not in scores:\n",
    "                scores[key] = []\n",
    "            scores[key].append(val)\n",
    "    return pd.DataFrame(scores)\n",
    "\n",
    "\n",
    "table0 = score_models([model0], X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 9.1(a): ($R^2$, RMSEC, RMSECV and RMSEP)\n",
    "\n",
    "(See the table above.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1(b)\n",
    "Improve your PLSR model by including more\n",
    "PLS components.\n",
    "Try components from 2 up to 15 and compare the different models. How many\n",
    "PLS components are you satisfied with? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for i in range(1, 16):\n",
    "    modeli = PLSRegression(n_components=i)\n",
    "    modeli.fit(X_train, Y_train)\n",
    "    models.append(modeli)\n",
    "\n",
    "table1 = score_models(models, X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kneed import KneeLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    constrained_layout=True,\n",
    "    ncols=2,\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    "    figsize=(8, 4),\n",
    ")\n",
    "axes[0].errorbar(\n",
    "    table1[\"PLS components\"],\n",
    "    table1[\"RMSECV\"],\n",
    "    table1[\"RMSECV_std\"],\n",
    "    marker=\"o\",\n",
    "    label=\"RMSECV\",\n",
    ")\n",
    "axes[0].plot(\n",
    "    table1[\"PLS components\"], table1[\"RMSEC\"], marker=\"s\", label=\"RMSEC\"\n",
    ")\n",
    "axes[1].plot(\n",
    "    table1[\"PLS components\"], table1[\"RMSEP\"], marker=\"o\", label=\"RMSEP\"\n",
    ")\n",
    "for ax in axes:\n",
    "    ax.set(xlabel=\"Number of PLS components\")\n",
    "    ax.set_xticks(table1[\"PLS components\"][::2])\n",
    "    ax.legend()\n",
    "axes[0].set(ylabel=\"RMSECV & RMSEC\")\n",
    "axes[1].set(ylabel=\"RMSEP\")\n",
    "\n",
    "kneedle = KneeLocator(\n",
    "    table1[\"PLS components\"],\n",
    "    table1[\"RMSEP\"],\n",
    "    S=1.0,\n",
    "    curve=\"convex\",\n",
    "    direction=\"decreasing\",\n",
    ")\n",
    "axes[1].axvline(\n",
    "    x=kneedle.elbow,\n",
    "    ls=\":\",\n",
    "    label=f\"Elbow ({kneedle.elbow} components)\",\n",
    "    color=\"k\",\n",
    ")\n",
    "\n",
    "\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 9.1(b):\n",
    "\n",
    "The figure above shows how the RMSE values change with the number of components.\n",
    "When increasing the number of components, we improve the model (we make the RMSE values smaller). However, we prefer a model with relatively few components (to avoid over-fitting), and we are satisfied with using just five here. This is motivated by the large drops in RMSECV and RMSEP observed up to five PLS components; including more than five components will only give minor improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1(c)\n",
    "Plot the regression coefficients for the model you found in [9.1(b)](#9.1(b))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can get the regression coefficients with:\n",
    "B = model.coef_\n",
    "# To get the coefficients for solvent no. i, you can do:\n",
    "# B[i, :]  # this selects all rows for column i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "B = models[4].coef_  # Model with 5 components\n",
    "fig, axes = plt.subplots(\n",
    "    constrained_layout=True, nrows=5, sharey=True, sharex=True, figsize=(6, 10)\n",
    ")\n",
    "solvents = (\n",
    "    \"methylene chloride, 2-butanol, methanol, dichloropropane, acetone\".split(\n",
    "        \",\"\n",
    "    )\n",
    ")\n",
    "for i, solvent in enumerate(solvents):\n",
    "    axes[i].set_title(solvent, loc=\"left\", fontsize=\"small\")\n",
    "    # axes[i].set(ylabel=\"Coefficient value\", xlabel=\"Wavelength\")\n",
    "    axes[i].plot(B[i, :])\n",
    "    axes[i].axhline(y=0, ls=\":\", color=\"k\")\n",
    "axes[-1].set_xlabel(\"(Wavelength)\", fontsize=\"small\")\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 9.1(c):\n",
    "(See the figure above.)\n",
    "\n",
    "The regression coefficients show some resemblance to spectra and  they pick out different\n",
    "parts as being important for the prediction of the different concentrations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1(d)\n",
    "Optimize the number of PLS components by a cross-validated grid search of the number of\n",
    "PLS components. Is this optimized model different from the PLS model you found in [9.1(b)](#9.1(b))?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the code for running the optimalization. This will try out\n",
    "# the number of PLS components and score the model with cross validation.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# First, we define a range of PLS components to try, let us\n",
    "# do 1, 2, ..., 20, 25, 50, 75, 100:\n",
    "parameters = {\"n_components\": list(range(1, 20)) + [25, 50, 75, 100]}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    PLSRegression(),  # the model we will make\n",
    "    parameters,  # the parameters to investigate\n",
    "    cv=5,  # number of splits for cross-validation\n",
    "    scoring=\"r2\",  # select the model with highest R²\n",
    "    refit=True,  # refit the best model for the whole training set\n",
    ")\n",
    "grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best estimator us:\n",
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# It is also a good idea to plot the scores to see where it levels off:\n",
    "fig, axes = plt.subplots(constrained_layout=True, ncols=2, figsize=(8, 4))\n",
    "for ax in axes:\n",
    "    ax.errorbar(\n",
    "        parameters[\"n_components\"],\n",
    "        grid.cv_results_[\"mean_test_score\"],\n",
    "        yerr=grid.cv_results_[\"std_test_score\"],\n",
    "        marker=\"o\",\n",
    "    )\n",
    "    ax.set(xlabel=\"No. of PLS components\", ylabel=\"Test score (R²)\")\n",
    "axes[1].set_xlim(0, 26)\n",
    "axes[1].set_xticks([1, 5, 10, 15, 20, 25])\n",
    "axes[1].axvline(x=5, ls=\":\", color=\"k\")\n",
    "sns.despine(fig=fig)\n",
    "# Hint: It may be a good idea to zoom in on the part (1, 20) for the x-axis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 9.1(d):\n",
    "\n",
    "The grid search method selects 25 components (note: this number might change every time you run the code above due to some randomness in the splitting). In the figure above, there is not a big difference in the score beyond five components. So even though the method selects 25 components, I will pick five because the score for 25 and five is essentially the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1(e)\n",
    "Assume that you are given a spectrum from a mixture with unknown concentrations of the solvents. How well would your model\n",
    "predict the unknown concentrations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the RMSEP values for the model with five components:\n",
    "Y_hat_test = models[4].predict(X_test)\n",
    "\n",
    "for i, solvent in enumerate(solvents):\n",
    "    rmsep = mean_squared_error(Y_test[:, i], Y_hat_test[:, i], squared=False)\n",
    "    print(f\"RMSEP {solvent}: {rmsep:.3g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 9.1(e):\n",
    "\n",
    "The RMSEP values indicate the error we can expect to make when predicting new samples. In all cases, these values (see the output above) are around one concentration unit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1(f)\n",
    "Create a least squares model for predicting the concentrations.\n",
    "Assess it using $R^2$, RMSEC, RMSECV and RMSEP. Does this model\n",
    "perform as you expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model_ls = LinearRegression()\n",
    "model_ls.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_model(model_ls, X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 9.1(f):\n",
    "\n",
    "The least squares model is performing well. In this situation,\n",
    "we fit a data set with 140 samples using 700 variables, which we can do\n",
    "perfectly. Judging from the training set, the performance is about the\n",
    "same, so this does not immediately suggest that we have overfitted the model.\n",
    "\n",
    "But let us see what happens if we, by some experimental mistake, have shifted the\n",
    "spectrum two wavelengths to the right for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_shift = np.roll(X_test, 2, axis=1)\n",
    "\n",
    "Y_hat_ls = model_ls.predict(X_test_shift)\n",
    "Y_hat_pls = models[4].predict(X_test_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    constrained_layout=True, ncols=5, figsize=(15, 3), sharex=True\n",
    ")\n",
    "for i, solvent in enumerate(solvents):\n",
    "    axes[i].set_title(solvent, loc=\"left\")\n",
    "    r2_ls = r2_score(Y_test[:, i], Y_hat_ls[:, i])\n",
    "    r2_pls = r2_score(Y_test[:, i], Y_hat_pls[:, i])\n",
    "    axes[i].scatter(\n",
    "        Y_test[:, i], Y_hat_ls[:, i], label=f\"Least squares, R² = {r2_ls:.3g}\"\n",
    "    )\n",
    "    axes[i].scatter(\n",
    "        Y_test[:, i], Y_hat_pls[:, i], label=f\"PLS, R²{r2_pls:.3g}\"\n",
    "    )\n",
    "    axes[i].set_xlabel(\"y\")\n",
    "    axes[i].legend()\n",
    "axes[0].set_ylabel(\"ŷ\")\n",
    "sns.despine(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure above shows the measured (y) and predicted (ŷ) values for the least squares and the PLS model with five components, when\n",
    "applied to the shifted spectra. Here, the effect is larger for the least squares model.\n",
    "This can indicate that the least squares model is overfitted, and it is not so robust to\n",
    "small changes in the measured spectra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9.2\n",
    "\n",
    "[Schummer *et al.*](https://doi.org/10.1016/S0378-1119(99)00342-X) sstudied ovarian cancer by measuring gene expression values for 1536 genes in both non-cancer and cancer tissues. One of their goals was to investigate whether specific genes were overexpressed in cancer samples compared to non-cancer ones.\n",
    "This knowledge may be used for diagnosis, and we will here see if we\n",
    "can find such genes by performing a PCA. The raw data can be\n",
    "found in the file [`Data/ovo.csv`](Data/ovo.csv).\n",
    "Each row in the data file contains a tissue sample's gene expressions (for 1536 genes). Each column corresponds to a specific gene, named `X.1`, `X.2`, and so on.\n",
    "The classification of tissue as non-cancer (`N`) or cancer (`C`) can\n",
    "be found in the column `class`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load the data set.\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"Data/ovo.csv\")\n",
    "classes = data[\"class\"]  # Classification of samples.\n",
    "X = data.filter(like=\"X.\", axis=1)  # Gene expressions for samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2(a)\n",
    " \n",
    "Perform a principal component analysis (PCA) on the gene expression data\n",
    "and plot the explained variance as a function of the number of components.\n",
    "\n",
    "Center the data before performing the PCA. This can be\n",
    "done as follows with the `scale` method\n",
    "from `sklearn.preprocessing`:\n",
    "\n",
    "```python\n",
    "X = scale(X, with_std=False)\n",
    "```\n",
    "Here, all the variables are in the same units, so we do not need\n",
    "to scale the variance (we set `with_std=False`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "\n",
    "X = scale(X, with_std=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "scores = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(\n",
    "    constrained_layout=True, ncols=2, figsize=(8, 4)\n",
    ")\n",
    "comp = range(1, len(pca.explained_variance_ratio_) + 1)\n",
    "ax1.bar(comp, 100 * pca.explained_variance_ratio_)\n",
    "ax2.plot(comp, 100 * np.cumsum(pca.explained_variance_ratio_), marker=\"o\")\n",
    "ax1.set(xlabel=\"PC no.\", ylabel=\"Explained variance (%)\")\n",
    "ax2.set(xlabel=\"Number of PCs used\", ylabel=\"Explained variance (%)\")\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 9.2(a):\n",
    "\n",
    "The explained variance per component and the cumulative variance explained is\n",
    "shown in the figure above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2(b)\n",
    "Inspect the data by plotting the scores and loadings for\n",
    "principal component\n",
    "number 1 and principal component number 2:\n",
    "\n",
    "\n",
    "* (i) Can you observe any clustering\n",
    "  of the samples? Here, it may be helpful to colour the samples\n",
    "  according to their classification as non-cancer or cancer.\n",
    "\n",
    "\n",
    "* (ii) Are there any outliers among the samples?\n",
    "\n",
    "\n",
    "* (iii) Can you identify some overexpressed genes in cancer tissue? \n",
    "\n",
    "\n",
    "* (iv) Can you identify some underexpressed genes in cancer tissue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First the scores:\n",
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "sns.scatterplot(\n",
    "    data=data, x=scores[:, 0], y=scores[:, 1], hue=\"class\", ax=ax, s=90\n",
    ")\n",
    "\n",
    "for i, pos in enumerate(scores):\n",
    "    ax.text(pos[0], pos[1], f\"{i}\")\n",
    "\n",
    "var1 = pca.explained_variance_ratio_[0] * 100\n",
    "var2 = pca.explained_variance_ratio_[1] * 100\n",
    "ax.set(\n",
    "    xlabel=f\"PC1 ({var1:.2g}%)\",\n",
    "    ylabel=f\"PC2 ({var2:.2g}%)\",\n",
    ")\n",
    "\n",
    "ax.axhline(y=0, ls=\":\", color=\"k\")\n",
    "ax.axvline(x=0, ls=\":\", color=\"k\")\n",
    "\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And then the loadings:\n",
    "import matplotlib.patheffects as pe\n",
    "\n",
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "loadings = pca.components_\n",
    "var1 = pca.explained_variance_ratio_[0] * 100\n",
    "var2 = pca.explained_variance_ratio_[1] * 100\n",
    "ax.set(\n",
    "    xlabel=f\"PC1 ({var1:.2g}%)\",\n",
    "    ylabel=f\"PC2 ({var2:.2g}%)\",\n",
    ")\n",
    "ax.axhline(y=0, ls=\":\", color=\"k\")\n",
    "ax.axvline(x=0, ls=\":\", color=\"k\")\n",
    "\n",
    "load1 = loadings[0, :]\n",
    "load2 = loadings[1, :]\n",
    "\n",
    "# Get the 10 largest loadings along PC1,\n",
    "# we will highlight these\n",
    "idx = np.argsort(abs(load1))[-10:]\n",
    "print(f\"10 largest along PC1: {idx}\")\n",
    "for i, (xi, yi) in enumerate(zip(load1, load2)):\n",
    "    if i in idx:  # This is one of the 10 largest along PC1.\n",
    "        txt = ax.text(xi, yi, i, fontsize=\"small\", ha=\"center\", va=\"center\")\n",
    "        # Add yellow color to make these stand out:\n",
    "        txt.set_path_effects(\n",
    "            [\n",
    "                pe.withStroke(linewidth=1.5, foreground=\"yellow\"),\n",
    "                pe.Normal(),\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        txt = ax.text(\n",
    "            xi,\n",
    "            yi,\n",
    "            i,\n",
    "            fontsize=\"small\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            color=\"0.7\",\n",
    "        )\n",
    "\n",
    "ax.set_xlim(-0.15, 0.15)\n",
    "ax.set_ylim(-0.15, 0.15)\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 9.2(b):\n",
    "\n",
    "> * (i) Can you observe any clustering\n",
    ">  of the samples? Here, it may be helpful to colour the samples\n",
    ">  according to their classification as non-cancer or cancer.\n",
    "\n",
    "We see some clustering into two groups (along PC1) with cancer and non-cancer samples.\n",
    "We note that there is some overlap between the two clusters, in particular for samples\n",
    "16, 21, 22, and 23.\n",
    "\n",
    "\n",
    "> * (ii) Are there any outliers among the samples?\n",
    "\n",
    "Samples 34, 44 and 43 are separated from the other points. These could\n",
    "be outliers. To investigate this\n",
    "further, we plot the diagonal elements of the leverage matrix\n",
    "($\\mathbf{H}$) for the individual points (see page 212 in the textbook). \n",
    "The leverage matrix is\n",
    "found from the scores $\\mathbf{T}$,\n",
    "\n",
    "\\begin{equation*}\n",
    " \\mathbf{H} = \\mathbf{T} (\\mathbf{T}^\\top \\mathbf{T})^{-1} \\mathbf{T}^\\top.\n",
    "\\end{equation*}\n",
    "                    \n",
    "The leverages for our samples are shown in the figure below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we are looking at just two components, we should compute the\n",
    "# leverage for the components we are actually using:\n",
    "pca2 = PCA(n_components=2)\n",
    "scores = pca2.fit_transform(X)\n",
    "mat_inv = np.linalg.inv(np.dot(scores.T, scores))\n",
    "leverage = np.dot(np.dot(scores, mat_inv), scores.T)\n",
    "diag1 = np.diag(leverage)\n",
    "fig, ax1 = plt.subplots(constrained_layout=True)\n",
    "ax1.scatter(range(len(diag1)), diag1, s=75)\n",
    "for i, diag1i in enumerate(diag1):\n",
    "    ax1.annotate(i, (i, diag1i), fontsize=\"large\")\n",
    "ax1.set(xlabel=\"Sample number\", ylabel=\"Leverage\")\n",
    "sns.despine(ax=ax1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this plot, the leverage is relatively high for samples 34 and\n",
    "43, and this strengthens our suspicion that these points are outliers.\n",
    "We need more information to know whether they are genuine\n",
    "outliers or interesting samples.\n",
    "We will thus keep all points in the following, but in a real-life situation,\n",
    "we would investigate these two points further. We would also probably explore the points that overlap in more detail - the cancer samples 16, 21, 22, and 23 that\n",
    "are \"in-between\" the N-samples.\n",
    "\n",
    ">* (iii) Can you identify some\n",
    ">  genes which are overexpressed in tumors? \n",
    "\n",
    "From the plot of the loadings, we find that the 5 genes with the largest expression for\n",
    "the cancer samples (along PC1) are 364, 291, 522, 510, and 509.\n",
    "\n",
    "\n",
    ">* (iv) Can you identify some\n",
    ">  genes which are underexpressed in tumors? \n",
    "\n",
    "From the plot of the loadings, we find that the 5 genes with the lowest expression for\n",
    "the cancer samples (along PC1) are 1490, 538, 1116, 92, and 692."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2(c)\n",
    "Based on your answer in [9.2(b)](#9.2(b)), can\n",
    "you identify some pairs of genes that distinguish between\n",
    "non-cancer and cancer tissues? Support your findings by plotting the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We make a small function to investigate pairs of genes:\n",
    "\n",
    "from ipywidgets import Dropdown, interact\n",
    "\n",
    "\n",
    "def show_data2(variable_x, variable_y):\n",
    "    grid = sns.jointplot(\n",
    "        data=data,\n",
    "        x=f\"X.{variable_x+1}\",\n",
    "        y=f\"X.{variable_y+1}\",\n",
    "        hue=\"class\",\n",
    "        palette=\"muted\",\n",
    "    )\n",
    "    ax = grid.fig.axes[0]\n",
    "    ax.set_xlabel(f\"Gene expression for {variable_x}\")\n",
    "    ax.set_ylabel(f\"Gene expression for {variable_y}\")\n",
    "\n",
    "\n",
    "variables = sorted([364, 291, 522, 510, 509, 1490, 538, 1116, 92, 692])\n",
    "\n",
    "dropdown1 = Dropdown(options=variables, description=\"Gene (x-axis):\")\n",
    "dropdown2 = Dropdown(options=variables, description=\"Gene (y-axis):\")\n",
    "interact(show_data2, variable_x=dropdown1, variable_y=dropdown2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 9.2(c):\n",
    "\n",
    "In the previous point, we found that the genes 364, 291, 522, 510, and 509 were overexpressed in cancer samples and that 1490, 538, 1116, 92, and 692 were underexpressed. After exploring\n",
    "a bit with the figure above, we find that, for instance, genes 92 and 509 can be used\n",
    "to separate the classes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5471ebed",
   "metadata": {},
   "source": [
    "# Least squares example 2 - A polynomial\n",
    "\n",
    "In this example we will fit a polynomial. We are going to generate some values for the relation\n",
    "\n",
    "\\begin{equation}\n",
    "y = 3 + 4x + 5x^2\n",
    "\\end{equation}\n",
    "\n",
    "and check if we can recover the parameters 3, 4, and 5 by doing a least squares fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3e20b0",
   "metadata": {},
   "source": [
    "## Generate data for $y=3 + 4x + 5x^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dced27f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import some libraries for generating values and plotting:\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "sns.set_theme(style=\"ticks\", context=\"notebook\", palette=\"muted\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f09de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some values we will use for solving the least squares problem:\n",
    "x = np.arange(-11, 11, 0.5)\n",
    "y = 3 + 4 * x + 5 * x**2\n",
    "# Also plot them:\n",
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "ax.set(xlabel=\"x\", ylabel=\"y = 3 + 4*x + 5*xÂ²\")\n",
    "ax.scatter(x, y)\n",
    "sns.despine(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7f4a0e",
   "metadata": {},
   "source": [
    "## Matrix solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8581cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = np.ones_like(x)\n",
    "X = np.column_stack((ones, x, x**2))\n",
    "b = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167c68c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.linalg.pinv(X) @ y  # Matrix product of the pseudoinverse and y:\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cb3332",
   "metadata": {},
   "source": [
    "## Solution with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd445308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X2 = np.column_stack((x, x**2))\n",
    "model = LinearRegression()\n",
    "model.fit(X2, y)\n",
    "print(model.intercept_)\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5a203c",
   "metadata": {},
   "source": [
    "## Solution with statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cab455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X3 = sm.add_constant(np.column_stack((x, x**2)))\n",
    "model_s = sm.OLS(y, X3)\n",
    "result = model_s.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503559d9",
   "metadata": {},
   "source": [
    "# Least squares example 3 - Dependence between variables\n",
    "Here, we will just check what happens when we have linear dependence between the variables.\n",
    "We will generate some values for the relation\n",
    "\n",
    "\\begin{equation}\n",
    "y = 3 + 2 x_1 + x_2\n",
    "\\end{equation}\n",
    "\n",
    "and at the same time we define\n",
    "\n",
    "\\begin{equation}\n",
    "x_2 = 2 x_1\n",
    "\\end{equation}\n",
    "\n",
    "Of course, this means that the first equation we are fitting to really is\n",
    "\n",
    "\\begin{equation}\n",
    "y = 3 + 2 x_1 + x_2 = 3 + 2 x_1 + 2_x1 = 3 + 4 x_1\n",
    "\\end{equation}\n",
    "\n",
    "We shall see how well least squares deals with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7b214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some values we will use for solving the least squares problem:\n",
    "x1 = np.arange(-11, 11, 0.5)\n",
    "x2 = 2 * x1\n",
    "y = 3 + 2 * x1 + x2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1182995e",
   "metadata": {},
   "source": [
    "## Solution with matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbccdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = np.ones_like(x1)\n",
    "X = np.column_stack((ones, x1, x2))\n",
    "b = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782cf382",
   "metadata": {},
   "source": [
    "Here, the above code should fail since we can't invert $\\mathbf{X}^\\top \\mathbf{X}$ here. (Why?)\n",
    "\n",
    "We can inspect $\\mathbf{X}^\\top \\mathbf{X}$ and print out the rank, which is the number of linearly independent columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb968b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.T @ X)\n",
    "print(np.linalg.matrix_rank(X.T @ X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2668c226",
   "metadata": {},
   "source": [
    "Although we can't do the inversion above, a solution still exists! We can find it by using the psudoinverse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb04068",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.linalg.pinv(X) @ y  # Matrix product of the pseudoinverse and y:\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6b1728",
   "metadata": {},
   "source": [
    "Here, the coefficients are seemingly different from the original equation. We shall comment on this after testing out scikit-learn and statsmodels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0191e3af",
   "metadata": {},
   "source": [
    "## Solution with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e87f6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X2 = np.column_stack((x1, x2))\n",
    "model = LinearRegression()\n",
    "model.fit(X2, y)\n",
    "print(model.intercept_)\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62d9aa5",
   "metadata": {},
   "source": [
    "## Solution with statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd80415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X3 = sm.add_constant(np.column_stack((x1, x2)))\n",
    "model_s = sm.OLS(y, X3)\n",
    "result = model_s.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e2afb3",
   "metadata": {},
   "source": [
    "## Comment about the solution we found.\n",
    "We find the following least squares solution\n",
    "\n",
    "\\begin{equation}\n",
    "y = 3 + 0.8 x_1 + 1.6 x_2\n",
    "\\end{equation}\n",
    "\n",
    "if we use what we know, that $x_2 = 2 x_1$, we get\n",
    "\n",
    "\\begin{equation}\n",
    "y = 3 + 0.8 x_1 + 1.6 x_2 = 3 + 0.8 x_1 + 1.6 \\cdot 2x_1 = 3 + 0.8 x_1 + 3.2 x_1 = 3 + 4x_1\n",
    "\\end{equation}\n",
    "\n",
    "and this is equal to the original equation. So we do find the correct solution, but we do not find the\n",
    "original parameters. In fact, if we inspect what we are fitting in more detail\n",
    "\n",
    "\\begin{equation}\n",
    "y = a + b_1 x_1 + b_2 x_2 = a + b_1 x_1 + 2 b_2 x_1 = a + x_1 (b_1 + 2 b_2)\n",
    "\\end{equation}\n",
    "\n",
    "we see that what we have many possible parameters. They only have to satisfy\n",
    "\n",
    "\\begin{equation}\n",
    "b_1 + 2 b_2 = 4\n",
    "\\end{equation}\n",
    "\n",
    "and the least squares approach above find one of these. OK, let us see if we can find some other solutions by just numerically minimizing the squared error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a91a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "def error(b, X, y):\n",
    "    return sum((y - X @ b) ** 2)\n",
    "\n",
    "\n",
    "result = minimize(error, [3, 4, 0], args=(X, y))\n",
    "b = result.x\n",
    "print(b)\n",
    "print(\"b[1] + 2*b[2]:\", b[1] + 2 * b[2])\n",
    "\n",
    "\n",
    "result = minimize(error, [3, -2.4, 3.2], args=(X, y))\n",
    "b = result.x\n",
    "print(b)\n",
    "print(\"b[1] + 2*b[2]:\", b[1] + 2 * b[2])\n",
    "\n",
    "\n",
    "result = minimize(error, [3, 5.2, -0.6], args=(X, y))\n",
    "b = result.x\n",
    "print(b)\n",
    "print(\"b[1] + 2*b[2]:\", b[1] + 2 * b[2])\n",
    "\n",
    "\n",
    "result = minimize(error, [3, 2000, -998], args=(X, y))\n",
    "b = result.x\n",
    "print(b)\n",
    "print(\"b[1] + 2*b[2]:\", b[1] + 2 * b[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0831dd5d",
   "metadata": {},
   "source": [
    "## Alternative to least squares\n",
    "Let us finally try a variant of least squares. This one ([Lasso](https://en.wikipedia.org/wiki/Lasso_(statistics))) modifies the term we are minimizing in such a way\n",
    "that coefficients can become zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06986ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "model_lasso = Lasso()\n",
    "model_lasso.fit(X2, y)\n",
    "print(model_lasso.intercept_)\n",
    "print(model_lasso.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97eaaa22",
   "metadata": {},
   "source": [
    "Note that one of the coefficients is zero here. This means that the Lasso regression above has selected that\n",
    "one of the variables is not important, and it is just using the other one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

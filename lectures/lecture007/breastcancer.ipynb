{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import scale\n",
    "from psynlig import (\n",
    "    pca_explained_variance,\n",
    "    pca_explained_variance_bar,\n",
    "    pca_2d_scores,\n",
    "    pca_2d_loadings,\n",
    "    pca_1d_loadings,\n",
    ")\n",
    "plt.style.use('seaborn-notebook')\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = load_breast_cancer()\n",
    "data = pd.DataFrame(data_set['data'], columns=data_set['feature_names'])\n",
    "data['target'] = data_set['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = {0: 'Malignant', 1: 'Benign'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data set contains many variables, for this example we select just 10 of these: \n",
    "variables = [\n",
    "    'mean radius',\n",
    "    'mean texture',\n",
    "    'mean perimeter',\n",
    "    'mean area',\n",
    "    'mean smoothness',\n",
    "    'mean compactness',\n",
    "    'mean concavity',\n",
    "    'mean concave points',\n",
    "    'mean symmetry',\n",
    "    'mean fractal dimension',\n",
    "]\n",
    "# to use all variables, uncomment the next line:\n",
    "#variables = [i for i in data.columns if i!= 'target']\n",
    "print(variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scale(data[variables].values)\n",
    "pca = PCA(n_components=4)  # Do PCA, but only ask for 4 principal components\n",
    "scores = pca.fit_transform(X)\n",
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the explained variance:\n",
    "pca_explained_variance(pca, marker='o', markersize=12, alpha=0.8);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot of explained variance:\n",
    "pca_explained_variance_bar(pca);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scores:\n",
    "pca_2d_scores(\n",
    "    pca,\n",
    "    scores,\n",
    "    class_data=data['target'],\n",
    "    class_names=class_names,\n",
    "    select_components={(1, 2), (1, 3)},  # Plot PC1 vs PC2 and PC1 vs PC3\n",
    "    s=150,\n",
    "    alpha=.8\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loadings for PC1 and PC2:\n",
    "text_settings = {\n",
    "    'fontsize': 'small',\n",
    "    'outline': {'foreground': '0.5'},\n",
    "    'show': False,\n",
    "}\n",
    "\n",
    "_, axes = pca_2d_loadings(\n",
    "    pca,\n",
    "    variables,\n",
    "    select_components={(1, 2),},\n",
    "    text_settings=text_settings,\n",
    "    cmap='Spectral',\n",
    ")\n",
    "for axi in axes:\n",
    "    leg = axi.legend(fontsize='small', ncol=2, loc='lower left')\n",
    "    for legi in leg.legendHandles:\n",
    "        legi.set_sizes([75.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2D scores and loadings together:\n",
    "loading_settings = {\n",
    "    'add_text': False,\n",
    "    'add_legend': True,\n",
    "    'biplot': True,\n",
    "}\n",
    "\n",
    "pca_2d_scores(\n",
    "    pca,\n",
    "    scores,\n",
    "    xvars=variables,\n",
    "    class_data=data['target'],\n",
    "    class_names=class_names,\n",
    "    select_components={(1, 2)},\n",
    "    loading_settings=loading_settings,\n",
    "    s=100,\n",
    "    alpha=.8,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot contributions to PC1 and PC2:\n",
    "pca_1d_loadings(\n",
    "    pca,\n",
    "    variables,\n",
    "    select_components={1, 2},\n",
    "    plot_type='bar',\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the previous plot, it looks like we can separate (to some degree) by using\n",
    "# just the mean area and the mean smoothness. Let us try this:\n",
    "fig1, ax1 = plt.subplots(constrained_layout=True)\n",
    "x = 'mean area'\n",
    "y = 'mean smoothness'\n",
    "\n",
    "class0 = data.loc[data['target'] == 0]\n",
    "class1 = data.loc[data['target'] == 1]\n",
    "\n",
    "for i, klass in enumerate((class0, class1)):\n",
    "    ax1.scatter(\n",
    "        klass[x].values,\n",
    "        klass[y].values,\n",
    "        s=100,\n",
    "        label=class_names[i],\n",
    "    )\n",
    "ax1.legend()\n",
    "ax1.set_xlabel(x);\n",
    "ax1.set_ylabel(y);\n",
    "fig1.savefig('two_variables.pdf', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

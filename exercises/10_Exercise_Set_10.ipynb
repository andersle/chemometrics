{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise set 10\n",
    "\n",
    "\n",
    ">The goal of this exercise is to gain familiarity with some\n",
    ">classification methods and the different ways we can assess and compare them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 10.1\n",
    "\n",
    "\n",
    "In this exercise, we will consider the\n",
    "[UCI ML Breast Cancer Wisconsin (Diagnostic) dataset](https://goo.gl/U2Uwz2\n",
    ").\n",
    "\n",
    "This data set contains 569 tumors that have been classified\n",
    "as malignant or benign. In addition, 30 variables have been\n",
    "measured and it is our goal to make a predictive model which\n",
    "can classify new tumors as being malignant or benign.\n",
    "An overview of the different variables can be found\n",
    "on the\n",
    "[sklearn website](https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset).\n",
    "\n",
    "In the following, we are going to label the two classes\n",
    "as:\n",
    "\n",
    "\n",
    "* \"benign\" as a negative ($-1$), and\n",
    "\n",
    "\n",
    "* \"malignant\" as a positive ($+1$).\n",
    "\n",
    "\n",
    "In the lectures, we mentioned categorical variables and that we might have to\n",
    "transform these to use them in practice\n",
    "([dummy variables](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html) and\n",
    "[one-hot encoding](https://en.wikipedia.org/wiki/One-hot)\n",
    "are examples of such transformations).\n",
    "In sklearn, we do normally not have to worry about this for the y-values we use in classification.\n",
    "For instance, the [sklearn documentation for decision trees](https://scikit-learn.org/stable/modules/tree.html#classification) says that a decision tree\n",
    "\n",
    "> is capable of both binary\n",
    "> (where the labels are $[-1, 1]$) classification and multiclass (where the labels are\n",
    "> $[0, \\ldots, K-1]$)\n",
    "> classification\n",
    "\n",
    "so we use the values $-1$ and $+1$ to represent the two classes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1(a) \n",
    "\n",
    "Begin by loading the raw data and creating\n",
    "a test set using $33$\\% of the available data points for the test set.\n",
    "The example code below can be used to load the data set\n",
    "and create training/test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data[\"data\"]\n",
    "# \"Rename\" y so that -1 = benign and 1 = malignant:\n",
    "y = [-1 if i == 1 else 1 for i in data[\"target\"]]\n",
    "class_names = [\"benign\", \"malignant\"]\n",
    "print(\"Classes:\")\n",
    "print(class_names)\n",
    "\n",
    "print(\"Variables:\", data[\"feature_names\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.33,\n",
    "    # stratify=y, # Uncomment if you are using stratification\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For creating the training/test sets we use the method\n",
    "[train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "from the module [sklearn.model_selection](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection). One of the input parameters to `train_test_split` is\n",
    "`stratify`:\n",
    "\n",
    "\n",
    "* (i) Reading the documentation for\n",
    "  [stratification](https://scikit-learn.org/stable/modules/cross_validation.html#stratification)\n",
    "  can you explain what `stratify` does?\n",
    "\n",
    "\n",
    "* (ii)  Should we use `stratify` here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 10.1(a):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1(b)\n",
    "In this case, we have to determine what\n",
    "metric we are going to use\n",
    "to judge the performance of the classifiers we make. Before selecting\n",
    "a metric, we should consider what false positives and false negatives\n",
    "mean for our current problem: How would you define these two terms in our present\n",
    "case, and would you say that false positives are a more serious compared to\n",
    "false negatives here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 10.1(b):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1(c)\n",
    "Following up on the previous question, here\n",
    "are some [possible metrics](https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html) we could use to assess the performance of a\n",
    "classifier model we make:\n",
    "\n",
    "\n",
    "* Precision: The ratio of true positives to the sum of\n",
    "  true positives and false positives.\n",
    "\n",
    "\n",
    "* Recall: The ratio of true positives to the sum of true positives and false negatives.\n",
    "\n",
    "\n",
    "* F1: The (harmonic) mean of the precision and recall.\n",
    "\n",
    "\n",
    "In addition, we can summarize the performance using the [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix).\n",
    "\n",
    "\n",
    "(Note: There are many [other possibilities](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics)\n",
    "as well! If you are curious you can for instance include the\n",
    "*accuracy* which is  the ratio of correct predictions\n",
    "to the number of total predictions.)\n",
    "\n",
    "\n",
    "The choice of the metric for assessing a classifier will lead to different results.\n",
    "For instance, if we choose to use precision as our metric, we will maximize it\n",
    "during the optimization of our model. This means that we will *minimize* the\n",
    "number of *false positives*. If we choose to use the recall, on the other hand,\n",
    "we will *minimize* the number of *false negatives*.\n",
    "\n",
    "\n",
    "In the following, we will calculate these metrics for the\n",
    "different classification methods we consider. At the end of the\n",
    "exercise, you will be asked to compare the different classifiers\n",
    "using them. But before we do that: \n",
    "Which of the\n",
    "aforementioned metrics would you say is most important for\n",
    "the classification task we have here?\n",
    "\n",
    "(Note: There is no single correct answer here, and it\n",
    "really depends on how *you* judge the seriousness of false positives vs.\n",
    "false negatives.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 10.1(c):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1(d)\n",
    "Create a [$k$-nearest neighbor classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    " with 3 neighbors and\n",
    "fit it using your training set. Evaluate (with the test set) the classifier using the\n",
    "precision, recall, and F1 metrics, and plot the confusion matrix.\n",
    "An\n",
    "example of how this can be done is (for some generated data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "# Just generate some synthetic classification data for this example:\n",
    "X, y = make_classification(n_samples=1000)\n",
    "# Create test/training sets:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Create a classifier:\n",
    "knn3 = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Fit the classifier:\n",
    "knn3.fit(X_train, y_train)\n",
    "\n",
    "# Use classifier for prediction for the test set:\n",
    "y_hat = knn3.predict(X_test)\n",
    "\n",
    "# Calculate the precision etc. for the test set:\n",
    "precision = precision_score(y_test, y_hat)\n",
    "recall = recall_score(y_test, y_hat)\n",
    "f1 = f1_score(y_test, y_hat)\n",
    "print(f\"precision = {precision}\")\n",
    "print(f\"recall = {recall}\")\n",
    "print(f\"f1 = {f1}\")\n",
    "\n",
    "# Make confusion matrix:\n",
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    knn3,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    display_labels=[\"Name of class one\", \"Name of class two\"],\n",
    "    ax=ax,  # Use the figure we created above\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many false positives and false negatives do you get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 10.1(d):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1(e)\n",
    "We will now try to optimize the $k$ for a $k$-nearest neighbor classifier.\n",
    "This can be done using the method [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html).\n",
    "\n",
    "One of the inputs to this method is the `scoring` parameter, which\n",
    "selects the metric to use for finding the best $k$. Here, use the metric\n",
    "you deemed most important in question [10.1(c)](#10.1(c)). An example\n",
    "of how this can be done is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "# Just generate some synthetic classification data for this example:\n",
    "X, y = make_classification(n_samples=1000)\n",
    "\n",
    "# Create test/training sets:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Set up a grid search:\n",
    "parameters = {\"n_neighbors\": range(1, 11)}\n",
    "grid = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    parameters,\n",
    "    scoring=\"accuracy\",  # Select scoring here!\n",
    ")\n",
    "\n",
    "# Run the grid search:\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Get the best classifier from the grid search:\n",
    "best_knn = grid.best_estimator_\n",
    "print(\"Best knn:\", best_knn)\n",
    "\n",
    "# Use the best classifier for the test set:\n",
    "y_hat = best_knn.predict(X_test)\n",
    "\n",
    "# Calculate the precision etc. for the test set:\n",
    "precision = precision_score(y_test, y_hat)\n",
    "recall = recall_score(y_test, y_hat)\n",
    "f1 = f1_score(y_test, y_hat)\n",
    "print(f\"precision = {precision}\")\n",
    "print(f\"recall = {recall}\")\n",
    "print(f\"f1 = {f1}\")\n",
    "\n",
    "# Make confusion matrix:\n",
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    best_knn,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    display_labels=[\"Name of class one\", \"Name of class two\"],\n",
    "    ax=ax,  # Use the figure we created above\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using `GridSearchCV`, consider $k$-values in the range $1 \\leq k \\leq 10$\n",
    "for your search for the best $k$.\n",
    "\n",
    "Evaluate the optimized classifier using\n",
    "all of the aforementioned metrics (with the test set) and plot the confusion matrix.\n",
    "\n",
    "What value for $k$ did you find in this case? And did the number of false\n",
    "positives and false negatives change compared to the non-optimized $k$-nearest neighbor classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 10.1(e):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1(f)\n",
    "Create a [decision tree classifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "and fit it using your training set. Limit the tree to $3$ levels by setting\n",
    "the parameter `max_depth=3`.\n",
    "\n",
    "Evaluate the classifier using the\n",
    "aforementioned metrics (with the test set) and plot the confusion matrix.\n",
    "\n",
    "There is an example below question [10.1(h)](#10.1(h)) that uses a decision tree and\n",
    "shows how it can be imported. This example will plot the decision tree\n",
    "and try to optimize the depth of the tree. You can use this example as\n",
    "inspiration for solving this question and the next two questions (if you\n",
    "prefer to do them all at once)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 10.1(f):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1(g)\n",
    "We will also\n",
    "try to tune the `DecisionTreeClassifier`\n",
    "by determining the maximum depth\n",
    "we should use for the tree. Again, you can use the method\n",
    "`GridSearchCV` to optimize the parameter\n",
    "`max_depth` for the `DecisionTreeClassifier`.\n",
    "Use the metric you deemed most important\n",
    "in question [10.1(c)](#10.1(c)) and consider depths\n",
    "in the range `max_depth = range(1, 21)`, and, in addition,\n",
    "a depth\n",
    "where you set `max_depth = None` (this lets the\n",
    "tree expand as far down as possible).\n",
    "\n",
    "Evaluate the classifier with the best `max_depth` using the\n",
    "aforementioned metrics (with the test set) and plot the confusion matrix.\n",
    "\n",
    "What is the best `max_depth` you find in this case?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 10.1(g):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1(h)\n",
    "Visualize the best decision tree you found. This\n",
    "can be done using the\n",
    "method [export_graphviz from sklearn.tree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html),\n",
    "or the method [plot_tree from sklearn.tree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html)\n",
    "\n",
    "An example using `export_graphviz` is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "import graphviz\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "\n",
    "# Just generate some synthetic classification data for this example:\n",
    "X, y = make_classification(n_samples=1000, n_features=5)\n",
    "# Create test/training sets:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "# Just make up some variable names for the generated data we have used:\n",
    "variables = [f\"x{i}\" for i in range(X.shape[1])]\n",
    "\n",
    "# Set up a grid search:\n",
    "parameters = {\"max_depth\": list(range(1, 21)) + [None]}\n",
    "grid = GridSearchCV(\n",
    "    DecisionTreeClassifier(),\n",
    "    parameters,\n",
    "    scoring=\"accuracy\",  # Select scoring here!\n",
    ")\n",
    "# Run the grid search:\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Get the best classifier from the grid search:\n",
    "best_clf = grid.best_estimator_\n",
    "print(\"Best tree:\", best_clf)\n",
    "\n",
    "# Show the decision tree:\n",
    "dot_data = export_graphviz(\n",
    "    best_clf,  # The decision tree we want to draw\n",
    "    out_file=None,  # We will set the file name later\n",
    "    feature_names=variables,  # Name of variables\n",
    "    class_names=[\"Name of first class\", \"Name of second class\"],  # Class names\n",
    "    rounded=True,  # Use rounded boxes\n",
    "    filled=True,  # Use colors\n",
    ")\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"tree\", view=False)  # Create a tree.pdf for the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(If the code above executed successfully, a file named [tree.pdf](./tree.pdf) should have been created.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 10.1(h):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1(i)\n",
    "Compare the precision, recall, and F1 scores for the classifiers you have considered.\n",
    "If you were to select one\n",
    "classifier to put into real-life use, which one would you choose and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 10.1(i):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1(j)\n",
    "Extra task for the curious student: Create an alternative classifier, for instance,\n",
    "using a so-called [support vector machine](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html). We will not go into the details about how\n",
    "this classifier works in our lectures, but with `sklearn` it is rather easy\n",
    "to just try\n",
    "it and see what it can do for us.\n",
    "\n",
    "In the sklearn documentation there is also [an example that compares several classifiers](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html). Maybe you can find one that performs better than the ones\n",
    "we have considered so far in this exercise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 10.1(j):\n",
    "*Double click here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 10.2\n",
    "\n",
    "Consider again the data set for ovarian cancer and the measured gene expressions (see exercise 9).\n",
    "Create a decision tree classifier for this data set. Limit the depth of the decision\n",
    "tree to 2, and visualize the decision tree. How do the \"rules\" the decision tree\n",
    "is using for its classification compare to what you found from the PCA analysis?\n",
    "Does it consider the same genes?\n",
    "\n",
    "Note: There is some \"randomness\" in decision trees, so\n",
    "the tree you now\n",
    "create will likely\n",
    "use different genes from the ones you\n",
    "found in exercise 9. You can rerun your code a few times to see how the randomness influences\n",
    "things, or you can also play with the depth of the tree so see if it picks out\n",
    "more genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to question 10.2:\n",
    "*Double click here*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
